{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from wildlife_datasets import analysis, datasets, loader\n",
    "from data.wildlife_dataset import WildlifeDataModule\n",
    "\n",
    "\n",
    "root = '/Users/amee/Documents/code/master-thesis/datasets/'\n",
    "path_raptors = os.path.join(root, 'raptor_individuals_cropped')\n",
    "path_BirdIndividualID = os.path.join(root, 'BirdIndividualID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 509\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 382/127/0/509\n",
      "Classes: train/test/unassigned/total = 69/53/0/69\n",
      "Classes: train only/test only/joint  = 16/0/53\n",
      "\n",
      "Fraction of train set     = 75.05%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 382\n",
      "Number of individuals (classes): 69\n",
      "Mean images/individual: 5.536231884057971\n",
      "Min images/individual: 2\n",
      "Max images/individual: 48\n",
      "Test Set\n",
      "Length: 127\n",
      "Number of individuals (classes): 53\n",
      "Mean images per individual: 2.3962264150943398\n",
      "Min images per individual: 1\n",
      "Max images per individual: 8\n",
      "Starting precomputation for bbox_mask (382 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/Documents/code/master-thesis/EagleID/notebooks/../data/wildlife_dataset.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['query'] = df_test['query'].astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mask cache from ../dataset/data_cache/train_raptors_mask.npz: Masks count: 382\n",
      "Loaded primary cache from ../dataset/data_cache/train_raptors_mask.npz: Mask: 382\n",
      "Precomputed data loaded from bbox_mask for train_raptors. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 382\n",
      "first 5 rows of metadata:\n",
      "   image_id species  identity_id         identity  \\\n",
      "0       271  goleag         33.0  Alabama_natchez   \n",
      "1       273  goleag         33.0  Alabama_natchez   \n",
      "2       274  goleag         33.0  Alabama_natchez   \n",
      "3       282  goleag         36.0  Bernheim_athena   \n",
      "4       283  goleag         36.0  Bernheim_athena   \n",
      "\n",
      "                                                path  from_video  video  date  \\\n",
      "0        goleag/Alabama_natchez/bostonmmountains.jpg       False    NaN  2000   \n",
      "1           goleag/Alabama_natchez/mfdc6688_crop.jpg       False    NaN  2000   \n",
      "2                 goleag/Alabama_natchez/Natchez.jpg       False    NaN  2000   \n",
      "3  goleag/Bernheim_athena/Athena_June2023-scaled.png       False    NaN  2023   \n",
      "4          goleag/Bernheim_athena/Athenajan_2023.png       False    NaN  2023   \n",
      "\n",
      "                                        segmentation  height   width  \\\n",
      "0  [[324.77813720703125, 77.23750305175781, 323.7...   386.0   686.0   \n",
      "1  [[101.9078140258789, 13.087499618530273, 101.3...   111.0   377.0   \n",
      "2  [[1027.6500244140625, 265.1999816894531, 1025....  1224.0  1632.0   \n",
      "3  [[256.1062316894531, 20.749998092651367, 253.1...   277.0   628.0   \n",
      "4  [[730.25, 166.60000610351562, 727.075012207031...  1146.0  2032.0   \n",
      "\n",
      "                                                bbox       area  iscrowd  \\\n",
      "0  [107.1875, 77.23750305175781, 525.21875, 306.5...   116883.0      0.0   \n",
      "1  [14.137499809265137, 13.087499618530273, 351.6...    14152.0      0.0   \n",
      "2  [387.6000061035156, 265.1999816894531, 1241.84...  1008001.0      0.0   \n",
      "3  [39.25, 20.749998092651367, 560.2937622070312,...    64045.0      0.0   \n",
      "4  [177.8000030517578, 166.60000610351562, 1539.8...  1101711.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [341, 89, 2, 295, 155, 2, 290, 155, 2, 177, 23...           23.0   \n",
      "1  [190, 41, 2, 197, 44, 2, 186, 41, 2, 193, 55, ...           23.0   \n",
      "2  [1029, 288, 2, 873, 528, 2, 861, 528, 2, 430, ...           23.0   \n",
      "3  [97, 51, 2, 86, 78, 2, 86, 83, 2, 48, 83, 2, 8...           23.0   \n",
      "4  [773, 186, 2, 1044, 487, 2, 1059, 502, 2, 1645...           23.0   \n",
      "\n",
      "   orientation  query metadata_split  \n",
      "0          NaN      0          train  \n",
      "1          NaN      0          train  \n",
      "2          NaN      0          train  \n",
      "3          NaN      0          train  \n",
      "4          NaN      0          train  \n",
      "Starting precomputation for bbox_mask (49 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_raptors_mask.npz: Masks count: 49\n",
      "Loaded primary cache from ../dataset/data_cache/query_raptors_mask.npz: Mask: 49\n",
      "Precomputed data loaded from bbox_mask for query_raptors. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 49\n",
      "first 5 rows of metadata:\n",
      "   image_id species  identity_id         identity  \\\n",
      "0       281  goleag         36.0  Bernheim_athena   \n",
      "1       162  baleag         22.0   BigBear_jackie   \n",
      "2       229  baleag         25.0   BigBear_shadow   \n",
      "3       223  baleag         24.0       Dayton_orv   \n",
      "4       255  baleag         26.0     Dayton_willa   \n",
      "\n",
      "                                                path  from_video  video  date  \\\n",
      "0  goleag/Bernheim_athena/wnp-aigle-eagle-1-640x4...       False    NaN  2000   \n",
      "1              baleag/BigBear_jackie/aug-13-2023.jpg       False    NaN  2023   \n",
      "2               baleag/BigBear_shadow/oct23_2022.jpg       False    NaN  2022   \n",
      "3  baleag/Dayton_orv/nov-2023-daytons-bald-eagle-...       False    NaN  2023   \n",
      "4  baleag/Dayton_willa/Sep-2023-the-carillon-park...       False    NaN  2023   \n",
      "\n",
      "                                        segmentation  height   width  \\\n",
      "0  [[187.0, 25.5, 186.0, 26.5, 183.0, 26.5, 182.0...   427.0   640.0   \n",
      "1  [[1143.0999755859375, 320.0, 1139.900024414062...  2048.0  1915.0   \n",
      "2  [[527.332763671875, 443.8562316894531, 524.212...  1362.0  1997.0   \n",
      "3  [[106.47655487060547, 127.59375, 101.40625, 13...  2405.0  3245.0   \n",
      "4  [[718.3312377929688, 170.5625, 714.38433837890...  1762.0  2526.0   \n",
      "\n",
      "                                                bbox      area  iscrowd  \\\n",
      "0                        [164.0, 25.5, 399.0, 398.0]   98949.0      0.0   \n",
      "1  [995.9000244140625, 320.0, 358.4000244140625, ...  173527.0      0.0   \n",
      "2  [499.2499694824219, 443.8562316894531, 876.807...   68519.0      0.0   \n",
      "3  [96.3359375, 127.59375, 3026.9765625, 2159.952...  818711.0      0.0   \n",
      "4  [426.2624816894531, 170.5625, 639.393768310546...  643870.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [256, 35, 2, 236, 50, 2, 232, 46, 2, 174, 42, ...           23.0   \n",
      "1  [1178, 335, 2, 1223, 380, 2, 1151, 380, 2, 118...           23.0   \n",
      "2  [1001, 560, 2, 1009, 569, 2, 984, 569, 2, 1018...           23.0   \n",
      "3  [1535, 1280, 2, 1476, 1398, 2, 1446, 1398, 2, ...           23.0   \n",
      "4  [794, 193, 2, 849, 235, 2, 849, 235, 2, 1002, ...           23.0   \n",
      "\n",
      "   orientation  query metadata_split  \n",
      "0          NaN   True           test  \n",
      "1          NaN   True           test  \n",
      "2          NaN   True           test  \n",
      "3          NaN   True           test  \n",
      "4          NaN   True           test  \n",
      "Starting precomputation for bbox_mask (78 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_raptors_mask.npz: Masks count: 78\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_raptors_mask.npz: Mask: 78\n",
      "Precomputed data loaded from bbox_mask for gallery_raptors. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 78\n",
      "first 5 rows of metadata:\n",
      "   image_id species  identity_id         identity  \\\n",
      "0       284  goleag         36.0  Bernheim_athena   \n",
      "1       165  baleag         22.0   BigBear_jackie   \n",
      "2       167  baleag         22.0   BigBear_jackie   \n",
      "3       186  baleag         22.0   BigBear_jackie   \n",
      "4       199  baleag         22.0   BigBear_jackie   \n",
      "\n",
      "                                                path  from_video  video  date  \\\n",
      "0  goleag/Bernheim_athena/both_athena_newpartner.jpg       False    NaN  2000   \n",
      "1              baleag/BigBear_jackie/jan_11_2023.jpg       False    NaN  2023   \n",
      "2              baleag/BigBear_jackie/june28-2022.png       False    NaN  2022   \n",
      "3               baleag/BigBear_jackie/feb_8_2023.jpg       False    NaN  2023   \n",
      "4               baleag/BigBear_jackie/jan_2_2019.jpg       False    NaN  2019   \n",
      "\n",
      "                                        segmentation  height   width  \\\n",
      "0  [[377.0078125, 9.0625, 376.3031311035156, 9.76...   300.0   451.0   \n",
      "1  [[721.995361328125, 321.5249938964844, 719.762...  1429.0  1118.0   \n",
      "2  [[152.08750915527344, 82.4000015258789, 150.80...   824.0   590.0   \n",
      "3  [[905.5999755859375, 562.7000122070312, 902.40...  1535.0  2048.0   \n",
      "4  [[423.3249816894531, 253.5, 421.2124938964844,...  1352.0  1041.0   \n",
      "\n",
      "                                                bbox      area  iscrowd  \\\n",
      "0  [2.8187501430511475, 9.0625, 437.6109373569488...   66754.0      0.0   \n",
      "1  [353.58123779296875, 321.5249938964844, 502.38...   73380.0      0.0   \n",
      "2  [99.30000305175781, 82.4000015258789, 346.3375...  111249.0      0.0   \n",
      "3  [179.1999969482422, 562.7000122070312, 1062.39...  135147.0      0.0   \n",
      "4  [5.049999713897705, 253.5, 804.8624758720398, ...  700721.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [367, 28, 2, 397, 33, 2, 393, 37, 2, 431, 37, ...           23.0   \n",
      "1  [469, 558, 2, 474, 568, 2, 469, 563, 2, 454, 5...           23.0   \n",
      "2  [217, 94, 2, 189, 104, 2, 189, 104, 2, 122, 13...           23.0   \n",
      "3  [684, 675, 2, 704, 695, 2, 673, 706, 2, 684, 7...           23.0   \n",
      "4  [455, 271, 2, 551, 324, 2, 551, 335, 2, 786, 4...           23.0   \n",
      "\n",
      "   orientation  query metadata_split  \n",
      "0          NaN  False           test  \n",
      "1          NaN  False           test  \n",
      "2          NaN  False           test  \n",
      "3          NaN  False           test  \n",
      "4          NaN  False           test  \n",
      "Round 1 Query image_ids: [81, 63, 6, 71, 74, 14, 42, 100, 104, 113, 124, 134, 162, 229, 255, 381, 149, 108, 144, 122, 209, 478, 288, 365, 340, 300, 503, 452, 419, 456, 395, 370, 460, 464, 475, 471, 432, 335, 223, 115, 274, 488, 342, 319, 323, 386, 281, 350, 309]\n",
      "Round 1 Gallery image_ids: [32, 21, 46, 51, 50, 91, 88, 90, 66, 73, 75, 106, 109, 116, 115, 123, 133, 131, 150, 167, 165, 186, 8, 9, 284, 200, 206, 199, 205, 239, 245, 244, 226, 256, 386, 384, 101, 135, 145, 211, 222, 359, 479, 368, 344, 338, 337, 504, 279, 454, 430, 420, 457, 499, 316, 409, 403, 408, 373, 462, 466, 351, 476, 472, 322, 328, 391, 443, 512, 306, 231, 46, 216, 289, 303, 495, 293, 315]\n"
     ]
    }
   ],
   "source": [
    "from data.raptors_wildlife import Raptors\n",
    "\n",
    "dataset_raptors = Raptors(path_raptors)\n",
    "\n",
    "data_raptors = WildlifeDataModule(\n",
    "                            metadata=dataset_raptors.df,\n",
    "                            data_dir=path_raptors, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_raptors_split.csv\", # METADATA SPLIT\n",
    "                            animal_cat=\"bird\", \n",
    "                            splitter ='metadata_split',  # METADATA SPLIT BC ALREADY SPLIT BEFORE\n",
    "                            only_cache=True,\n",
    "                            wildlife_names='raptors',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 2875\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "No segmentation data found: Not a list after conversion.\n",
      "Removed 597 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 1773/505/0/2278\n",
      "Classes: train/test/unassigned/total = 40/40/0/40\n",
      "Classes: train only/test only/joint  = 0/0/40\n",
      "\n",
      "Fraction of train set     = 77.83%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 1773\n",
      "Number of individuals (classes): 40\n",
      "Mean images/individual: 44.325\n",
      "Min images/individual: 6\n",
      "Max images/individual: 74\n",
      "Test Set\n",
      "Length: 505\n",
      "Number of individuals (classes): 40\n",
      "Mean images per individual: 12.625\n",
      "Min images per individual: 3\n",
      "Max images per individual: 20\n",
      "Starting precomputation for bbox_mask (1773 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/train_BirdIndividualID_mask.npz: Masks count: 1773\n",
      "Loaded primary cache from ../dataset/data_cache/train_BirdIndividualID_mask.npz: Mask: 1773\n",
      "Precomputed data loaded from bbox_mask for train_BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 1773\n",
      "first 5 rows of metadata:\n",
      "           image_id    identity  \\\n",
      "0  012a691860d0efb5  011016A9DF   \n",
      "1  05f4a08da3b5d7bb  011016A9DF   \n",
      "2  0be589a0a94d12c3  011016A9DF   \n",
      "3  14298ed789b2209a  011016A9DF   \n",
      "4  19d52f6706a25484  011016A9DF   \n",
      "\n",
      "                                                path           species  \\\n",
      "0  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "1  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "2  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "3  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "4  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "\n",
      "  original_split                  bbox  \\\n",
      "0          train  [416, 240, 185, 361]   \n",
      "1          train  [192, 304, 233, 141]   \n",
      "2          train   [720, 240, 221, 93]   \n",
      "3          train     [80, 32, 93, 169]   \n",
      "4          train   [496, 96, 153, 457]   \n",
      "\n",
      "                                        segmentation  height  width  area  \\\n",
      "0  [[576, 240, 528, 240, 520, 244, 464, 316, 440,...     768   1024   NaN   \n",
      "1  [[192, 364, 204, 380, 232, 396, 244, 396, 296,...     768   1024   NaN   \n",
      "2  [[720, 260, 724, 276, 744, 296, 764, 304, 769,...     768   1024   NaN   \n",
      "3  [[168, 32, 116, 32, 100, 44, 96, 52, 96, 84, 8...     768   1024   NaN   \n",
      "4  [[544, 96, 528, 108, 512, 132, 512, 144, 500, ...     768   1024   NaN   \n",
      "\n",
      "   iscrowd  width.1  height.1  \\\n",
      "0      NaN     1024       768   \n",
      "1      NaN     1024       768   \n",
      "2      NaN     1024       768   \n",
      "3      NaN     1024       768   \n",
      "4      NaN     1024       768   \n",
      "\n",
      "                                           keypoints  num_keypoints  \n",
      "0  [563, 242, 2, 531, 249, 2, 587, 253, 2, 513, 2...             23  \n",
      "1  [375, 311, 2, 375, 346, 2, 373, 346, 2, 423, 3...             23  \n",
      "2  [920, 255, 2, 917, 285, 2, 915, 285, 2, 939, 3...             23  \n",
      "3  [117, 39, 2, 138, 43, 2, 137, 44, 2, 150, 38, ...             23  \n",
      "4  [560, 104, 2, 600, 108, 2, 595, 112, 2, 639, 1...             23  \n",
      "Starting precomputation for bbox_mask (40 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_BirdIndividualID_mask.npz: Masks count: 40\n",
      "Loaded primary cache from ../dataset/data_cache/query_BirdIndividualID_mask.npz: Mask: 40\n",
      "Precomputed data loaded from bbox_mask for query_BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 40\n",
      "first 5 rows of metadata:\n",
      "           image_id    identity  \\\n",
      "0  05882ea0023ccd22  011016A9DF   \n",
      "1  15256a78161a711d  011016AAEE   \n",
      "2  008cb7cf80eaa283  011016B1FB   \n",
      "3  17ecd67ee98f984f  011016B484   \n",
      "4  66f7f2d4f07d6b60  011016B52D   \n",
      "\n",
      "                                                path           species  \\\n",
      "0  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "1  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "2  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "3  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "4  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "\n",
      "  original_split                                               bbox  \\\n",
      "0          train  [486.3999938964844, 179.1999969482422, 190.399...   \n",
      "1            val                               [512, 176, 217, 425]   \n",
      "2          train  [928.0, 550.4000244140625, 94.4000244140625, 2...   \n",
      "3          train                               [448, 192, 229, 461]   \n",
      "4            val                               [784, 576, 237, 189]   \n",
      "\n",
      "                                        segmentation  height  width     area  \\\n",
      "0  [[612.7999877929688, 179.1999969482422, 611.20...     768   1024  43406.0   \n",
      "1  [[532, 176, 524, 181, 520, 192, 528, 224, 528,...     768   1024      NaN   \n",
      "2  [[1011.2000122070312, 550.4000244140625, 1009....     768   1024  15266.0   \n",
      "3  [[468, 192, 452, 204, 448, 216, 448, 256, 452,...     768   1024      NaN   \n",
      "4  [[1020, 645, 1008, 640, 1000, 616, 964, 576, 8...     768   1024      NaN   \n",
      "\n",
      "   iscrowd  width.1  height.1  \\\n",
      "0      0.0     1024       768   \n",
      "1      NaN     1024       768   \n",
      "2      0.0     1024       768   \n",
      "3      NaN     1024       768   \n",
      "4      NaN     1024       768   \n",
      "\n",
      "                                           keypoints  num_keypoints  query  \n",
      "0  [651, 181, 2, 651, 194, 2, 651, 194, 2, 668, 2...             23   True  \n",
      "1  [585, 183, 2, 539, 199, 2, 539, 199, 2, 518, 1...             23   True  \n",
      "2  [932, 750, 0, 994, 715, 2, 992, 713, 2, 930, 7...             23   True  \n",
      "3  [483, 204, 2, 456, 267, 2, 614, 303, 2, 452, 2...             23   True  \n",
      "4  [963, 595, 2, 848, 611, 2, 949, 655, 2, 945, 6...             23   True  \n",
      "Starting precomputation for bbox_mask (465 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_BirdIndividualID_mask.npz: Masks count: 465\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_BirdIndividualID_mask.npz: Mask: 465\n",
      "Precomputed data loaded from bbox_mask for gallery_BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 465\n",
      "first 5 rows of metadata:\n",
      "           image_id    identity  \\\n",
      "0  0aab098edc3e0d00  011016A9DF   \n",
      "1  196cf70a5d39d39d  011016A9DF   \n",
      "2  23a251d7458b0609  011016A9DF   \n",
      "3  379b64a12e0e8b2f  011016A9DF   \n",
      "4  439ab2330583830c  011016A9DF   \n",
      "\n",
      "                                                path           species  \\\n",
      "0  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "1  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "2  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "3  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "4  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
      "\n",
      "  original_split                  bbox  \\\n",
      "0          train   [32, 304, 229, 285]   \n",
      "1          train  [544, 164, 141, 557]   \n",
      "2          train   [768, 144, 97, 189]   \n",
      "3            val  [160, 448, 145, 317]   \n",
      "4          train  [248, 192, 297, 453]   \n",
      "\n",
      "                                        segmentation  height  width  area  \\\n",
      "0  [[36, 304, 32, 308, 32, 408, 44, 424, 48, 440,...     768   1024   NaN   \n",
      "1  [[565, 164, 568, 236, 560, 264, 544, 292, 544,...     768   1024   NaN   \n",
      "2  [[772, 144, 768, 152, 780, 164, 780, 184, 768,...     768   1024   NaN   \n",
      "3  [[208, 448, 176, 468, 160, 504, 160, 636, 176,...     768   1024   NaN   \n",
      "4  [[528, 196, 520, 192, 472, 192, 352, 340, 352,...     768   1024   NaN   \n",
      "\n",
      "   iscrowd  width.1  height.1  \\\n",
      "0      NaN     1024       768   \n",
      "1      NaN     1024       768   \n",
      "2      NaN     1024       768   \n",
      "3      NaN     1024       768   \n",
      "4      NaN     1024       768   \n",
      "\n",
      "                                           keypoints  num_keypoints  query  \n",
      "0  [50, 311, 2, 36, 319, 0, 145, 317, 0, 142, 317...             23  False  \n",
      "1  [611, 200, 2, 557, 189, 2, 557, 189, 2, 546, 1...             23  False  \n",
      "2  [804, 156, 2, 793, 158, 2, 791, 160, 2, 769, 1...             23  False  \n",
      "3  [237, 459, 2, 271, 487, 2, 271, 487, 2, 302, 4...             23  False  \n",
      "4  [513, 195, 2, 535, 208, 2, 535, 208, 2, 544, 2...             23  False  \n",
      "Round 1 Query image_ids: ['05882ea0023ccd22', '15256a78161a711d', '008cb7cf80eaa283', '17ecd67ee98f984f', '66f7f2d4f07d6b60', '087b13613915c5dc', '04f9932b9802771c', '055dd7918826bf4e', '174973ce7aa07523', '01ba69d5bf44bce0', '2819f9f62729e850', '00698098dd8a3954', '29cba2694192577d', '07fecee35e61e376', '02e33957a97af54c', '30e53e15cd78693c', '40fb9fd54fac155d', '0f2f90ae6aa889c3', '3e4e95d346065cef', '2425e9d4374c0e5f', '0e7e289bda0eecc5', '034c0892d43e28a6', '099a10a96ef4101f', '1c1218aa4b50c674', '0c73c770e2371c51', '0479ca29beea5f2b', '0403d7270d5828f0', '0522fada68872644', '018bdb032143d8d7', '3508c4aa773dd569', '2246e1e76384545b', '011f48d6ef9d1956', '090088ba575e2c2e', '098f70d801b6959d', '1423631d6231c229', '06537194758bd439', '00239fb5101d581c', '25ba0843c3d63092', '129b43c010863699', '0978f65499c17b73']\n",
      "Round 1 Gallery image_ids: ['23a251d7458b0609', '379b64a12e0e8b2f', 'a806bff9038765cd', '196cf70a5d39d39d', '0aab098edc3e0d00', 'b64d060f1c665bc1', 'f4b6b69d50f08ace', 'f78d03cd7f6e571a', '7666ba27570a59a8', '83938a9a8d46c4f4', '60a34e48a4a3ffbb', '6ce19fa23d808b09', 'e096018fb051c741', '439ab2330583830c', '654ae96dc17a3c29', '66100f45260ceb72', 'e2b3e4d0c9c78af9', '78bf4dfda2ae02e8', '9d26232ba5c10ba7', '8d512d275e184736', 'a6a734078993a960', 'f06662e7f2d67ef0', '9e8381fdfc1a8fd0', 'ef560bdce88404fa', 'dfa77c7deb3ccf5c', 'c49328438d4e86eb', 'e51fed6b31211809', '6fe706f18daf8476', '2371cba35a53b2e2', '953f9c0cfff85f09', '769e3ac711d30bff', '3397f88d8b7e8e3d', '42ce0c23fc557006', '3f6c6792842b4fe3', 'df4a83248fa25edb', 'bcf60fb8ac721335', '8faa5b972396c72c', '623e4db522f9a1cc', 'b7a0ef40e6163c91', '3cf4b2356dfee7ff', 'bd8804809c033c89', '6132cb3a69279d6a', 'b9964f11b2452fc5', '8bea851c26e058ac', '613be371daf79c30', 'ed888d6c5788a3a2', '3c288654d0262dcf', 'a23eccc236a35d5d', '865f6799ffed4a29', 'fd6057b073444fe7', 'b3b568d3373e8448', 'a79f84a2d5161421', '9a9b13b5a1224cb9', '9cbbda3b0991fc4d', '78e4870027a27dd4', 'fa8c38dca4667d52', '69d11afc859eddf9', 'ad9d199da03b2034', '8eb8b713873e21ea', '5fea6b904933be7d', '35b6a952d22ba98e', 'b5c562f2b456446b', 'cd59c21285bc5574', '289fe506d3016bf2', '99a1aac77314d559', 'd2a8fa5015c6205f', 'b555d58da5b8e710', 'd943f7f75b29fbf7', 'ca3321b66228fadd', 'e5e0e92717ab6957', '249c65a88c53e84b', '50a6cc71de68ae75', '9f9db4e1856b7f4f', 'dcf1d11253521845', 'ba7221ebbf33b554', 'a5ed33145bc933fb', '6eeba97425f9e8ae', '6348bbfc9ad54a2f', '5dd74751d4214494', 'dc68b41abdfd0805', '7702f8280c79ed04', '5f099a71a7d992a4', '90f4008f6a7d4699', '77544022dbd78714', '58d71b248597b339', 'ed3dc0ea512785ee', '1d63bebf2bf7db46', '4e6c8643124191fe', '80bcda76e8efa66f', '38468a066407c592', 'c3f11a65f52e108b', '5c7410dd297a83d2', 'aac1dc333bbcea6c', 'fbd06a920cd988a7', '9efed14bfa747d41', '6271a64d7102b32c', '8fc2c0144170064e', '53bcec33e8b4b701', 'a810b1bf002716ea', '1f37588ad8e83279', '4176dff5e36a8b5f', '37de7727bfc97484', '3de031e22ad72867', '9bb0088796e91b8e', '4e9ab9fedf9885ad', '05189c57b6033108', 'e88f9e35234d80a4', '7fcbbe70cea3a33f', 'c98ff2f036c25a4c', '574a729ddd4d0432', 'c1b945612e993ae5', 'd7a76ec28bb0f4c6', '2f65f53b6614ba63', '4ae2a60d0a3bdadb', '1d1c0730b7c8194c', '1bc72ab2404c04f6', '9b32e03bc063965a', '9456c5da21982c53', 'b3fa39771632916c', '1c18eead36afaa58', '4ee99a3d45c77dea', '3e77e9a15c05794c', 'fdf410bdeb881eaa', 'fef4dfe56d578de9', '3c20f36f7359cdf6', '286ef613008423a5', '7383d91873c20848', 'f88a41f9964daf8b', '8806f87f9c777db3', 'f12396990168a55d', 'a251bdfa071e1f8b', '8af081de786f789e', '8db547040f9282a3', '5878df96cfd22741', '503cf6161ee4c9dc', '88501d3efe81c133', 'e7610f1641b3c751', 'ebe0ea5a6bd4af03', 'd4001cbefce06d11', 'b48bb3bfee007b1b', '4ce51b825c3cda3b', '044f22c9aeea334a', 'a637d0022c77b19a', '3c65aa38d3ab1c8d', 'a8b48d09c65476b8', '13c8845a495dba99', 'aa48b38e781df24e', '9ef699fb57db7760', '9da6f0bd5782c01b', 'd4c0ac9f3f13c655', 'fe8a0b3943efca0d', '0746098d4d326b55', 'c46efc893402ced5', '43f3f6cc0044aa2d', 'e9de553c94f284b1', 'ffe243034c7e749a', '50e9e201413bfa0d', 'f70edbef5b2907be', '36392d1df721eeda', '9a5c95beda948d4c', '620a130cf4b3e446', '8eca27eed6f4dc45', '3ccde6882d4f1051', '4086101eca9d90a5', '85c2ff4b58453e96', 'ec67cff30d1c8aaf', '7a8f7c286a47cd7a', '98a894fe5999fd35', '6e14726183e6e275', '32cd442d6270a7f4', 'eb30606f5fae439b', 'cccc44dda0f895bd', 'ace5156f66827e01', '45f2f3c8d4261ed2', 'c63c02ef252a70e4', '71fd0e6445da386a', '5a2219d818e8e79c', 'f5f72ad3ab3cf4c3', '60fd5dd61e696fd2', '6ef69b96946b8d67', '749c73fd4fcba788', 'b11d1fa5e5746925', '870a585967708f69', 'f21f001fb12412d8', '59edae0958874fd8', '7e67b9818cb30473', '57f3f62147501756', 'c77854a6c03f4867', '76b4f5ecc19f5705', '59a8f1bbe95ef6f7', '979b8fcd36e0951d', '7f85841cef4e6526', '884aaf7860ae8d84', '5a868e81d9440687', '400fa17a2abffe32', 'b8b3757f3a960461', 'cb93d4741c276867', '75280bf5679d7f8f', '7c716704389f1e6c', 'c04ea6bd37f6a90e', 'd1e7229577dd72c3', '86f44b70b907432b', '727a14cba78de4e4', '455f190c088fb232', 'c88da21681dc2147', '6a3f5aa4b6a39a26', 'd93306c33b9d7da9', '2bfb83a4fcdea5cb', '1223cbce1fe14c19', 'fdce61a32bdd0534', 'c103d5a6b8c71a1e', 'ec59b0632a621a66', '719c758773099b17', 'fe07aeac69a71da4', '33f71541e05a3d24', '8d103ebedc8393a0', 'fec2c42a8a4584ca', '3a2303ef568a78a8', 'bb59567ff179c66f', '1be3b3f5fdb20217', 'aab84f158f60d711', '803475590334d452', '8b7a8710bcdc4680', '955cb903e1c3127b', '960c667ef28f3fd1', '6451b4af0e40c169', '5436fd0a733e983e', 'c7040235fafdc2e5', 'c18368c8961b7426', 'b9ef65e071796ed8', '3e3304e62af66e77', 'eb16913d2114f772', '6bc34cc4cb8cbe46', 'cb3fabd29600184a', '7b34fdb945cb456b', '2d95200fbe74bbbf', 'ebf0c28d2256e308', 'ede199ee6ca108ab', '5e2978f7319ee43c', '5462fe3333f3999d', 'fe4b7500329379f6', '38eb0218d7b1154d', 'f8a19b50b0950051', '5ac23482f7c3aa01', '29536436e0313d09', '5fb0fd305bbbd7a4', 'f4a9fdb05d90caca', '67ef44d037d65109', '237e9fa1c72bdcec', '72557a0e8fafb662', 'ceb7c36e3e6c2ef9', 'f59987c72d8fb9ef', '8990e6a54572e943', 'cae5e0b7906c100c', 'fded388a6d68d82d', '33f956a20aa7d09c', '202ce0636b9b5306', '993eb9a0cfcb1853', '2b680760c525d8d3', 'd6343993bf3ed562', '4e2d40c96859cc0e', '65b2e810f6fd7e4b', '0e98ff329f78f5dc', '25476378a6de5d67', 'c5bcd10e222f72cb', '16977c5acb9d0f5f', '2c6b1cb0b8bc6397', 'e32adf1aa0f86567', '4cba2be7843066e1', '57a080f6756dc05a', '17faed353848b522', 'c196ad5fa87afb1d', '1283ea666d2a5884', 'fac7ced039f2ece4', '12cab36847a83f71', '68505869c6d614c0', 'e5ea6019a2eb77e7', 'e68ccbd02baa7745', '5b263f1d4861757b', 'd4c6df0c094fe7f2', 'bcda609492ace48a', 'df4b2e4dadfae3bd', '9fc741fb0ebc715e', '63e1e0ccd24aa244', 'c6f152f065e19b57', '96331b591461f98c', 'fda411a9df6c8df2', '2337ce0211de96a0', '4b6bbf50d7cdef8d', 'fb564ff6617a76b7', '320742a94db60c22', 'b195a587cd3f566e', 'f8a319638daee867', '1592e8f45cca9b42', 'ca66891673ebf729', '6cfa85015fc029ab', '74c35cd1098621bf', '18ab72a77c36551c', '8520095ddc4177ee', '1fad2acf3a8a6567', '45d5f4e8d373562f', '7d1bbf0e394d84cc', '894e002a788ece1f', '59346b1afe36dc97', 'cdc8cbdd05cb55e1', '74e4ee51c5116b88', 'a627999577cbdc2d', '3ff1635d5d255697', '23dcec7415fd1833', '28192319608d8ab9', 'd81dc02bb0e94546', '1baabd8dc9e38348', '28d7853fe9b6bbee', '37bd6e17d30b60c4', '0d85d5ae9c5b8695', '44b6330c66e18835', '1b5fca0d8fd1e2ff', 'b3d7c59a37ccbc32', '0e59811e5950100c', '5c0dc948b6c4054a', '37e067cfa2a2b620', '827e0d70a0aae16b', '1673b5015544f2d9', '276ddc3d38f9227f', '92e6308a4914eb3c', '41cb030e2b10e093', 'c65858dcec433a77', '3cc802cce56df11f', '4d3a7366599913a7', '683b10c12b8df7ea', 'e0d173a8deb3dc02', '3b2db441749a6122', '6dc67bc7149d51f0', '4b7f8c46b1338f5c', '7ca2fe6dc6c0a426', '9f102b27f0259db6', '8646d23aad929a25', 'a686139dec908c62', 'c65398e479ed0c66', 'ef8beed34ff38781', '96dc00d507f79ba7', 'ac7dad092e404b3d', '02f070dad7cda6e5', 'c6c9a87aa5c6db81', 'bea6e360fbcb5e06', 'fe8c4ff8b0fabd77', '7789b50c222de273', '8c4282a0eb5528ba', 'c24787cb63343c17', '3253d532b2deeccd', '26eea6871abaebb4', '1feff7a52424fb4b', '4d37075c1b9f4d70', '9c5a113024a16275', 'bd9a010df3380a1f', 'e12a74e55f222e62', '5f6fa728eb474eb1', '0c3203fb5abb8207', '81dae5f82c221c43', 'c1ad519f36763141', '43498074bfdcb253', '2fa0f764af20471c', 'e91e4d3477355dd4', 'c70ffeab14da407e', '952b8ef28b1c8d5c', '18400e851dfa0554', '7255823bfa0b5eab', 'd637257d57f235c5', '360e3e342a9cecaa', 'fabeed47c0f7ec65', '2dc6db43084bbdf3', '6817089230ba94d7', '4db2369b215b39e0', 'bb87aad099d6c087', '8b766a1c69e14cd3', 'acab191a177e137d', '91c6e97e2d99404b', '87fff9200a4f370b', '5d21b505158fb5ff', '91598420f8c38c14', 'cabd288e21b82cf2', '5934f9120d7924b5', 'cc36d5cc025fc692', '9124fa44f21dc1eb', '95ae25e85eadfb76', '5b7bd69d74a91b1d', '918c4090c71089fe', 'ef7abe7a12ec15a3', 'ea3b52787d83d6ac', '8b327a2a38e2e5c0', '277aaf1b1ca91879', '0ebd0f8c89392e68', '2101a2aa0ed62141', 'a7666a70c29829f6', '932952675a14dd74', 'e30f6caeaa9d7dda', '29bf49e220826867', '849872c87d3ece1f', 'ea45775ac06a78f7', 'b71d1f65ab20ee9b', '4d5d4cb6f4c89e68', '57778e6e3d7e4383', '4be193b96504b0ed', '5eb02f2b511be31e', 'c0171469e9cf9d3e', 'b96b2a22b0d2ab68', '898147e6cda7fd05', '52361e3cffe3a3f5', '94ab7b385718aae7', '2dccbc5be007025b', 'e515a183caf446e9', 'c0015cdbaf8550c1', '785a886da7dca71a', '5b6cdfae9f4375f6', '40aa82c5b5e6099e', 'cdc9243e20391187', '8871c6dfa89dfcda', '3482d9e3684ca708', '633e4a5318b1ea98', 'e64d9a8ff0bfb70f', '412e54b0a8e790db', '5ec53bf51fa7a37b', '663d918510fecf56', 'c6d594357ddf0a86', '76589e7284618285', 'e6553fc1a1497c91', '5bee7a79f6b09f81', 'ef8941409bb40e81', 'bb5d1413985bc4ec', 'ebc838082a95e50d', '7a148a63d7ec94b0', 'fc94fec2a80f9c69', 'e9ccef7068ac6fd0', 'b86a87a47e56b9f2', '5b5b7981ef35b7e8', '5e1760b82109e5d5', '31d66c42d02af78a', '75df02a3690d47d0', 'd4fbf1284416eea1', 'cf661d92c947f492', 'b6017d5f38da3d92', '74e56d4727f49634', 'fe904f598a7a87b8', '68a10f28d3f1551b', 'e1a27abf6656d848', '18a09854dfc768c6', '3ecadb3ef1ca5690', 'e535253cb1b36dd6', 'cc3c7e517820fa53', 'e17e8ecaf0704fe9', '1cd64f2ef9c8794f', 'c88a414c531f655e', '705af3623beb9895', '3eab5875f41ed762', 'ae377dcb4f9fb988', '61b597214f1b1f32', '7fcef1db60d234fa', '127a977937197177', 'ade5c64b9107ee44', '0dc16fc89de34ed4', '29d0e6387dd8f25d', '219d4df03f6db30f', 'd9f5842176c044f1', 'd8a03ec80d9ee2c0', '2116e606c7ebe137']\n"
     ]
    }
   ],
   "source": [
    "dataset_BirdIndividualID = datasets.BirdIndividualID(path_BirdIndividualID)\n",
    "\n",
    "data_BirdIndividualID = WildlifeDataModule(\n",
    "                            metadata=dataset_BirdIndividualID.df,\n",
    "                            data_dir=path_BirdIndividualID, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_BirdIndividualID.csv\",\n",
    "                            animal_cat=\"bird\", \n",
    "                            splitter ='custom_closed', \n",
    "                            only_cache=True,\n",
    "                            wildlife_names='BirdIndividualID',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>species</th>\n",
       "      <th>original_split</th>\n",
       "      <th>bbox</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>area</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>width.1</th>\n",
       "      <th>height.1</th>\n",
       "      <th>keypoints</th>\n",
       "      <th>num_keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012a691860d0efb5</td>\n",
       "      <td>011016A9DF</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[416, 240, 185, 361]</td>\n",
       "      <td>[[576, 240, 528, 240, 520, 244, 464, 316, 440,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[563, 242, 2, 531, 249, 2, 587, 253, 2, 513, 2...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05f4a08da3b5d7bb</td>\n",
       "      <td>011016A9DF</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[192, 304, 233, 141]</td>\n",
       "      <td>[[192, 364, 204, 380, 232, 396, 244, 396, 296,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[375, 311, 2, 375, 346, 2, 373, 346, 2, 423, 3...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0be589a0a94d12c3</td>\n",
       "      <td>011016A9DF</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[720, 240, 221, 93]</td>\n",
       "      <td>[[720, 260, 724, 276, 744, 296, 764, 304, 769,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[920, 255, 2, 917, 285, 2, 915, 285, 2, 939, 3...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14298ed789b2209a</td>\n",
       "      <td>011016A9DF</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[80, 32, 93, 169]</td>\n",
       "      <td>[[168, 32, 116, 32, 100, 44, 96, 52, 96, 84, 8...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[117, 39, 2, 138, 43, 2, 137, 44, 2, 150, 38, ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19d52f6706a25484</td>\n",
       "      <td>011016A9DF</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[496, 96, 153, 457]</td>\n",
       "      <td>[[544, 96, 528, 108, 512, 132, 512, 144, 500, ...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[560, 104, 2, 600, 108, 2, 595, 112, 2, 639, 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>f0ae1fd7ef327626</td>\n",
       "      <td>0700EE42FD</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[464, 160, 233, 497]</td>\n",
       "      <td>[[484, 160, 464, 180, 464, 264, 468, 268, 468,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[500, 173, 2, 476, 187, 2, 476, 187, 2, 462, 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>f17d064594bd0199</td>\n",
       "      <td>0700EE42FD</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>val</td>\n",
       "      <td>[80, 416, 141, 349]</td>\n",
       "      <td>[[200, 416, 164, 416, 148, 424, 132, 440, 120,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[162, 421, 2, 193, 432, 2, 193, 432, 2, 220, 4...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>f5cc7cfdce34038d</td>\n",
       "      <td>0700EE42FD</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[448, 224, 305, 333]</td>\n",
       "      <td>[[452, 224, 448, 228, 448, 292, 452, 296, 452,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[481, 226, 2, 455, 249, 2, 455, 249, 2, 449, 2...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>f9a00b376cfb73ad</td>\n",
       "      <td>0700EE42FD</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>train</td>\n",
       "      <td>[16, 592, 205, 173]</td>\n",
       "      <td>[[192, 592, 140, 592, 116, 608, 76, 664, 60, 6...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[155, 599, 2, 191, 623, 0, 189, 623, 2, 205, 5...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>fd0f7ad56e7ba6ab</td>\n",
       "      <td>0700EE42FD</td>\n",
       "      <td>Original_pictures/IndividualID/sociable_weaver...</td>\n",
       "      <td>sociable_weavers</td>\n",
       "      <td>val</td>\n",
       "      <td>[560, 160, 177, 589]</td>\n",
       "      <td>[[724, 160, 664, 160, 632, 172, 604, 200, 592,...</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>[639, 187, 2, 703, 210, 2, 703, 215, 2, 731, 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1773 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_id    identity  \\\n",
       "0     012a691860d0efb5  011016A9DF   \n",
       "1     05f4a08da3b5d7bb  011016A9DF   \n",
       "2     0be589a0a94d12c3  011016A9DF   \n",
       "3     14298ed789b2209a  011016A9DF   \n",
       "4     19d52f6706a25484  011016A9DF   \n",
       "...                ...         ...   \n",
       "1768  f0ae1fd7ef327626  0700EE42FD   \n",
       "1769  f17d064594bd0199  0700EE42FD   \n",
       "1770  f5cc7cfdce34038d  0700EE42FD   \n",
       "1771  f9a00b376cfb73ad  0700EE42FD   \n",
       "1772  fd0f7ad56e7ba6ab  0700EE42FD   \n",
       "\n",
       "                                                   path           species  \\\n",
       "0     Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "1     Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "2     Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "3     Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "4     Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "...                                                 ...               ...   \n",
       "1768  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "1769  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "1770  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "1771  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "1772  Original_pictures/IndividualID/sociable_weaver...  sociable_weavers   \n",
       "\n",
       "     original_split                  bbox  \\\n",
       "0             train  [416, 240, 185, 361]   \n",
       "1             train  [192, 304, 233, 141]   \n",
       "2             train   [720, 240, 221, 93]   \n",
       "3             train     [80, 32, 93, 169]   \n",
       "4             train   [496, 96, 153, 457]   \n",
       "...             ...                   ...   \n",
       "1768          train  [464, 160, 233, 497]   \n",
       "1769            val   [80, 416, 141, 349]   \n",
       "1770          train  [448, 224, 305, 333]   \n",
       "1771          train   [16, 592, 205, 173]   \n",
       "1772            val  [560, 160, 177, 589]   \n",
       "\n",
       "                                           segmentation  height  width  area  \\\n",
       "0     [[576, 240, 528, 240, 520, 244, 464, 316, 440,...     768   1024   NaN   \n",
       "1     [[192, 364, 204, 380, 232, 396, 244, 396, 296,...     768   1024   NaN   \n",
       "2     [[720, 260, 724, 276, 744, 296, 764, 304, 769,...     768   1024   NaN   \n",
       "3     [[168, 32, 116, 32, 100, 44, 96, 52, 96, 84, 8...     768   1024   NaN   \n",
       "4     [[544, 96, 528, 108, 512, 132, 512, 144, 500, ...     768   1024   NaN   \n",
       "...                                                 ...     ...    ...   ...   \n",
       "1768  [[484, 160, 464, 180, 464, 264, 468, 268, 468,...     768   1024   NaN   \n",
       "1769  [[200, 416, 164, 416, 148, 424, 132, 440, 120,...     768   1024   NaN   \n",
       "1770  [[452, 224, 448, 228, 448, 292, 452, 296, 452,...     768   1024   NaN   \n",
       "1771  [[192, 592, 140, 592, 116, 608, 76, 664, 60, 6...     768   1024   NaN   \n",
       "1772  [[724, 160, 664, 160, 632, 172, 604, 200, 592,...     768   1024   NaN   \n",
       "\n",
       "      iscrowd  width.1  height.1  \\\n",
       "0         NaN     1024       768   \n",
       "1         NaN     1024       768   \n",
       "2         NaN     1024       768   \n",
       "3         NaN     1024       768   \n",
       "4         NaN     1024       768   \n",
       "...       ...      ...       ...   \n",
       "1768      NaN     1024       768   \n",
       "1769      NaN     1024       768   \n",
       "1770      NaN     1024       768   \n",
       "1771      NaN     1024       768   \n",
       "1772      NaN     1024       768   \n",
       "\n",
       "                                              keypoints  num_keypoints  \n",
       "0     [563, 242, 2, 531, 249, 2, 587, 253, 2, 513, 2...             23  \n",
       "1     [375, 311, 2, 375, 346, 2, 373, 346, 2, 423, 3...             23  \n",
       "2     [920, 255, 2, 917, 285, 2, 915, 285, 2, 939, 3...             23  \n",
       "3     [117, 39, 2, 138, 43, 2, 137, 44, 2, 150, 38, ...             23  \n",
       "4     [560, 104, 2, 600, 108, 2, 595, 112, 2, 639, 1...             23  \n",
       "...                                                 ...            ...  \n",
       "1768  [500, 173, 2, 476, 187, 2, 476, 187, 2, 462, 1...             23  \n",
       "1769  [162, 421, 2, 193, 432, 2, 193, 432, 2, 220, 4...             23  \n",
       "1770  [481, 226, 2, 455, 249, 2, 455, 249, 2, 449, 2...             23  \n",
       "1771  [155, 599, 2, 191, 623, 0, 189, 623, 2, 205, 5...             23  \n",
       "1772  [639, 187, 2, 703, 210, 2, 703, 215, 2, 731, 1...             23  \n",
       "\n",
       "[1773 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_BirdIndividualID.train_dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine raptors and BirdIndividualID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_raptors = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_raptors_split.csv')\n",
    "cache_birdIndividual = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_BirdIndividualID_split.csv')\n",
    "\n",
    "cache_raptors['wildlife_name'] = 'raptors'\n",
    "cache_raptors['path'] = cache_raptors['path'].apply(lambda x: os.path.join('raptor_individuals_cropped', x))\n",
    "cache_raptors['identity'] = 'raptors-' + cache_raptors['identity'].astype(str)\n",
    "\n",
    "cache_birdIndividual['wildlife_name'] = 'BirdIndividualID'\n",
    "cache_birdIndividual['path'] = cache_birdIndividual['path'].apply(lambda x: os.path.join('BirdIndividualID', x))\n",
    "cache_raptors['identity'] = 'BirdIndividualID-' + cache_raptors['identity'].astype(str)\n",
    "\n",
    "cache_allbirds = pd.concat([cache_raptors, cache_birdIndividual], ignore_index=True)\n",
    "cache_allbirds.to_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_allbirds_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>species</th>\n",
       "      <th>identity_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>from_video</th>\n",
       "      <th>video</th>\n",
       "      <th>date</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>keypoints</th>\n",
       "      <th>num_keypoints</th>\n",
       "      <th>orientation</th>\n",
       "      <th>query</th>\n",
       "      <th>metadata_split</th>\n",
       "      <th>wildlife_name</th>\n",
       "      <th>original_split</th>\n",
       "      <th>width.1</th>\n",
       "      <th>height.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>whteag</td>\n",
       "      <td>3.0</td>\n",
       "      <td>England_G274</td>\n",
       "      <td>raptor_individuals_cropped/whteag/England_G274...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>[[76.32499694824219, 33.875, 76.10311889648438...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>[26.625, 33.875, 103.171875, 49.256248474121094]</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[50, 59, 2, 51, 61, 2, 50, 62, 2, 49, 67, 2, 5...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>raptors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>whteag</td>\n",
       "      <td>3.0</td>\n",
       "      <td>England_G274</td>\n",
       "      <td>raptor_individuals_cropped/whteag/England_G274...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[[119.8062515258789, 32.32500076293945, 119.13...</td>\n",
       "      <td>431.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>[63.23749542236328, 32.32500076293945, 144.115...</td>\n",
       "      <td>28482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[130, 35, 2, 108, 48, 2, 111, 48, 2, 95, 51, 2...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>raptors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>whteag</td>\n",
       "      <td>3.0</td>\n",
       "      <td>England_G274</td>\n",
       "      <td>raptor_individuals_cropped/whteag/England_G274...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>[[96.40469360351562, 64.26875305175781, 95.046...</td>\n",
       "      <td>487.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>[55.67031478881836, 64.26875305175781, 609.657...</td>\n",
       "      <td>91127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[107, 73, 2, 89, 91, 2, 95, 91, 2, 59, 115, 2,...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>raptors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>whteag</td>\n",
       "      <td>3.0</td>\n",
       "      <td>England_G274</td>\n",
       "      <td>raptor_individuals_cropped/whteag/England_G274...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>[[331.3984375, 151.8125, 329.4375, 153.7734375...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>[298.0625, 151.8125, 672.6015625, 513.765625]</td>\n",
       "      <td>98606.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[637, 371, 2, 643, 377, 2, 637, 377, 2, 637, 3...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>raptors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>whteag</td>\n",
       "      <td>3.0</td>\n",
       "      <td>England_G274</td>\n",
       "      <td>raptor_individuals_cropped/whteag/England_G274...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>[[650.25, 414.0, 648.0, 416.25, 618.75, 416.25...</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>[495.0, 414.0, 472.5, 717.75]</td>\n",
       "      <td>206975.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[734, 425, 2, 678, 432, 2, 685, 432, 2, 594, 4...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>raptors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id species  identity_id      identity  \\\n",
       "0       26  whteag          3.0  England_G274   \n",
       "1       22  whteag          3.0  England_G274   \n",
       "2       28  whteag          3.0  England_G274   \n",
       "3       18  whteag          3.0  England_G274   \n",
       "4       40  whteag          3.0  England_G274   \n",
       "\n",
       "                                                path from_video  video  \\\n",
       "0  raptor_individuals_cropped/whteag/England_G274...      False    NaN   \n",
       "1  raptor_individuals_cropped/whteag/England_G274...      False    NaN   \n",
       "2  raptor_individuals_cropped/whteag/England_G274...      False    NaN   \n",
       "3  raptor_individuals_cropped/whteag/England_G274...      False    NaN   \n",
       "4  raptor_individuals_cropped/whteag/England_G274...      False    NaN   \n",
       "\n",
       "     date                                       segmentation  height   width  \\\n",
       "0  2020.0  [[76.32499694824219, 33.875, 76.10311889648438...   121.0   142.0   \n",
       "1  2021.0  [[119.8062515258789, 32.32500076293945, 119.13...   431.0   245.0   \n",
       "2  2020.0  [[96.40469360351562, 64.26875305175781, 95.046...   487.0   869.0   \n",
       "3  2020.0  [[331.3984375, 151.8125, 329.4375, 153.7734375...   837.0  1255.0   \n",
       "4  2022.0  [[650.25, 414.0, 648.0, 416.25, 618.75, 416.25...  1440.0  1440.0   \n",
       "\n",
       "                                                bbox      area  iscrowd  \\\n",
       "0   [26.625, 33.875, 103.171875, 49.256248474121094]    2238.0      0.0   \n",
       "1  [63.23749542236328, 32.32500076293945, 144.115...   28482.0      0.0   \n",
       "2  [55.67031478881836, 64.26875305175781, 609.657...   91127.0      0.0   \n",
       "3      [298.0625, 151.8125, 672.6015625, 513.765625]   98606.0      0.0   \n",
       "4                      [495.0, 414.0, 472.5, 717.75]  206975.0      0.0   \n",
       "\n",
       "                                           keypoints  num_keypoints  \\\n",
       "0  [50, 59, 2, 51, 61, 2, 50, 62, 2, 49, 67, 2, 5...           23.0   \n",
       "1  [130, 35, 2, 108, 48, 2, 111, 48, 2, 95, 51, 2...           23.0   \n",
       "2  [107, 73, 2, 89, 91, 2, 95, 91, 2, 59, 115, 2,...           23.0   \n",
       "3  [637, 371, 2, 643, 377, 2, 637, 377, 2, 637, 3...           23.0   \n",
       "4  [734, 425, 2, 678, 432, 2, 685, 432, 2, 594, 4...           23.0   \n",
       "\n",
       "   orientation  query metadata_split wildlife_name original_split  width.1  \\\n",
       "0          NaN      0          train       raptors            NaN      NaN   \n",
       "1          NaN      0          train       raptors            NaN      NaN   \n",
       "2          NaN      0          train       raptors            NaN      NaN   \n",
       "3          NaN      0          train       raptors            NaN      NaN   \n",
       "4          NaN      0          train       raptors            NaN      NaN   \n",
       "\n",
       "   height.1  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe\n",
    "pd.set_option(\"display.max_columns\",300)\n",
    "cache_allbirds = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_allbirds_split.csv')\n",
    "cache_allbirds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run dataloader for multispecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/Documents/code/master-thesis/EagleID/notebooks/../data/wildlife_dataset.py:328: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.metadata.loc[pd.isna(self.metadata['date']), 'date'] = \"unknown\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 2787\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 2155/632/0/2787\n",
      "Classes: train/test/unassigned/total = 109/93/0/109\n",
      "Classes: train only/test only/joint  = 16/0/93\n",
      "\n",
      "Fraction of train set     = 77.32%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 2155\n",
      "Number of individuals (classes): 109\n",
      "Mean images/individual: 19.770642201834864\n",
      "Min images/individual: 2\n",
      "Max images/individual: 74\n",
      "Test Set\n",
      "Length: 632\n",
      "Number of individuals (classes): 93\n",
      "Mean images per individual: 6.795698924731183\n",
      "Min images per individual: 1\n",
      "Max images per individual: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/Documents/code/master-thesis/EagleID/notebooks/../data/wildlife_dataset.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['query'] = df_test['query'].astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed data loaded from bbox_mask for train_raptors__BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 2155\n",
      "first 5 rows of metadata:\n",
      "           image_id           species  identity_id    identity  \\\n",
      "0  012a691860d0efb5  sociable_weavers          NaN  011016A9DF   \n",
      "1  05f4a08da3b5d7bb  sociable_weavers          NaN  011016A9DF   \n",
      "2  0be589a0a94d12c3  sociable_weavers          NaN  011016A9DF   \n",
      "3  14298ed789b2209a  sociable_weavers          NaN  011016A9DF   \n",
      "4  19d52f6706a25484  sociable_weavers          NaN  011016A9DF   \n",
      "\n",
      "                                                path from_video  video  date  \\\n",
      "0  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "1  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "2  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "3  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "4  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "\n",
      "                                        segmentation  height  ...  iscrowd  \\\n",
      "0  [[576, 240, 528, 240, 520, 244, 464, 316, 440,...   768.0  ...      NaN   \n",
      "1  [[192, 364, 204, 380, 232, 396, 244, 396, 296,...   768.0  ...      NaN   \n",
      "2  [[720, 260, 724, 276, 744, 296, 764, 304, 769,...   768.0  ...      NaN   \n",
      "3  [[168, 32, 116, 32, 100, 44, 96, 52, 96, 84, 8...   768.0  ...      NaN   \n",
      "4  [[544, 96, 528, 108, 512, 132, 512, 144, 500, ...   768.0  ...      NaN   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [563, 242, 2, 531, 249, 2, 587, 253, 2, 513, 2...           23.0   \n",
      "1  [375, 311, 2, 375, 346, 2, 373, 346, 2, 423, 3...           23.0   \n",
      "2  [920, 255, 2, 917, 285, 2, 915, 285, 2, 939, 3...           23.0   \n",
      "3  [117, 39, 2, 138, 43, 2, 137, 44, 2, 150, 38, ...           23.0   \n",
      "4  [560, 104, 2, 600, 108, 2, 595, 112, 2, 639, 1...           23.0   \n",
      "\n",
      "   orientation query  metadata_split     wildlife_name  original_split  \\\n",
      "0          NaN     0           train  BirdIndividualID           train   \n",
      "1          NaN     0           train  BirdIndividualID           train   \n",
      "2          NaN     0           train  BirdIndividualID           train   \n",
      "3          NaN     0           train  BirdIndividualID           train   \n",
      "4          NaN     0           train  BirdIndividualID           train   \n",
      "\n",
      "  width.1 height.1  \n",
      "0  1024.0    768.0  \n",
      "1  1024.0    768.0  \n",
      "2  1024.0    768.0  \n",
      "3  1024.0    768.0  \n",
      "4  1024.0    768.0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Precomputed data loaded from bbox_mask for query_raptors__BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 89\n",
      "first 5 rows of metadata:\n",
      "           image_id           species  identity_id    identity  \\\n",
      "0  05882ea0023ccd22  sociable_weavers          NaN  011016A9DF   \n",
      "1  15256a78161a711d  sociable_weavers          NaN  011016AAEE   \n",
      "2  008cb7cf80eaa283  sociable_weavers          NaN  011016B1FB   \n",
      "3  17ecd67ee98f984f  sociable_weavers          NaN  011016B484   \n",
      "4  66f7f2d4f07d6b60  sociable_weavers          NaN  011016B52D   \n",
      "\n",
      "                                                path from_video  video  date  \\\n",
      "0  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "1  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "2  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "3  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "4  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "\n",
      "                                        segmentation  height  ...  iscrowd  \\\n",
      "0  [[612.7999877929688, 179.1999969482422, 611.20...   768.0  ...      0.0   \n",
      "1  [[532, 176, 524, 181, 520, 192, 528, 224, 528,...   768.0  ...      NaN   \n",
      "2  [[1011.2000122070312, 550.4000244140625, 1009....   768.0  ...      0.0   \n",
      "3  [[468, 192, 452, 204, 448, 216, 448, 256, 452,...   768.0  ...      NaN   \n",
      "4  [[1020, 645, 1008, 640, 1000, 616, 964, 576, 8...   768.0  ...      NaN   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [651, 181, 2, 651, 194, 2, 651, 194, 2, 668, 2...           23.0   \n",
      "1  [585, 183, 2, 539, 199, 2, 539, 199, 2, 518, 1...           23.0   \n",
      "2  [932, 750, 0, 994, 715, 2, 992, 713, 2, 930, 7...           23.0   \n",
      "3  [483, 204, 2, 456, 267, 2, 614, 303, 2, 452, 2...           23.0   \n",
      "4  [963, 595, 2, 848, 611, 2, 949, 655, 2, 945, 6...           23.0   \n",
      "\n",
      "   orientation query  metadata_split     wildlife_name  original_split  \\\n",
      "0          NaN  True            test  BirdIndividualID           train   \n",
      "1          NaN  True            test  BirdIndividualID             val   \n",
      "2          NaN  True            test  BirdIndividualID           train   \n",
      "3          NaN  True            test  BirdIndividualID           train   \n",
      "4          NaN  True            test  BirdIndividualID             val   \n",
      "\n",
      "  width.1 height.1  \n",
      "0  1024.0    768.0  \n",
      "1  1024.0    768.0  \n",
      "2  1024.0    768.0  \n",
      "3  1024.0    768.0  \n",
      "4  1024.0    768.0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Precomputed data loaded from bbox_mask for gallery_raptors__BirdIndividualID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 543\n",
      "first 5 rows of metadata:\n",
      "           image_id           species  identity_id    identity  \\\n",
      "0  0aab098edc3e0d00  sociable_weavers          NaN  011016A9DF   \n",
      "1  196cf70a5d39d39d  sociable_weavers          NaN  011016A9DF   \n",
      "2  23a251d7458b0609  sociable_weavers          NaN  011016A9DF   \n",
      "3  379b64a12e0e8b2f  sociable_weavers          NaN  011016A9DF   \n",
      "4  439ab2330583830c  sociable_weavers          NaN  011016A9DF   \n",
      "\n",
      "                                                path from_video  video  date  \\\n",
      "0  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "1  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "2  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "3  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "4  BirdIndividualID/Original_pictures/IndividualI...        NaN    NaN   NaN   \n",
      "\n",
      "                                        segmentation  height  ...  iscrowd  \\\n",
      "0  [[36, 304, 32, 308, 32, 408, 44, 424, 48, 440,...   768.0  ...      NaN   \n",
      "1  [[565, 164, 568, 236, 560, 264, 544, 292, 544,...   768.0  ...      NaN   \n",
      "2  [[772, 144, 768, 152, 780, 164, 780, 184, 768,...   768.0  ...      NaN   \n",
      "3  [[208, 448, 176, 468, 160, 504, 160, 636, 176,...   768.0  ...      NaN   \n",
      "4  [[528, 196, 520, 192, 472, 192, 352, 340, 352,...   768.0  ...      NaN   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [50, 311, 2, 36, 319, 0, 145, 317, 0, 142, 317...           23.0   \n",
      "1  [611, 200, 2, 557, 189, 2, 557, 189, 2, 546, 1...           23.0   \n",
      "2  [804, 156, 2, 793, 158, 2, 791, 160, 2, 769, 1...           23.0   \n",
      "3  [237, 459, 2, 271, 487, 2, 271, 487, 2, 302, 4...           23.0   \n",
      "4  [513, 195, 2, 535, 208, 2, 535, 208, 2, 544, 2...           23.0   \n",
      "\n",
      "   orientation  query  metadata_split     wildlife_name  original_split  \\\n",
      "0          NaN  False            test  BirdIndividualID           train   \n",
      "1          NaN  False            test  BirdIndividualID           train   \n",
      "2          NaN  False            test  BirdIndividualID           train   \n",
      "3          NaN  False            test  BirdIndividualID             val   \n",
      "4          NaN  False            test  BirdIndividualID           train   \n",
      "\n",
      "  width.1 height.1  \n",
      "0  1024.0    768.0  \n",
      "1  1024.0    768.0  \n",
      "2  1024.0    768.0  \n",
      "3  1024.0    768.0  \n",
      "4  1024.0    768.0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Round 1 Query image_ids: ['81', '63', '6', '71', '74', '14', '42', '100', '104', '113', '124', '134', '162', '229', '255', '381', '149', '108', '144', '122', '209', '478', '288', '365', '340', '300', '503', '452', '419', '456', '395', '370', '460', '464', '475', '471', '432', '335', '223', '115', '274', '488', '342', '319', '323', '386', '281', '350', '309', '00239fb5101d581c', '00698098dd8a3954', '011f48d6ef9d1956', '018bdb032143d8d7', '01ba69d5bf44bce0', '034c0892d43e28a6', '0403d7270d5828f0', '0479ca29beea5f2b', '04f9932b9802771c', '055dd7918826bf4e', '06537194758bd439', '087b13613915c5dc', '090088ba575e2c2e', '0978f65499c17b73', '098f70d801b6959d', '099a10a96ef4101f', '0c73c770e2371c51', '0e7e289bda0eecc5', '0f2f90ae6aa889c3', '129b43c010863699', '1423631d6231c229', '15256a78161a711d', '174973ce7aa07523', '17ecd67ee98f984f', '1c1218aa4b50c674', '2246e1e76384545b', '2425e9d4374c0e5f', '25ba0843c3d63092', '2819f9f62729e850', '29cba2694192577d', '30e53e15cd78693c', '3508c4aa773dd569', '3e4e95d346065cef', '40fb9fd54fac155d', '66f7f2d4f07d6b60', '05882ea0023ccd22', '008cb7cf80eaa283', '02e33957a97af54c', '0522fada68872644', '07fecee35e61e376']\n",
      "Round 1 Gallery image_ids: ['32', '21', '46', '51', '50', '91', '88', '90', '66', '73', '75', '106', '109', '116', '115', '123', '133', '131', '150', '167', '165', '186', '8', '9', '284', '200', '206', '199', '205', '239', '245', '244', '226', '256', '386', '384', '101', '135', '145', '211', '222', '359', '479', '368', '344', '338', '337', '504', '279', '454', '430', '420', '457', '499', '316', '409', '403', '408', '373', '462', '466', '351', '476', '472', '322', '328', '391', '443', '512', '306', '231', '46', '216', '289', '303', '495', '293', '315', '02f070dad7cda6e5', '044f22c9aeea334a', '05189c57b6033108', '0746098d4d326b55', '0aab098edc3e0d00', '0c3203fb5abb8207', '0d85d5ae9c5b8695', '0dc16fc89de34ed4', '0e59811e5950100c', '0e98ff329f78f5dc', '0ebd0f8c89392e68', '1223cbce1fe14c19', '127a977937197177', '1283ea666d2a5884', '12cab36847a83f71', '13c8845a495dba99', '1592e8f45cca9b42', '1673b5015544f2d9', '16977c5acb9d0f5f', '17faed353848b522', '18400e851dfa0554', '18a09854dfc768c6', '18ab72a77c36551c', '196cf70a5d39d39d', '1b5fca0d8fd1e2ff', '1baabd8dc9e38348', '1bc72ab2404c04f6', '1be3b3f5fdb20217', '1c18eead36afaa58', '1cd64f2ef9c8794f', '1d1c0730b7c8194c', '1d63bebf2bf7db46', '1f37588ad8e83279', '1fad2acf3a8a6567', '1feff7a52424fb4b', '202ce0636b9b5306', '2101a2aa0ed62141', '2116e606c7ebe137', '219d4df03f6db30f', '2337ce0211de96a0', '2371cba35a53b2e2', '237e9fa1c72bdcec', '23a251d7458b0609', '23dcec7415fd1833', '249c65a88c53e84b', '25476378a6de5d67', '26eea6871abaebb4', '276ddc3d38f9227f', '277aaf1b1ca91879', '28192319608d8ab9', '286ef613008423a5', '289fe506d3016bf2', '28d7853fe9b6bbee', '29536436e0313d09', '29bf49e220826867', '29d0e6387dd8f25d', '2b680760c525d8d3', '2bfb83a4fcdea5cb', '2c6b1cb0b8bc6397', '2d95200fbe74bbbf', '2dc6db43084bbdf3', '2dccbc5be007025b', '2f65f53b6614ba63', '2fa0f764af20471c', '31d66c42d02af78a', '320742a94db60c22', '3253d532b2deeccd', '32cd442d6270a7f4', '3397f88d8b7e8e3d', '33f71541e05a3d24', '33f956a20aa7d09c', '3482d9e3684ca708', '35b6a952d22ba98e', '360e3e342a9cecaa', '36392d1df721eeda', '379b64a12e0e8b2f', '37bd6e17d30b60c4', '37de7727bfc97484', '37e067cfa2a2b620', '38468a066407c592', '38eb0218d7b1154d', '3a2303ef568a78a8', '3b2db441749a6122', '3c20f36f7359cdf6', '3c288654d0262dcf', '3c65aa38d3ab1c8d', '3cc802cce56df11f', '3ccde6882d4f1051', '3cf4b2356dfee7ff', '3de031e22ad72867', '3e3304e62af66e77', '3e77e9a15c05794c', '3eab5875f41ed762', '3ecadb3ef1ca5690', '3f6c6792842b4fe3', '3ff1635d5d255697', '400fa17a2abffe32', '4086101eca9d90a5', '40aa82c5b5e6099e', '412e54b0a8e790db', '4176dff5e36a8b5f', '41cb030e2b10e093', '42ce0c23fc557006', '43498074bfdcb253', '439ab2330583830c', '43f3f6cc0044aa2d', '44b6330c66e18835', '455f190c088fb232', '45d5f4e8d373562f', '45f2f3c8d4261ed2', '4ae2a60d0a3bdadb', '4b6bbf50d7cdef8d', '4b7f8c46b1338f5c', '4be193b96504b0ed', '4cba2be7843066e1', '4ce51b825c3cda3b', '4d37075c1b9f4d70', '4d3a7366599913a7', '4d5d4cb6f4c89e68', '4db2369b215b39e0', '4e2d40c96859cc0e', '4e6c8643124191fe', '4e9ab9fedf9885ad', '4ee99a3d45c77dea', '503cf6161ee4c9dc', '50a6cc71de68ae75', '50e9e201413bfa0d', '52361e3cffe3a3f5', '53bcec33e8b4b701', '5436fd0a733e983e', '5462fe3333f3999d', '574a729ddd4d0432', '57778e6e3d7e4383', '57a080f6756dc05a', '57f3f62147501756', '5878df96cfd22741', '58d71b248597b339', '59346b1afe36dc97', '5934f9120d7924b5', '59a8f1bbe95ef6f7', '59edae0958874fd8', '5a2219d818e8e79c', '5a868e81d9440687', '5ac23482f7c3aa01', '5b263f1d4861757b', '5b5b7981ef35b7e8', '5b6cdfae9f4375f6', '5b7bd69d74a91b1d', '5bee7a79f6b09f81', '5c0dc948b6c4054a', '5c7410dd297a83d2', '5d21b505158fb5ff', '5dd74751d4214494', '5e1760b82109e5d5', '5e2978f7319ee43c', '5eb02f2b511be31e', '5ec53bf51fa7a37b', '5f099a71a7d992a4', '5f6fa728eb474eb1', '5fb0fd305bbbd7a4', '5fea6b904933be7d', '60a34e48a4a3ffbb', '60fd5dd61e696fd2', '6132cb3a69279d6a', '613be371daf79c30', '61b597214f1b1f32', '620a130cf4b3e446', '623e4db522f9a1cc', '6271a64d7102b32c', '633e4a5318b1ea98', '6348bbfc9ad54a2f', '63e1e0ccd24aa244', '6451b4af0e40c169', '654ae96dc17a3c29', '65b2e810f6fd7e4b', '66100f45260ceb72', '663d918510fecf56', '67ef44d037d65109', '6817089230ba94d7', '683b10c12b8df7ea', '68505869c6d614c0', '68a10f28d3f1551b', '69d11afc859eddf9', '6a3f5aa4b6a39a26', '6bc34cc4cb8cbe46', '6ce19fa23d808b09', '6cfa85015fc029ab', '6dc67bc7149d51f0', '6e14726183e6e275', '6eeba97425f9e8ae', '6ef69b96946b8d67', '6fe706f18daf8476', '705af3623beb9895', '719c758773099b17', '71fd0e6445da386a', '72557a0e8fafb662', '7255823bfa0b5eab', '727a14cba78de4e4', '7383d91873c20848', '749c73fd4fcba788', '74c35cd1098621bf', '74e4ee51c5116b88', '74e56d4727f49634', '75280bf5679d7f8f', '75df02a3690d47d0', '76589e7284618285', '7666ba27570a59a8', '769e3ac711d30bff', '76b4f5ecc19f5705', '7702f8280c79ed04', '77544022dbd78714', '7789b50c222de273', '785a886da7dca71a', '78bf4dfda2ae02e8', '78e4870027a27dd4', '7a148a63d7ec94b0', '7a8f7c286a47cd7a', '7b34fdb945cb456b', '7c716704389f1e6c', '7ca2fe6dc6c0a426', '7d1bbf0e394d84cc', '7e67b9818cb30473', '7f85841cef4e6526', '7fcbbe70cea3a33f', '7fcef1db60d234fa', '803475590334d452', '80bcda76e8efa66f', '81dae5f82c221c43', '827e0d70a0aae16b', '83938a9a8d46c4f4', '849872c87d3ece1f', '8520095ddc4177ee', '85c2ff4b58453e96', '8646d23aad929a25', '865f6799ffed4a29', '86f44b70b907432b', '870a585967708f69', '87fff9200a4f370b', '8806f87f9c777db3', '884aaf7860ae8d84', '88501d3efe81c133', '8871c6dfa89dfcda', '894e002a788ece1f', '898147e6cda7fd05', '8990e6a54572e943', '8af081de786f789e', '8b327a2a38e2e5c0', '8b766a1c69e14cd3', '8b7a8710bcdc4680', '8bea851c26e058ac', '8c4282a0eb5528ba', '8d103ebedc8393a0', '8d512d275e184736', '8db547040f9282a3', '8eb8b713873e21ea', '8eca27eed6f4dc45', '8faa5b972396c72c', '8fc2c0144170064e', '90f4008f6a7d4699', '9124fa44f21dc1eb', '91598420f8c38c14', '918c4090c71089fe', '91c6e97e2d99404b', '92e6308a4914eb3c', '932952675a14dd74', '9456c5da21982c53', '94ab7b385718aae7', '952b8ef28b1c8d5c', '953f9c0cfff85f09', '955cb903e1c3127b', '95ae25e85eadfb76', '960c667ef28f3fd1', '96331b591461f98c', '96dc00d507f79ba7', '979b8fcd36e0951d', '98a894fe5999fd35', '993eb9a0cfcb1853', '99a1aac77314d559', '9a5c95beda948d4c', '9a9b13b5a1224cb9', '9b32e03bc063965a', '9bb0088796e91b8e', '9c5a113024a16275', '9cbbda3b0991fc4d', '9d26232ba5c10ba7', '9da6f0bd5782c01b', '9e8381fdfc1a8fd0', '9ef699fb57db7760', '9efed14bfa747d41', '9f102b27f0259db6', '9f9db4e1856b7f4f', '9fc741fb0ebc715e', 'a23eccc236a35d5d', 'a251bdfa071e1f8b', 'a5ed33145bc933fb', 'a627999577cbdc2d', 'a637d0022c77b19a', 'a686139dec908c62', 'a6a734078993a960', 'a7666a70c29829f6', 'a79f84a2d5161421', 'a806bff9038765cd', 'a810b1bf002716ea', 'a8b48d09c65476b8', 'aa48b38e781df24e', 'aab84f158f60d711', 'aac1dc333bbcea6c', 'ac7dad092e404b3d', 'acab191a177e137d', 'ace5156f66827e01', 'ad9d199da03b2034', 'ade5c64b9107ee44', 'ae377dcb4f9fb988', 'b11d1fa5e5746925', 'b195a587cd3f566e', 'b3b568d3373e8448', 'b3d7c59a37ccbc32', 'b3fa39771632916c', 'b48bb3bfee007b1b', 'b555d58da5b8e710', 'b5c562f2b456446b', 'b6017d5f38da3d92', 'b64d060f1c665bc1', 'b71d1f65ab20ee9b', 'b7a0ef40e6163c91', 'b86a87a47e56b9f2', 'b8b3757f3a960461', 'b96b2a22b0d2ab68', 'b9964f11b2452fc5', 'b9ef65e071796ed8', 'ba7221ebbf33b554', 'bb59567ff179c66f', 'bb5d1413985bc4ec', 'bb87aad099d6c087', 'bcda609492ace48a', 'bcf60fb8ac721335', 'bd8804809c033c89', 'bd9a010df3380a1f', 'bea6e360fbcb5e06', 'c0015cdbaf8550c1', 'c0171469e9cf9d3e', 'c04ea6bd37f6a90e', 'c103d5a6b8c71a1e', 'c18368c8961b7426', 'c196ad5fa87afb1d', 'c1ad519f36763141', 'c1b945612e993ae5', 'c24787cb63343c17', 'c3f11a65f52e108b', 'c46efc893402ced5', 'c49328438d4e86eb', 'c5bcd10e222f72cb', 'c63c02ef252a70e4', 'c65398e479ed0c66', 'c65858dcec433a77', 'c6c9a87aa5c6db81', 'c6d594357ddf0a86', 'c6f152f065e19b57', 'c7040235fafdc2e5', 'c70ffeab14da407e', 'c77854a6c03f4867', 'c88a414c531f655e', 'c88da21681dc2147', 'c98ff2f036c25a4c', 'ca3321b66228fadd', 'ca66891673ebf729', 'cabd288e21b82cf2', 'cae5e0b7906c100c', 'cb3fabd29600184a', 'cb93d4741c276867', 'cc36d5cc025fc692', 'cc3c7e517820fa53', 'cccc44dda0f895bd', 'cd59c21285bc5574', 'cdc8cbdd05cb55e1', 'cdc9243e20391187', 'ceb7c36e3e6c2ef9', 'cf661d92c947f492', 'd1e7229577dd72c3', 'd2a8fa5015c6205f', 'd4001cbefce06d11', 'd4c0ac9f3f13c655', 'd4c6df0c094fe7f2', 'd4fbf1284416eea1', 'd6343993bf3ed562', 'd637257d57f235c5', 'd7a76ec28bb0f4c6', 'd81dc02bb0e94546', 'd8a03ec80d9ee2c0', 'd93306c33b9d7da9', 'd943f7f75b29fbf7', 'd9f5842176c044f1', 'dc68b41abdfd0805', 'dcf1d11253521845', 'df4a83248fa25edb', 'df4b2e4dadfae3bd', 'dfa77c7deb3ccf5c', 'e096018fb051c741', 'e0d173a8deb3dc02', 'e12a74e55f222e62', 'e17e8ecaf0704fe9', 'e1a27abf6656d848', 'e2b3e4d0c9c78af9', 'e30f6caeaa9d7dda', 'e32adf1aa0f86567', 'e515a183caf446e9', 'e51fed6b31211809', 'e535253cb1b36dd6', 'e5e0e92717ab6957', 'e5ea6019a2eb77e7', 'e64d9a8ff0bfb70f', 'e6553fc1a1497c91', 'e68ccbd02baa7745', 'e7610f1641b3c751', 'e88f9e35234d80a4', 'e91e4d3477355dd4', 'e9ccef7068ac6fd0', 'e9de553c94f284b1', 'ea3b52787d83d6ac', 'ea45775ac06a78f7', 'eb16913d2114f772', 'eb30606f5fae439b', 'ebc838082a95e50d', 'ebe0ea5a6bd4af03', 'ebf0c28d2256e308', 'ec59b0632a621a66', 'ec67cff30d1c8aaf', 'ed3dc0ea512785ee', 'ed888d6c5788a3a2', 'ede199ee6ca108ab', 'ef560bdce88404fa', 'ef7abe7a12ec15a3', 'ef8941409bb40e81', 'ef8beed34ff38781', 'f06662e7f2d67ef0', 'f12396990168a55d', 'f21f001fb12412d8', 'f4a9fdb05d90caca', 'f4b6b69d50f08ace', 'f59987c72d8fb9ef', 'f5f72ad3ab3cf4c3', 'f70edbef5b2907be', 'f78d03cd7f6e571a', 'f88a41f9964daf8b', 'f8a19b50b0950051', 'f8a319638daee867', 'fa8c38dca4667d52', 'fabeed47c0f7ec65', 'fac7ced039f2ece4', 'fb564ff6617a76b7', 'fbd06a920cd988a7', 'fc94fec2a80f9c69', 'fd6057b073444fe7', 'fda411a9df6c8df2', 'fdce61a32bdd0534', 'fded388a6d68d82d', 'fdf410bdeb881eaa', 'fe07aeac69a71da4', 'fe4b7500329379f6', 'fe8a0b3943efca0d', 'fe8c4ff8b0fabd77', 'fe904f598a7a87b8', 'fec2c42a8a4584ca', 'fef4dfe56d578de9', 'ffe243034c7e749a']\n"
     ]
    }
   ],
   "source": [
    "data_allbirds = WildlifeDataModule(\n",
    "                            metadata=pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_allbirds_split.csv'),\n",
    "                            data_dir=root, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_allbirds_split.csv\", # METADATA SPLIT\n",
    "                            animal_cat=\"bird\", \n",
    "                            splitter ='metadata_split',  # METADATA SPLIT\n",
    "                            only_cache=True,\n",
    "                            wildlife_names='raptors, BirdIndividualID',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query dataset length: 89\n",
      "Gallery dataset length: 543\n",
      "Query labels: [0 1 2 3 4]\n",
      "Gallery labels: [0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..1.8550389].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6225708].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.2914162].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4831371].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6051416].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.3437037].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4134204].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_images(train_dataloader, val_dataloader, num_images=4):\n",
    "    # Load a batch from the train and validation dataloaders\n",
    "    train_batch = next(iter(train_dataloader))  # Get a batch from train dataloader\n",
    "    val_batch = next(iter(val_dataloader))  # Get a batch from validation dataloader\n",
    "\n",
    "    # Assuming the batch contains images and labels, modify accordingly if the structure is different\n",
    "    train_images, train_labels = train_batch  # Change as per your data structure\n",
    "    val_images, val_labels = val_batch  # Change as per your data structure\n",
    "\n",
    "    # Setup plot\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 6))\n",
    "    \n",
    "    # Plot train images\n",
    "    for i in range(num_images):\n",
    "        ax = axes[0, i]\n",
    "        image = train_images[i].permute(1, 2, 0).numpy()  # Change this if needed for correct channels format\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"Train {train_labels[i]}\")\n",
    "        ax.axis('off')  # Hide axes\n",
    "    \n",
    "    # Plot validation images\n",
    "    for i in range(num_images):\n",
    "        ax = axes[1, i]\n",
    "        image = val_images[i].permute(1, 2, 0).numpy()  # Change this if needed for correct channels format\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"Val {val_labels[i]}\")\n",
    "        ax.axis('off')  # Hide axes\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "train_loader = data_allbirds.train_dataloader()\n",
    "val_loader = data_allbirds.val_dataloader()[0]  # Assuming we want the query loader\n",
    "visualize_images(train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whalesharks next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 2674\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: open-set\n",
      "Samples: train/test/unassigned/total = 2006/668/0/2674\n",
      "Classes: train/test/unassigned/total = 317/309/0/378\n",
      "Classes: train only/test only/joint  = 69/61/248\n",
      "\n",
      "Fraction of train set     = 75.02%\n",
      "Fraction of test set only = 2.28%\n",
      "Training Set\n",
      "Length: 2006\n",
      "Number of individuals (classes): 317\n",
      "Mean images/individual: 6.3280757097791795\n",
      "Min images/individual: 2\n",
      "Max images/individual: 59\n",
      "Test Set\n",
      "Length: 668\n",
      "Number of individuals (classes): 309\n",
      "Mean images per individual: 2.161812297734628\n",
      "Min images per individual: 1\n",
      "Max images per individual: 9\n",
      "Starting precomputation for bbox_mask (2006 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/Documents/code/master-thesis/EagleID/notebooks/../data/wildlife_dataset.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['query'] = df_test['query'].astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mask cache from ../dataset/data_cache/train_whaleshark_mask.npz: Masks count: 2006\n",
      "Loaded primary cache from ../dataset/data_cache/train_whaleshark_mask.npz: Mask: 2006\n",
      "Precomputed data loaded from bbox_mask for train_whaleshark. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 2006\n",
      "first 5 rows of metadata:\n",
      "   image_id                              identity  \\\n",
      "0       895  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "1      2072  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "2      2270  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "3      3887  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "4      4729  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "\n",
      "                                                path  \\\n",
      "0  whaleshark.coco/images/train2020/000000000896.jpg   \n",
      "1  whaleshark.coco/images/train2020/000000002073.jpg   \n",
      "2  whaleshark.coco/images/train2020/000000002271.jpg   \n",
      "3  whaleshark.coco/images/train2020/000000003888.jpg   \n",
      "4  whaleshark.coco/images/train2020/000000004730.jpg   \n",
      "\n",
      "                                                bbox                 date  \\\n",
      "0  [408.3250045776367, 730.2375030517578, 2582.52...              unknown   \n",
      "1  [30.131250381469727, 619.3062591552734, 2197.4...              unknown   \n",
      "2  [18.725000381469727, 361.5249938964844, 2972.5...              unknown   \n",
      "3  [1691.0625, 594.2812485694885, 951.3203125, 10...  2016-06-20 12:10:48   \n",
      "4  [37.28750228881836, 255.40625762939453, 2903.7...  2016-06-18 11:48:14   \n",
      "\n",
      "  orientation                                       segmentation  height  \\\n",
      "0        left  [[1515.1234130859375, 730.2375030517578, 1510....  2020.0   \n",
      "1       right  [[1973.17822265625, 619.3062591552734, 1969.64...  2250.0   \n",
      "2        left  [[2822.793701171875, 361.5249938964844, 2818.1...  2408.0   \n",
      "3        left  [[1694.6796875, 594.2812485694885, 1691.0625, ...  1871.0   \n",
      "4        left  [[1980.8984375, 255.40625762939453, 1976.23754...  1567.0   \n",
      "\n",
      "    width       area  iscrowd  \\\n",
      "0  3000.0  2409237.0      0.0   \n",
      "1  3000.0  2151078.0      0.0   \n",
      "2  3000.0  4971498.0      0.0   \n",
      "3  3000.0    63634.0      0.0   \n",
      "4  3000.0  1202105.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [904, 815, 2, 2921, 1597, 0, 2921, 1597, 0, 47...           23.0   \n",
      "1  [1975, 730, 2, 2147, 816, 0, 2169, 795, 2, 221...           23.0   \n",
      "2  [396, 896, 0, 2102, 1474, 0, 1379, 693, 0, 123...           23.0   \n",
      "3  [1818, 611, 2, 1827, 649, 2, 1836, 649, 2, 173...           23.0   \n",
      "4  [291, 503, 2, 139, 579, 2, 114, 579, 2, 89, 55...           23.0   \n",
      "\n",
      "   identity_idx  query metadata_split  \n",
      "0           NaN      0          train  \n",
      "1           NaN      0          train  \n",
      "2           NaN      0          train  \n",
      "3           NaN      0          train  \n",
      "4           NaN      0          train  \n",
      "Starting precomputation for bbox_mask (228 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_whaleshark_mask.npz: Masks count: 228\n",
      "Loaded primary cache from ../dataset/data_cache/query_whaleshark_mask.npz: Mask: 228\n",
      "Precomputed data loaded from bbox_mask for query_whaleshark. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 228\n",
      "first 5 rows of metadata:\n",
      "   image_id                              identity  \\\n",
      "0      1119  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "1      6134  035fd7fd-70d7-8e73-43e3-b0fa0bdbbcc2   \n",
      "2       385  058c2047-cdb9-6ce8-8130-80e53f23622f   \n",
      "3      2948  07229899-48c9-ad8d-1fdf-58657f69dcab   \n",
      "4      1997  096eb7d9-82e3-d5a5-1116-42ddd304701e   \n",
      "\n",
      "                                                path  \\\n",
      "0  whaleshark.coco/images/train2020/000000001120.jpg   \n",
      "1  whaleshark.coco/images/train2020/000000006135.jpg   \n",
      "2  whaleshark.coco/images/train2020/000000000386.jpg   \n",
      "3  whaleshark.coco/images/train2020/000000002949.jpg   \n",
      "4  whaleshark.coco/images/train2020/000000001998.jpg   \n",
      "\n",
      "                                                bbox                 date  \\\n",
      "0  [80.80000019073486, 642.8000183105469, 2118.30...              unknown   \n",
      "1  [2240.159423828125, 527.3624992370605, 292.724...              unknown   \n",
      "2  [14.693750381469727, 465.5562515258789, 2277.5...  2016-05-03 12:06:27   \n",
      "3  [376.82500076293945, 111.39374542236328, 2414....              unknown   \n",
      "4  [280.7249984741211, 340.6000061035156, 2699.85...              unknown   \n",
      "\n",
      "  orientation                                       segmentation  height  \\\n",
      "0       right  [[774.25, 642.8000183105469, 770.800048828125,...  2400.0   \n",
      "1       right  [[2248.29052734375, 527.3624992370605, 2244.22...  2250.0   \n",
      "2       right  [[290.2015686035156, 465.5562515258789, 286.52...  2250.0   \n",
      "3        left  [[2410.784423828125, 111.39374542236328, 2406....  2250.0   \n",
      "4        left  [[978.8875122070312, 340.6000061035156, 974.46...  2250.0   \n",
      "\n",
      "    width       area  iscrowd  \\\n",
      "0  3000.0  1795337.0      0.0   \n",
      "1  3000.0     8281.0      0.0   \n",
      "2  3000.0  1334753.0      0.0   \n",
      "3  3000.0  2034552.0      0.0   \n",
      "4  3000.0  3205594.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  \\\n",
      "0  [1703, 788, 0, 2074, 829, 0, 2115, 932, 0, 215...           23.0   \n",
      "1  [2270, 554, 0, 2478, 582, 0, 2478, 579, 0, 252...           23.0   \n",
      "2  [2008, 874, 2, 2208, 941, 2, 2208, 963, 2, 225...           23.0   \n",
      "3  [2272, 321, 2, 2413, 345, 2, 2413, 345, 0, 445...           23.0   \n",
      "4  [2875, 781, 2, 495, 337, 0, 3006, 1278, 0, 312...           23.0   \n",
      "\n",
      "   identity_idx  query metadata_split  \n",
      "0           NaN   True           test  \n",
      "1           NaN   True           test  \n",
      "2           NaN   True           test  \n",
      "3           5.0   True           test  \n",
      "4           NaN   True           test  \n",
      "Starting precomputation for bbox_mask (440 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_whaleshark_mask.npz: Masks count: 440\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_whaleshark_mask.npz: Mask: 440\n",
      "Precomputed data loaded from bbox_mask for gallery_whaleshark. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 440\n",
      "first 5 rows of metadata:\n",
      "   image_id                              identity  \\\n",
      "0      3694  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "1      4689  016d6422-fab0-b809-90f6-e8ad20d8c9d8   \n",
      "2      6806  035fd7fd-70d7-8e73-43e3-b0fa0bdbbcc2   \n",
      "3      2619  053ccacf-2ac3-ce3b-5c55-59a7756bc059   \n",
      "4      1608  058c2047-cdb9-6ce8-8130-80e53f23622f   \n",
      "\n",
      "                                                path  \\\n",
      "0  whaleshark.coco/images/train2020/000000003695.jpg   \n",
      "1  whaleshark.coco/images/train2020/000000004690.jpg   \n",
      "2  whaleshark.coco/images/train2020/000000006807.jpg   \n",
      "3  whaleshark.coco/images/train2020/000000002620.jpg   \n",
      "4  whaleshark.coco/images/train2020/000000001609.jpg   \n",
      "\n",
      "                                                bbox     date orientation  \\\n",
      "0  [1239.65625, 637.625, 449.53118896484375, 1420...  unknown        back   \n",
      "1  [650.5125007629395, 452.2750015258789, 1509.71...  unknown       right   \n",
      "2  [593.9000015258789, 427.3000030517578, 2398.17...  unknown        left   \n",
      "3  [264.29999923706055, 683.0062561035156, 2386.8...  unknown       right   \n",
      "4  [757.3000030517578, 468.75, 2237.062545776367,...  unknown        left   \n",
      "\n",
      "                                        segmentation  height   width  \\\n",
      "0  [[1646.5311889648438, 637.625, 1643.2499389648...  2252.0  3000.0   \n",
      "1  [[657.9312515258789, 452.2750015258789, 650.51...  2252.0  3000.0   \n",
      "2  [[813.6999816894531, 427.3000030517578, 809.77...  2250.0  3000.0   \n",
      "3  [[1643.5499267578125, 683.0062561035156, 1639....  2250.0  3000.0   \n",
      "4  [[1226.5375366210938, 468.75, 1222.90002441406...  2250.0  3000.0   \n",
      "\n",
      "        area  iscrowd                                          keypoints  \\\n",
      "0   195187.0      0.0  [1567, 757, 2, 1622, 743, 2, 1609, 743, 2, 163...   \n",
      "1   609048.0      0.0  [1442, 857, 0, 1720, 1223, 0, 1647, 1106, 0, 1...   \n",
      "2  1259463.0      0.0  [820, 476, 0, 656, 500, 0, 656, 500, 0, 2904, ...   \n",
      "3   841370.0      0.0  [2307, 1017, 2, 2354, 1064, 2, 2354, 1064, 2, ...   \n",
      "4  1776045.0      0.0  [1165, 581, 2, 947, 647, 0, 925, 625, 0, 772, ...   \n",
      "\n",
      "   num_keypoints  identity_idx  query metadata_split  \n",
      "0           23.0           NaN  False           test  \n",
      "1           23.0           0.0  False           test  \n",
      "2           23.0           NaN  False           test  \n",
      "3           23.0           NaN  False           test  \n",
      "4           23.0           NaN  False           test  \n",
      "Round 1 Query image_ids: [1119, 6134, 385, 1997, 1020, 1866, 4223, 2524, 954, 58, 5503, 39, 4552, 3382, 2107, 1950, 4414, 3077, 502, 4562, 515, 4558, 618, 2651, 962, 3401, 3966, 774, 7251, 437, 1300, 2549, 3459, 2486, 1267, 2078, 3814, 399, 2400, 2533, 268, 866, 1675, 1084, 604, 1146, 386, 4758, 3241, 1334, 2509, 5410, 3507, 916, 184, 537, 1525, 2048, 1994, 1250, 750, 1791, 119, 3668, 3690, 4876, 2660, 2277, 2970, 2914, 6293, 1060, 600, 2188, 1912, 226, 3406, 2100, 299, 3381, 4604, 2238, 348, 1836, 667, 2411, 508, 2022, 1981, 2646, 2598, 1491, 5198, 122, 5460, 3864, 3455, 2579, 4157, 170, 3060, 5365, 833, 992, 3600, 5933, 2362, 3532, 2019, 112, 797, 1075, 1330, 1180, 1241, 4339, 1266, 1615, 2256, 1014, 3470, 4435, 2117, 6592, 1520, 773, 456, 2457, 4217, 1265, 2773, 5360, 5021, 1035, 941, 493, 637, 3834, 752, 505, 2893, 6248, 133, 1112, 2187, 1857, 859, 5442, 1899, 1837, 483, 6609, 81, 218, 1576, 2521, 304, 281, 407, 2570, 5812, 3687, 1260, 512, 1152, 1421, 1494, 1340, 134, 1022, 4490, 1741, 1365, 103, 193, 3922, 1071, 1758, 4169, 1649, 419, 199, 1584, 6845, 5110, 5106, 82, 1204, 2756, 4855, 2948, 3540, 1953, 3604, 732, 1163, 517, 4544, 4734, 5702, 1343, 4032, 4097, 114, 4150, 4059, 180, 4808, 171, 842, 2662, 1557, 241, 311, 1578, 3524, 2435, 1231, 940, 2737, 266, 2691, 3153, 288, 129, 372, 879, 6325]\n",
      "Round 1 Gallery image_ids: [3694, 6806, 2619, 6928, 1608, 2127, 2654, 6599, 5125, 3197, 7040, 1840, 6975, 1959, 3496, 6497, 5948, 4942, 5663, 3145, 6692, 2168, 1108, 830, 7143, 4290, 3876, 6279, 5180, 6675, 4006, 6741, 5280, 4915, 7305, 5299, 4023, 2839, 5422, 5100, 5089, 4610, 7089, 4270, 2594, 1401, 4742, 6132, 2778, 6220, 3608, 2784, 4807, 6509, 4140, 7314, 1345, 2244, 4881, 2625, 7415, 7330, 5146, 6044, 5974, 6299, 2794, 3652, 3104, 2206, 3917, 2793, 2419, 1693, 891, 1383, 4578, 620, 3662, 3333, 1410, 2140, 2449, 7295, 874, 1213, 1008, 6157, 2393, 4859, 3265, 3818, 7592, 4809, 4521, 7621, 6902, 2123, 2888, 7470, 6320, 6068, 3175, 4825, 1673, 1271, 4458, 5546, 4462, 2216, 2564, 6330, 6130, 1010, 3961, 2108, 5529, 4183, 6289, 5316, 7279, 7269, 2567, 2796, 7073, 7026, 5115, 6143, 2656, 6645, 7552, 7437, 5134, 3549, 1717, 4306, 4638, 6882, 5617, 7178, 6528, 3831, 4889, 3503, 5821, 3685, 3147, 4158, 6446, 7640, 420, 7466, 4149, 2648, 6386, 5743, 4646, 7015, 2883, 4545, 5440, 2588, 4363, 1392, 745, 3280, 2724, 6789, 6865, 4025, 1093, 4560, 4230, 3918, 7011, 6803, 756, 7622, 2444, 3905, 3704, 3415, 4254, 7321, 5622, 5409, 3623, 3105, 3994, 6297, 7547, 2042, 5011, 6249, 3692, 6739, 2170, 6839, 3937, 2291, 3155, 6570, 5516, 5264, 6930, 1568, 3632, 4269, 3539, 911, 5342, 7366, 7315, 3650, 3395, 4709, 3645, 6003, 7506, 2145, 3719, 7352, 7425, 3817, 2060, 3062, 4947, 5415, 1043, 871, 6419, 3725, 5537, 7336, 5023, 3520, 7051, 6615, 1400, 5649, 5551, 6165, 1501, 3897, 6685, 5607, 5433, 7620, 5637, 5828, 1492, 4834, 3911, 2604, 2421, 5972, 1659, 6552, 725, 3143, 4484, 5945, 3878, 3220, 3923, 1672, 2837, 6795, 2461, 6465, 6858, 3001, 6585, 6219, 7247, 5429, 3657, 5880, 4799, 867, 7462, 4907, 5707, 6477, 3774, 4165, 4575, 4588, 5609, 6990, 3967, 5772, 5860, 5698, 2339, 7372, 6773, 7648, 5944, 6542, 2535, 2329, 5150, 4866, 3726, 7009, 7361, 6600, 4090, 3772, 3036, 5051, 4788, 2652, 2974, 1436, 6932, 3902, 1350, 6027, 4827, 5818, 5562, 4689, 1276, 7663, 6872, 4542, 4241, 7453, 6922, 3921, 7496, 5716, 3570, 4226, 3100, 7523, 3187, 4877, 1264, 6966, 2062, 5873, 5578, 1478, 5070, 5728, 3924, 7412, 6699, 5513, 7118, 4710, 327, 6172, 1019, 6876, 5288, 1645, 4507, 3671, 4755, 6805, 7641, 901, 4563, 4853, 7299, 6309, 4759, 2422, 141, 5435, 4708, 6224, 5159, 3792, 3543, 7048, 404, 7297, 4821, 5634, 6322, 4170, 2313, 4875, 4561, 1232, 4077, 4185, 6032, 480, 579, 7261, 2998, 3309, 6682, 3484, 3669, 6783, 5864, 6690, 2293, 2815, 1908, 5040, 242, 7534, 271, 1684, 6110, 2503, 5736, 7568, 6103, 1126, 2889, 331, 4846, 5693, 7686, 2428, 7558, 1987, 6613, 6128, 4745, 5580, 3670, 3948, 3361, 6936, 7469, 2867, 582, 3790, 4167, 1682]\n"
     ]
    }
   ],
   "source": [
    "path_whaleshark = os.path.join(root, 'EDA-whaleshark')\n",
    "dataset_whaleshark = datasets.WhaleSharkID(path_whaleshark)\n",
    "\n",
    "data_whaleshark = WildlifeDataModule(\n",
    "                            metadata=dataset_whaleshark.df,\n",
    "                            data_dir=path_whaleshark, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_EDAwhaleshark_split.csv\",\n",
    "                            animal_cat=\"fish\", \n",
    "                            splitter ='metadata_split', \n",
    "                            only_cache=True,\n",
    "                            wildlife_names='whaleshark',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 6102\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 2026/631/3445/6102\n",
      "Classes: train/test/unassigned/total = 82/82/1/83\n",
      "Classes: train only/test only/joint  = 0/0/82\n",
      "\n",
      "Fraction of train set     = 76.25%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 2026\n",
      "Number of individuals (classes): 82\n",
      "Mean images/individual: 24.70731707317073\n",
      "Min images/individual: 5\n",
      "Max images/individual: 88\n",
      "Test Set\n",
      "Length: 631\n",
      "Number of individuals (classes): 82\n",
      "Mean images per individual: 7.695121951219512\n",
      "Min images per individual: 3\n",
      "Max images per individual: 23\n",
      "Starting precomputation for bbox_mask (2026 images)...\n",
      "Mask crop mismatch! Expected (538, 848), got (538, 846)\n",
      "Mask crop mismatch! Expected (876, 1274), got (876, 1272)\n",
      "Mask crop mismatch! Expected (401, 534), got (401, 532)\n",
      "Mask crop mismatch! Expected (621, 731), got (621, 729)\n",
      "Mask crop mismatch! Expected (698, 1359), got (698, 1357)\n",
      "Mask crop mismatch! Expected (310, 399), got (310, 397)\n",
      "Mask crop mismatch! Expected (351, 655), got (351, 653)\n",
      "Mask crop mismatch! Expected (626, 974), got (626, 972)\n",
      "Mask crop mismatch! Expected (710, 1483), got (710, 1481)\n",
      "Mask crop mismatch! Expected (743, 1343), got (743, 1340)\n",
      "Mask crop mismatch! Expected (995, 1684), got (995, 1682)\n",
      "Mask crop mismatch! Expected (818, 1256), got (818, 1254)\n",
      "Mask crop mismatch! Expected (1077, 1162), got (1075, 1162)\n",
      "Mask crop mismatch! Expected (715, 969), got (715, 967)\n",
      "Loaded mask cache from ../dataset/data_cache/train_NDD20_mask.npz: Masks count: 1989\n",
      "Loaded primary cache from ../dataset/data_cache/train_NDD20_mask.npz: Mask: 1989\n",
      "Precomputed data loaded from bbox_mask for train_NDD20. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 2026\n",
      "first 5 rows of metadata:\n",
      "   image_id identity            path orientation  \\\n",
      "0      1288        1   ABOVE/526.jpg       above   \n",
      "1      1289        1   ABOVE/926.jpg       above   \n",
      "2      1292        1  ABOVE/1161.jpg       above   \n",
      "3      1295        1   ABOVE/984.jpg       above   \n",
      "4      1301        1  ABOVE/1876.jpg       above   \n",
      "\n",
      "                                        segmentation species out_of_focus  \\\n",
      "0  [[1841.0, 2508.0, 1962.0, 2355.0, 2108.0, 2102...     WBD          NaN   \n",
      "1  [[1663.0, 2220.0, 1784.0, 2072.0, 1902.0, 1927...     WBD          NaN   \n",
      "2  [[2582.0, 2105.0, 2629.0, 2023.0, 2670.0, 1937...     WBD          NaN   \n",
      "3  [[1288.0, 1754.0, 1401.0, 1767.0, 1478.0, 1770...     WBD          NaN   \n",
      "4  [[1828.0, 2954.0, 2134.0, 2863.0, 2505.0, 2772...     WBD          NaN   \n",
      "\n",
      "                               bbox  width  height  \n",
      "0  [1781.0, 1194.0, 3129.0, 1624.0]   5184    3456  \n",
      "1    [1663.0, 1658.0, 760.0, 746.0]   5184    3456  \n",
      "2    [2580.0, 1811.0, 280.0, 335.0]   5184    3456  \n",
      "3   [1288.0, 1250.0, 1581.0, 804.0]   5184    3456  \n",
      "4  [1533.0, 1800.0, 2040.0, 1300.0]   5184    3456  \n",
      "Starting precomputation for bbox_mask (82 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_NDD20_mask.npz: Masks count: 82\n",
      "Loaded primary cache from ../dataset/data_cache/query_NDD20_mask.npz: Mask: 82\n",
      "Precomputed data loaded from bbox_mask for query_NDD20. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 82\n",
      "first 5 rows of metadata:\n",
      "   image_id identity            path orientation  \\\n",
      "0      1291        1  ABOVE/1425.jpg       above   \n",
      "1      3603       10  BELOW/1515.jpg       below   \n",
      "2      1298       11   ABOVE/566.jpg       above   \n",
      "3      2983       12  BELOW/2145.jpg       below   \n",
      "4        63       13  ABOVE/1336.jpg       above   \n",
      "\n",
      "                                        segmentation species out_of_focus  \\\n",
      "0  [[2882.0, 2429.0, 2975.0, 2316.0, 3068.0, 2163...     WBD          NaN   \n",
      "1  [[1090.0, 849.0, 1136.0, 829.0, 1167.0, 816.0,...     WBD        False   \n",
      "2  [[429.0, 2271.0, 614.0, 2266.0, 837.0, 2258.0,...     WBD          NaN   \n",
      "3  [[1430.0, 358.0, 1397.0, 352.0, 1351.0, 349.0,...     WBD        False   \n",
      "4  [[479.0, 2899.0, 674.0, 2860.0, 831.0, 2866.0,...     WBD          NaN   \n",
      "\n",
      "                              bbox  width  height  query  \n",
      "0   [2879.0, 1905.0, 999.0, 595.0]   5184    3456   True  \n",
      "1     [941.0, 799.0, 410.0, 278.0]   1920    1080   True  \n",
      "2  [429.0, 1511.0, 2280.0, 1281.0]   5184    3456   True  \n",
      "3    [1044.0, 168.0, 386.0, 274.0]   1920    1080   True  \n",
      "4     [330.0, 8.0, 1966.0, 2913.0]   5184    3456   True  \n",
      "Starting precomputation for bbox_mask (549 images)...\n",
      "Mask crop mismatch! Expected (545, 1141), got (545, 1139)\n",
      "Mask crop mismatch! Expected (512, 1044), got (512, 1042)\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_NDD20_mask.npz: Masks count: 547\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_NDD20_mask.npz: Mask: 547\n",
      "Precomputed data loaded from bbox_mask for gallery_NDD20. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 549\n",
      "first 5 rows of metadata:\n",
      "   image_id identity            path orientation  \\\n",
      "0      1310        1   ABOVE/863.jpg       above   \n",
      "1      4140        1   BELOW/269.jpg       below   \n",
      "2      4146        1  BELOW/1262.jpg       below   \n",
      "3      4153        1  BELOW/1008.jpg       below   \n",
      "4      4791        1  BELOW/1803.jpg       below   \n",
      "\n",
      "                                        segmentation species out_of_focus  \\\n",
      "0  [[1492.0, 2230.0, 1911.0, 2183.0, 2337.0, 2150...     WBD          NaN   \n",
      "1  [[3.0, 645.0, 63.0, 604.0, 142.0, 561.0, 202.0...     WBD        False   \n",
      "2  [[3.0, 647.0, 71.0, 658.0, 115.0, 658.0, 217.0...     WBD        False   \n",
      "3  [[990.0, 669.0, 914.0, 669.0, 848.0, 677.0, 80...     WBD        False   \n",
      "4  [[2.0, 802.0, 117.0, 770.0, 307.0, 667.0, 371....     WBD        False   \n",
      "\n",
      "                               bbox  width  height  query  \n",
      "0  [1492.0, 1277.0, 2500.0, 1173.0]   5184    3456  False  \n",
      "1        [3.0, 440.0, 641.0, 363.0]   1920    1080  False  \n",
      "2       [3.0, 474.0, 1025.0, 458.0]   1920    1080  False  \n",
      "3     [628.0, 561.0, 1240.0, 458.0]   1920    1080  False  \n",
      "4       [2.0, 504.0, 1020.0, 449.0]   1920    1080  False  \n",
      "Round 1 Query image_ids: [1291, 3603, 1298, 2983, 63, 1151, 282, 1375, 1933, 2400, 2495, 449, 3275, 2488, 1294, 2670, 2458, 1771, 1198, 2797, 1376, 225, 688, 3303, 2564, 681, 809, 1629, 3325, 655, 784, 4134, 709, 1225, 3515, 3211, 273, 2616, 666, 3540, 3812, 3816, 3543, 3156, 3478, 2945, 3184, 3344, 3440, 4008, 3002, 4830, 5023, 4622, 4794, 3644, 3914, 3105, 3128, 4131, 3082, 5378, 3080, 3665, 3196, 3629, 2751, 3572, 3011, 5141, 3241, 2970, 3804, 3178, 4465, 3039, 3335, 1548, 3018, 3243, 3072, 1986]\n",
      "Round 1 Gallery image_ids: [4140, 1310, 6045, 6049, 4153, 4943, 4146, 4791, 4793, 5522, 3622, 4239, 3364, 5765, 1299, 1346, 4605, 5124, 3968, 5799, 1352, 5791, 4604, 1332, 4600, 1336, 4528, 3284, 5894, 1325, 5789, 4603, 1328, 5889, 3625, 5500, 3609, 5519, 4235, 5515, 3620, 2993, 5505, 3619, 5497, 3624, 5517, 3328, 3931, 5859, 5855, 5083, 5084, 4569, 3941, 5538, 2201, 1207, 1209, 2175, 5539, 1507, 1208, 5410, 5588, 3056, 5571, 3061, 3691, 4335, 3053, 5589, 5413, 453, 4338, 4319, 4316, 4092, 4727, 4899, 5994, 4888, 3473, 3457, 4895, 2053, 4733, 5997, 4093, 4721, 4890, 5984, 6011, 5587, 5401, 5303, 3742, 2485, 4390, 3739, 5733, 3236, 3137, 3738, 3219, 2514, 2679, 3431, 4036, 3308, 3920, 5854, 3309, 5851, 5879, 1082, 5068, 4581, 5089, 3307, 5800, 5782, 3872, 3881, 5014, 4997, 4996, 5803, 5794, 5696, 3199, 5689, 3781, 3800, 3421, 4283, 1344, 5373, 3587, 5555, 5480, 3034, 3037, 2939, 3394, 4629, 2753, 5155, 3987, 5926, 5914, 5908, 2726, 3996, 3108, 3591, 2475, 5473, 3558, 1935, 4835, 1955, 1858, 4523, 2190, 5772, 4502, 4504, 4994, 4498, 3267, 3317, 4571, 5075, 5862, 3935, 5347, 5524, 1381, 4247, 1884, 1882, 5349, 1443, 1474, 4252, 4771, 1432, 4764, 4923, 1754, 6023, 3487, 1424, 818, 4022, 826, 689, 3400, 3404, 4553, 5844, 4120, 5836, 3305, 4915, 4548, 5954, 4962, 3436, 5947, 4860, 3434, 5946, 5949, 3438, 4862, 4052, 4054, 6056, 4165, 3510, 3026, 2270, 5549, 2316, 1723, 1644, 2322, 2321, 5768, 3784, 3946, 5872, 4574, 3773, 5172, 3423, 5939, 3424, 5938, 3444, 4069, 4700, 4874, 4941, 4942, 4772, 4138, 6037, 4787, 4779, 4785, 4137, 4777, 4936, 4939, 729, 3986, 5132, 3981, 5903, 3984, 5906, 2962, 2966, 3606, 3608, 1538, 1482, 1525, 5452, 4797, 4957, 6068, 6064, 4896, 6003, 3808, 4718, 5987, 4741, 3468, 3459, 4094, 3462, 3703, 3704, 5178, 2721, 3961, 3343, 3974, 3960, 5645, 3172, 3751, 3166, 831, 4810, 4827, 4807, 4965, 4180, 5709, 5705, 4441, 5708, 5293, 4452, 4397, 5649, 4392, 5291, 6076, 4819, 4188, 3162, 5651, 5662, 3771, 4595, 5944, 4677, 4043, 3955, 4859, 5232, 3750, 4675, 5233, 4858, 5256, 5657, 5262, 3157, 4115, 4750, 4751, 4903, 6017, 5477, 5445, 5439, 2949, 5679, 5258, 3766, 5886, 3368, 3536, 4584, 4808, 3351, 3956, 4606, 6083, 5128, 4814, 4712, 4060, 4867, 5978, 5960, 4684, 4875, 5965, 4881, 4698, 4059, 5917, 5139, 4639, 5920, 5531, 5532, 3637, 6091, 4836, 6094, 5780, 5327, 5764, 5146, 4623, 4640, 4631, 4948, 6052, 5752, 5353, 5356, 5308, 3850, 4536, 4537, 5832, 5822, 3727, 3109, 5623, 3715, 5635, 4389, 3107, 5184, 5179, 3720, 5206, 4384, 3722, 5621, 5197, 5191, 4930, 6040, 4781, 4929, 3101, 3102, 3087, 5417, 3091, 4351, 5386, 5384, 3104, 5415, 4214, 5176, 5581, 4318, 5392, 5313, 3209, 5686, 4424, 4421, 5270, 3225, 3249, 3248, 3775, 3245, 4426, 5523, 3634, 6093, 4202, 4190, 3570, 4975, 4979, 4195, 4199, 3567, 4193, 4210, 4988, 4989, 4204, 3581, 3578, 4254, 5351, 3012, 5918, 5156, 5150, 5316, 5747, 5620, 4376, 3731, 4387, 4388, 5201, 5617, 5212, 5214, 5189, 4436, 5282, 5701, 5697, 4439, 4432, 3765, 4411, 4410, 3179, 5304, 5323, 5309, 4485, 5380, 3660, 4287, 3044, 5928, 4658, 4023, 3952, 5869, 5927, 4757, 4752, 6019, 3485, 6022, 4755, 2326, 1559, 2484, 1788, 1863, 6021, 3480, 4273, 4279, 5367, 3648, 4472, 4660, 3893, 3837, 4025, 3896, 3411, 3897, 5933, 4661, 4533, 5813, 3903, 4475, 5746, 5395, 5582, 5397, 5040, 3291, 5041, 2030, 4534, 3295, 5828, 4543, 2093]\n"
     ]
    }
   ],
   "source": [
    "path_dolphins = os.path.join(root, 'NDD20')\n",
    "dataset_dolphins = datasets.NDD20v2(path_dolphins)\n",
    "\n",
    "data_whaleshark = WildlifeDataModule(\n",
    "                            metadata=dataset_dolphins.df,\n",
    "                            data_dir=path_dolphins, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_dolphins.csv\",\n",
    "                            animal_cat=\"fish\", \n",
    "                            splitter ='custom_closed', \n",
    "                            only_cache=True,\n",
    "                            wildlife_names='NDD20',\n",
    "                            precompute=True,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fliers\n",
    "cache_raptors = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_raptors_split.csv')\n",
    "cache_birdIndividual = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_BirdIndividualID_split.csv')\n",
    "cache_whaleshark = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_EDAwhaleshark_split.csv')\n",
    "cache_dolphin = pd.read_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_dolphins_split.csv')\n",
    "\n",
    "cache_raptors['wildlife_name'] = 'raptors'\n",
    "cache_raptors['path'] = cache_raptors['path'].apply(lambda x: os.path.join('raptor_individuals_cropped', x))\n",
    "cache_raptors['identity'] = 'raptors-' + cache_raptors['identity'].astype(str)\n",
    "\n",
    "cache_birdIndividual['wildlife_name'] = 'BirdIndividualID'\n",
    "cache_birdIndividual['path'] = cache_birdIndividual['path'].apply(lambda x: os.path.join('BirdIndividualID', x))\n",
    "cache_birdIndividual['identity'] = 'BirdIndividualID-' + cache_birdIndividual['identity'].astype(str)\n",
    "\n",
    "cache_whaleshark['wildlife_name'] = 'whaleshark'\n",
    "cache_whaleshark['path'] = cache_whaleshark['path'].apply(lambda x: os.path.join('EDA-whaleshark', x))\n",
    "cache_whaleshark['identity'] = 'whaleshark-' + cache_whaleshark['identity'].astype(str)\n",
    "\n",
    "cache_dolphin['wildlife_name'] = 'NDD20'\n",
    "cache_dolphin['path'] = cache_dolphin['path'].apply(lambda x: os.path.join('NDD20', x))\n",
    "cache_dolphin['identity'] = 'NDD20-' + cache_dolphin['identity'].astype(str)\n",
    "\n",
    "cache_multispecies = pd.concat([cache_raptors, cache_birdIndividual, cache_whaleshark], ignore_index=True)\n",
    "cache_multispecies.to_csv('/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_fliers_split.csv', index=False) # save with _split bc already split inidivdually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 2078\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 1647/431/0/2078\n",
      "Classes: train/test/unassigned/total = 274/272/0/274\n",
      "Classes: train only/test only/joint  = 2/0/272\n",
      "\n",
      "Fraction of train set     = 79.26%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 1647\n",
      "Number of individuals (classes): 274\n",
      "Mean images/individual: 6.010948905109489\n",
      "Min images/individual: 1\n",
      "Max images/individual: 18\n",
      "Test Set\n",
      "Length: 431\n",
      "Number of individuals (classes): 272\n",
      "Mean images per individual: 1.5845588235294117\n",
      "Min images per individual: 1\n",
      "Max images per individual: 4\n",
      "Starting precomputation for bbox_mask (1647 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/Documents/code/master-thesis/EagleID/notebooks/../data/wildlife_dataset.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['query'] = df_test['query'].astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mask cache from ../dataset/data_cache/train_ELPephant_mask.npz: Masks count: 1647\n",
      "Loaded primary cache from ../dataset/data_cache/train_ELPephant_mask.npz: Mask: 1647\n",
      "Precomputed data loaded from bbox_mask for train_ELPephant. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 1647\n",
      "first 5 rows of metadata:\n",
      "           image_id  identity  \\\n",
      "0  0f00d12884e9181a        15   \n",
      "1  28110992e7f47739        15   \n",
      "2  91cd99c83b041284        15   \n",
      "3  bcf1cc147d4fbd07        15   \n",
      "4  ea43e664b5146790        15   \n",
      "\n",
      "                                                path      date orientation  \\\n",
      "0         images/15_4th Tuskless VI left_Feb2009.jpg  2-1-2009        left   \n",
      "1      images/15_4th Tuskless VI right_March2003.jpg  3-1-2003       right   \n",
      "2              images/15_4th Tuskless VI_Aug2006.jpg  8-1-2006         NaN   \n",
      "3  images/15_4th Tuskless VI left side_18Jul2015.jpg  7-1-2015        left   \n",
      "4   images/15_4th Tuskless VI right head_16Jul15.jpg   unknown       right   \n",
      "\n",
      "  original_split                                       segmentation  height  \\\n",
      "0          train  [[807.2859497070312, 97.0062484741211, 805.350...   829.0   \n",
      "1          train  [[138.43124389648438, 19.0625, 136.92655944824...   640.0   \n",
      "2           test  [[330.96875, 5.950000286102295, 329.0218505859...  1071.0   \n",
      "3          train  [[1167.965576171875, 167.1750030517578, 1165.5...  1044.0   \n",
      "4          train  [[12.3203125, 9.47499942779541, 9.856249809265...  1044.0   \n",
      "\n",
      "    width                                               bbox      area  \\\n",
      "0  1239.0  [116.15625, 97.0062484741211, 1051.21411132812...  443603.0   \n",
      "1   963.0  [6.018750190734863, 19.0625, 856.1671628952026...  380712.0   \n",
      "2  1246.0  [147.96249389648438, 5.950000286102295, 1070.7...  660160.0   \n",
      "3  1577.0  [295.6875, 167.1750030517578, 1249.27966308593...  610320.0   \n",
      "4  1577.0  [9.856249809265137, 9.47499942779541, 1236.959...  955303.0   \n",
      "\n",
      "   iscrowd                                          keypoints  num_keypoints  \\\n",
      "0      0.0  [280, 222, 2, 250, 314, 2, 229, 304, 2, 199, 4...             23   \n",
      "1      0.0  [497, 116, 2, 613, 266, 2, 605, 266, 0, 588, 4...             23   \n",
      "2      0.0  [824, 310, 2, 980, 571, 2, 980, 560, 2, 1136, ...             23   \n",
      "3      0.0  [840, 332, 2, 791, 320, 2, 779, 332, 2, 718, 4...             23   \n",
      "4      0.0  [899, 194, 2, 610, 278, 2, 598, 254, 2, 1067, ...             23   \n",
      "\n",
      "   query metadata_split  \n",
      "0      0          train  \n",
      "1      0          train  \n",
      "2      0          train  \n",
      "3      0          train  \n",
      "4      0          train  \n",
      "Starting precomputation for bbox_mask (113 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_ELPephant_mask.npz: Masks count: 113\n",
      "Loaded primary cache from ../dataset/data_cache/query_ELPephant_mask.npz: Mask: 113\n",
      "Precomputed data loaded from bbox_mask for query_ELPephant. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 113\n",
      "first 5 rows of metadata:\n",
      "           image_id  identity                                       path  \\\n",
      "0  780310623986ddf2        15      images/15_4th Tuskless VI_Apr2003.jpg   \n",
      "1  91952b585994649d        28     images/28_Aaron right side_Nov2010.jpg   \n",
      "2  5918d60f560eaa7b        35          images/35_Malak right_Mar2010.jpg   \n",
      "3  28660d243d483044        42      images/42_Adar left head_8Aug2016.jpg   \n",
      "4  4d2e7923a0c08a3f       102  images/102_Ailanthie II right_Oct2004.jpg   \n",
      "\n",
      "        date orientation original_split  \\\n",
      "0   4-1-2003         NaN          train   \n",
      "1  11-1-2010       right          train   \n",
      "2   3-1-2010       right          train   \n",
      "3   8-1-2016        left           test   \n",
      "4  10-1-2004       right          train   \n",
      "\n",
      "                                        segmentation  height   width  \\\n",
      "0  [[7.5234375, 1.0062494277954102, 6.01875019073...   640.0   963.0   \n",
      "1  [[3009.643798828125, 404.3999938964844, 3001.5...  3649.0  5164.0   \n",
      "2  [[274.90313720703125, 11.824999809265137, 272....   829.0  1239.0   \n",
      "3  [[270.2718811035156, 37.881248474121094, 269.2...   578.0   681.0   \n",
      "4  [[504.1968688964844, 85.31249237060547, 501.63...  1092.0  1638.0   \n",
      "\n",
      "                                                bbox       area  iscrowd  \\\n",
      "0  [6.018750190734863, 1.0062494277954102, 878.73...   417546.0      0.0   \n",
      "1  [129.10000610351562, 404.3999938964844, 4913.8...  9009843.0      0.0   \n",
      "2  [69.6937484741211, 11.824999809265137, 1064.76...   595828.0      0.0   \n",
      "3  [72.35624694824219, 37.881248474121094, 607.57...   234714.0      0.0   \n",
      "4  [225.22499084472656, 85.31249237060547, 1115.8...   652184.0      0.0   \n",
      "\n",
      "                                           keypoints  num_keypoints  query  \\\n",
      "0  [492, 34, 2, 492, 120, 2, 475, 120, 2, 449, 17...             23   True   \n",
      "1  [4006, 822, 2, 4387, 1251, 2, 3530, 1060, 2, 3...             23   True   \n",
      "2  [834, 79, 2, 1102, 224, 2, 937, 162, 2, 999, 3...             23   True   \n",
      "3  [328, 122, 2, 304, 239, 2, 194, 233, 2, 316, 3...             23   True   \n",
      "4  [1266, 483, 2, 1266, 602, 2, 1147, 504, 2, 113...             23   True   \n",
      "\n",
      "  metadata_split  \n",
      "0           test  \n",
      "1           test  \n",
      "2           test  \n",
      "3           test  \n",
      "4           test  \n",
      "Starting precomputation for bbox_mask (318 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_ELPephant_mask.npz: Masks count: 318\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_ELPephant_mask.npz: Mask: 318\n",
      "Precomputed data loaded from bbox_mask for gallery_ELPephant. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 318\n",
      "first 5 rows of metadata:\n",
      "           image_id  identity  \\\n",
      "0  dd20481c2e0aabbb        15   \n",
      "1  abae41ab03c9aafd        24   \n",
      "2  dabf87e7e52fc5a3        28   \n",
      "3  5e0b24ceb64d676b        35   \n",
      "4  d5ba5959ad5b54fa        35   \n",
      "\n",
      "                                                path       date orientation  \\\n",
      "0   images/15_4th Tuskless VI right side_Feb2009.jpg   2-1-2009       right   \n",
      "1  images/24_7th Tuskless III right side_Jan2010.jpg   1-1-2010       right   \n",
      "2            images/28_Aaron left head_17Aug2016.jpg   8-1-2016        left   \n",
      "3              images/35_Malak left head_Mar2010.jpg   3-1-2010        left   \n",
      "4             images/35_Malak right side_Nov2008.jpg  11-1-2008       right   \n",
      "\n",
      "  original_split                                       segmentation  height  \\\n",
      "0           test  [[269.73126220703125, 43.75, 268.421875, 45.05...   716.0   \n",
      "1          train  [[582.7172241210938, 104.75, 580.78125, 106.68...   829.0   \n",
      "2          train  [[672.8687133789062, 56.375, 671.1781005859375...   789.0   \n",
      "3          train  [[447.41094970703125, 348.46875, 445.475006103...  1239.0   \n",
      "4          train  [[1930.8187255859375, 314.5, 1924.950073242187...  2507.0   \n",
      "\n",
      "    width                                               bbox       area  \\\n",
      "0   838.0  [31.42500114440918, 43.75, 783.0062732696533, ...   267126.0   \n",
      "1  1239.0  [46.462501525878906, 104.75, 1053.150047302246...   394658.0   \n",
      "2  1082.0  [13.524999618530273, 56.375, 1066.784326553344...   435365.0   \n",
      "3   829.0  [166.70001220703125, 348.46875, 662.0906372070...   353523.0   \n",
      "4  3756.0  [187.8000030517578, 314.5, 3075.225143432617, ...  3329151.0   \n",
      "\n",
      "   iscrowd                                          keypoints  num_keypoints  \\\n",
      "0      0.0  [732, 195, 2, 717, 241, 2, 702, 248, 2, 747, 3...             23   \n",
      "1      0.0  [895, 191, 2, 936, 273, 2, 916, 273, 2, 946, 3...             23   \n",
      "2      0.0  [781, 88, 0, 605, 357, 0, 595, 367, 0, 616, 45...             23   \n",
      "3      0.0  [353, 407, 0, 600, 597, 0, 476, 646, 0, 534, 1...             23   \n",
      "4      0.0  [2672, 429, 2, 2732, 637, 2, 2554, 637, 2, 264...             23   \n",
      "\n",
      "   query metadata_split  \n",
      "0  False           test  \n",
      "1  False           test  \n",
      "2  False           test  \n",
      "3  False           test  \n",
      "4  False           test  \n",
      "Round 1 Query image_ids: ['0010ae716882691c', '03e83890cd4289ce', '04e162ba5b56f252', '05fbc3a2bf68ca80', '0707791c54b42200', '0800e5393d2e72d1', '081e8270d413f4c9', '095565ab6d1d4852', '0a2fd94a3f373b0b', '0c8b4e8f06794404', '0ce5531c26e6b19d', '0d03e39a64874764', '0d8e53a4297912f6', '0e517b885c2a84d7', '0ef18d0ead28392d', '0fc793649ad6ac96', '110bcaa64ceb588f', '117c2c2a2e2c7aec', '154aedcba2d7abaf', '16f8f627c07abfec', '17ed3aaf9cf5605d', '1a3476906076ab67', '1ab877037c78f4db', '1add04078c8aa1da', '1bad03f7d1df0f02', '204abbcf2a70a91d', '2195478465bb7f88', '2229f7e514d45a8a', '22636e6c5c0f3c75', '23a833b0c2b38ecb', '23d940a18f32f625', '23dd205f8d05975d', '24dabddf93619c5a', '25bf0dc6b69f92ab', '266218343bd87edd', '28660d243d483044', '2bb3a71abcbb05ef', '2d64876d68e05687', '2e4ebb10de65df2c', '30f7a76bb382416d', '313a5433ceb1391a', '32d114c54c4af86c', '3933692ef752947a', '394507403c8a8456', '39b30f87c74ee60b', '3a0096fcf06579ce', '3a64b55d2b795de5', '3c17be49efb77f7f', '3ece6e50fc49a6b1', '3fb6d576937c948b', '43c51f8a07a5a06c', '4427dd4415399301', '45d9d01a2dccc8ce', '4650b732d5facd54', '4988ab87254e641d', '4ab35a294661903d', '4be61069aef36427', '4d2e7923a0c08a3f', '50c1381ae1b4a272', '53b95663d8b5d80a', '53ce8b3e80cae1e1', '55394831e32191ad', '5856f7f28766cc5d', '58baefd795ba493c', '5918d60f560eaa7b', '5ce16526682392de', '601e95b3903b9b49', '607e7a0e9f83618e', '62c7789c4edc40e8', '62dee6f86d95c171', '62f0fa8455680b38', '6352a729e4cb5b8d', '64c192a33d2d0d6f', '65e1484cea82cd45', '673a5742a1a8e9d5', '6b6dfea20324ca90', '6c4a8b87e7278b97', '6e26f1bb126b6060', '73acc1d19d52c81c', '7651c23481fbf213', '780310623986ddf2', '790a5dad9a023134', '7c3991bc7ec9a5d3', '7d8edcba876e1519', '805bd3a50ec89c30', '80a54a9c6590f6d9', '829b710b26d5d806', '8378f422aa87ab50', '839034d0fc24024b', '83ee669ec6df952a', '8a7a772c0addf3c3', '8af2820f5dd39e77', '8b7d24283f15f77b', '8c855f95050a4944', '9190ec0e1cecd2e4', '91952b585994649d', '938cafb47649e92f', '97a79f0f6b68161d', '9896351ded4b34e0', '9a356f80c1b98d6c', '9b267ed07bc05775', 'ad4fe7a4fb01ab14', 'b2fc6db14232eb89', 'bc41e7657c752d88', 'bfef420df85c8de6', 'c01d21bbff4bc0f0', 'c6d4ed92aac6ecf2', 'c9385c8707663ee9', 'cbe68a42b5f8f582', 'd3df99c1cd1c3059', 'd6f82e9aff1aca26', 'd9d2a5502ec59fc3', 'e013b92754b40ef0']\n",
      "Round 1 Gallery image_ids: ['00250c82b3123448', '02a22d514e49aee4', '02c05aa98bab86be', '02d1675ff79e7fd5', '02f72d783973551e', '05865fe5766eb412', '096c2968dbb56422', '0a3bc3b9f60c563a', '0aa17678d96b10e9', '0bcc2c1cb281373d', '0bd05e905d87b78e', '0beb0ed45805fd74', '0efcbb0797cd6c7c', '0f56bfd6677b8c2d', '0f9998478e642304', '0fb4a18079827989', '10298908f9ab21da', '12fad800ae33b884', '1420feb3cfc6a3c9', '17775977714c2e94', '1899bfdddf3cd987', '1a14339b5defc408', '1a9ddbb7102f05b2', '1bc10828c971221c', '1c766a6cad608ac6', '1cc43b3352c74b57', '1d944ddbee0aee56', '21356f6b7decb765', '21d5510160b24f68', '232a4511f1e66943', '23ab310081c10d2a', '252d6e8bc1ae1ccb', '253b4bcef63ac3fa', '257e874e7b3fd206', '2593e6a9a4b3a6cb', '2885b1ace15be2d3', '2971e9c4d557d382', '2b425ac18e917b26', '2b62ecf3428fdc62', '2b681a25f38a00fc', '2bc8a148a63aa20b', '2df5d6b883d976b8', '2e0226835803a562', '2f6c167c199dd831', '336cb250d15df70b', '33d7aed4f366718a', '35aed33416ef3de9', '35de7987ded09387', '367d2e22472b4661', '3725cca5ead96732', '37ede4615d5bc2f0', '3821d05f3e69fb7b', '38ccaaf89204b074', '3971b05029abcf9a', '3c59195a2b6360e5', '3cea6012e86253a9', '3d925be46f3ab78d', '3dff77ca0128f510', '3e58b81236064196', '3eda7cf7b12205bb', '3f5cfa73eeb20cbc', '3f8710d13f33109c', '3fadd0f3a7d14697', '4037c24bacd7a441', '40dc44a4131b0341', '4120fe3647242f92', '419b7e1a488ec2a2', '425731377709f493', '43f74ca3423f2f52', '44266eddc4df9c63', '44ff120b51ffd652', '462ca114cd195a47', '463c8f8c337deda6', '47079e96862e5aef', '47246f33a6d05944', '47b398143b185a11', '47d6846a178b2a20', '482638304021b8f7', '49f5fdcf729f19c8', '4a8019003bca9ada', '4c8467f2e2fe8adb', '4cdf0f64840c9571', '4ce66aefc1f705fb', '4d1767882ae39a87', '4d1e0ce3d1981cf1', '4d7953a9ece9fc65', '4dce9ace92e6a3c9', '4ded2d5b83a5a114', '4f192e4565d259e1', '4f75d9025ea2cd66', '5022dcabd5afc85e', '5336b2b309bf0135', '53b15f74a5dd6e44', '53ced30cf52fb44b', '541859c636ba975b', '54245284e7f17551', '5591423e39d773f3', '55a9487c340d6004', '572d39e8917a3a28', '59dbd98bb7e43df9', '5a3bb678d982a8e3', '5ac033c16d92169b', '5ad2d8e835781710', '5b183b93b626d80f', '5e0b24ceb64d676b', '61a5ef334e3e4610', '63cfd8100b4da743', '63f42f6115d0324d', '6ab4879a50c84f40', '6ac3378269960e51', '6b5678f3d10e5967', '6d07fd41e4f89fcf', '6d4964b98e15821f', '6dbb8dd3b189fcb3', '6de8b4310dd0ce19', '6ef5b2dbedf71d10', '71cbb01dfe233266', '72967f4ed76eff2f', '74465ee05df6bdf7', '765b5b819efe7be6', '76b289933a976a3c', '771f888504a7ef28', '78044f294bbddd05', '783868fac14c0006', '79f47548d13d28ef', '7bb0c3d291972769', '7c3e480c2fb2dbde', '7df5302a54d8e07f', '7e6911d5ea7046b5', '7f045a077e9c3077', '7fa63471d2de6e35', '80384f9dc7033d5f', '8038b755c9615d77', '803e211609505b8b', '808aa46e0adf0a1f', '80d12a065a98344a', '815b2ff790b1b6ce', '82975d37b8019233', '835dbe8f24a40928', '8392c5e1b4ba9123', '845fa0278f065ebb', '865110ba70f901dd', '86676a4cc1fa6660', '86b6795bbbe7594f', '86e7766f48688539', '87487ef6ab33ce62', '87a05d77f38da2f4', '884117e9232be2e6', '8931748d2bf1d125', '89f7cecde1d57811', '8c0c970ec23a6602', '8c163b8135d8ddbd', '8c3aa394de7d3a27', '8c447db50764ac10', '8cf39e1ed1b5ee79', '8d1a8827a9acab9c', '8d83d29b50ae3345', '8dcd36b1777420bb', '8e86a25c846ed5f5', '8eceba0544f992fc', '8eec6730e3e844c0', '90b870520b43e6d7', '9177f4d929fbbb67', '91aa9a2cde3da26e', '91afd15ded16da50', '92bef95694be13e5', '94ee55f6eff0627e', '94f0249d9c064d05', '95caba47ac3df67d', '964c3062234baba2', '964e0493d396c17f', '96af1b6fa7ef113f', '97ef54520ad700f8', '98f342a6612f826d', '98fccf71fdda4b64', '991d7e547219ae04', '9aedb35430a8137c', '9af312027f3bc953', '9c3742596f17d9d3', '9c95eeee86cc5cf1', '9dc66d2782181e0a', '9e2734d00aedb8c5', '9f5df0959e462857', 'a0067d1a89d9afc7', 'a092f9c6188350db', 'a0f40514870d436b', 'a2091982e94cd03f', 'a22d24a432f4d124', 'a30044f9573036c1', 'a371caa0d7e47b31', 'a3de69aef2b3ad23', 'a4c59a9c2af9d827', 'a515cc6c9b807d51', 'a521df9b78833833', 'a553e869d56a3c24', 'a56792ca3ddafd13', 'a5988c2db1d8ef50', 'a5d61a24dc458b54', 'a6f5b44681b53d40', 'a71798955e0320a5', 'a7875b6bd9463a79', 'a8e01a5ef0506346', 'a90e930e5aac1f66', 'aa1ec674d274b5fe', 'aa25499c6ae3e8a1', 'ab0083edbe785ccc', 'abae41ab03c9aafd', 'ad06bd218d528fce', 'ae9b55dfea4bbf68', 'aed66408bb1d8b27', 'b0d8c5d87dad7aaa', 'b23e47492d9a4d5b', 'b2c4db657061d7ad', 'b4c4723687808871', 'b4fa1714131ae40e', 'b5ab71d4261a59cf', 'b601b67b3d4faa22', 'b6d75695ada6aae4', 'b7180e17597182ef', 'b7185420cd859eda', 'b748ee3931126287', 'b8232a53ca09064f', 'b8b996098910f3dd', 'b975099afa132ff8', 'bb5a478efb0deb05', 'bbdc49b443978f84', 'bbf1e145bad89cf5', 'bc40cea36cd6086e', 'bf948a7eb2dca09b', 'c002d4c33d3586f1', 'c0139cd51c866936', 'c0e621cf57ea6514', 'c192ee8e74a29c56', 'c3269acc1572b0c7', 'c333ea14a0c31551', 'c41e3ffd0469edb0', 'c54b65db18b394b2', 'c6fa57dfa8b74e3c', 'c708f716f71bbd6f', 'c82d008e7db68963', 'c88cfc738e3ef512', 'c89fe5f82bb9640b', 'c8e7dff242ab8926', 'c9d46552773ec640', 'cb0d4de29d632352', 'cb7017f3cfeb3050', 'cc241d02b24cb82a', 'cdabbe627eb29df3', 'cdc2ebb2242c2086', 'cee18f0f40d761af', 'cef6682362fe03f4', 'cf0b609dedd20c4b', 'd01eb7c0b1ce3569', 'd180297695e51cd3', 'd21e35bfab93814c', 'd302d21432d34812', 'd44574775f877af5', 'd45e7ff2b67a691d', 'd5ba5959ad5b54fa', 'd8d799ad30dc1047', 'd8ef5830adfc27a7', 'd908ef24677d129f', 'd9847b4055d7d176', 'da38cb6c9632656d', 'dabf87e7e52fc5a3', 'db31cd2b95cf526c', 'dc4126d4f5720511', 'dd20481c2e0aabbb', 'dfdd9970b406140c', 'e16e0abb2d5e33ab', 'e1afdc1a991c45b4', 'e219b700481b77a8', 'e245b2148a64cd67', 'e250587632c07951', 'e26d5b1ca15b57dd', 'e2a21f8689778bab', 'e35edc1324dfbc2f', 'e38cd262e86d8be8', 'e516e378feb8198d', 'e5b266a235ac70b0', 'e5b68826bcef898c', 'e61d6d063216f44a', 'e6572233c11e9bf4', 'e7d4eefef7498a81', 'e7f338b3cb3d151a', 'e8467c120a0a47f7', 'e85a0538b20cfef0', 'e8bae7b9d6da20f9', 'e8bfa50419a98d8e', 'e96f9f7eb822ca85', 'e9a7434a8c0b2b99', 'e9b1520e18a3478f', 'ebc29e467eed72a1', 'ebf170f0d750ffc5', 'ec26148d1a041166', 'ec268983bcb69abb', 'ecd7c2c3a99a7256', 'ed740e78b66cdb3b', 'ee022808ca42df50', 'eef317b86707a284', 'efe58ef5aa226e9c', 'f294321e02043621', 'f40ace68b7865cf9', 'f436b0839296b335', 'f488bf656de99b0e', 'f6e20932a24e8652', 'f6fc93fd0636f6c6', 'f74fb370d23759e2', 'f82d0ccc9dd64c5e', 'f8a28aa722d4ea02', 'f937f522f5e5217a', 'f95bf3e102fb7975', 'f96ca0efdee550fc', 'fbb486e3d15a09e1', 'fcc237df89e78dee', 'fdb0c99ce54ef14b', 'fe367e0dc74a2a3b', 'fefa5178f6f91724']\n"
     ]
    }
   ],
   "source": [
    "path_elephants = os.path.join(root, 'ELPephant')\n",
    "dataset_elephants = datasets.ELPephants(path_elephants)\n",
    "\n",
    "data_elephants = WildlifeDataModule(\n",
    "                            metadata=dataset_elephants.df,\n",
    "                            data_dir=path_elephants, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_elephants_split.csv\",\n",
    "                            animal_cat=\"mammal\", \n",
    "                            splitter ='metadata_split', \n",
    "                            only_cache=True,\n",
    "                            wildlife_names='ELPephant',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 1764\n",
      "Removed 0 rows with invalid segmentation data.\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 1343/421/0/1764\n",
      "Classes: train/test/unassigned/total = 57/57/0/57\n",
      "Classes: train only/test only/joint  = 0/0/57\n",
      "\n",
      "Fraction of train set     = 76.13%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 1343\n",
      "Number of individuals (classes): 57\n",
      "Mean images/individual: 23.56140350877193\n",
      "Min images/individual: 6\n",
      "Max images/individual: 99\n",
      "Test Set\n",
      "Length: 421\n",
      "Number of individuals (classes): 57\n",
      "Mean images per individual: 7.385964912280702\n",
      "Min images per individual: 3\n",
      "Max images per individual: 26\n",
      "Starting precomputation for bbox_mask (1343 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/train_SealID_mask.npz: Masks count: 1343\n",
      "Loaded primary cache from ../dataset/data_cache/train_SealID_mask.npz: Mask: 1343\n",
      "Precomputed data loaded from bbox_mask for train_SealID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 1343\n",
      "first 5 rows of metadata:\n",
      "  image_id  identity                                    path original_split  \\\n",
      "0   fxhdev         1  full images/source_database/fxhdev.jpg          train   \n",
      "1   ggbxhv         1     full images/source_query/ggbxhv.jpg            val   \n",
      "2   nhcykn         1  full images/source_database/nhcykn.jpg          train   \n",
      "3   nmjxdr         1  full images/source_database/nmjxdr.jpg           test   \n",
      "4   qcsyyu         1  full images/source_database/qcsyyu.jpg          train   \n",
      "\n",
      "  original_split_reid                                       segmentation  \\\n",
      "0            database  [[684.7999877929688, 1024.0, 678.4000244140625...   \n",
      "1               query  [[547.8562622070312, 162.28749084472656, 541.8...   \n",
      "2            database  [[3481.60009765625, 614.4000244140625, 3475.19...   \n",
      "3            database  [[2278.39990234375, 998.4000244140625, 2272.0,...   \n",
      "4            database  [[2009.5999755859375, 819.2000122070312, 2003....   \n",
      "\n",
      "   height   width                                               bbox  \\\n",
      "0  4096.0  4096.0  [25.600000381469727, 1024.0, 4064.000097274780...   \n",
      "1   600.0   958.0  [311.3500061035156, 162.28749084472656, 276.92...   \n",
      "2  4096.0  4096.0  [25.600000381469727, 614.4000244140625, 4051.2...   \n",
      "3  4096.0  4096.0  [537.5999755859375, 998.4000244140625, 3552.00...   \n",
      "4  4096.0  4096.0  [25.600000381469727, 819.2000122070312, 3494.3...   \n",
      "\n",
      "        area  iscrowd                                          keypoints  \\\n",
      "0  5572874.0      0.0  [696, 1110, 2, 657, 1229, 2, 380, 1229, 2, 143...   \n",
      "1    19151.0      0.0  [562, 171, 2, 581, 176, 2, 565, 173, 2, 573, 2...   \n",
      "2  5010821.0      0.0  [3588, 765, 2, 3705, 1001, 2, 3627, 1001, 2, 3...   \n",
      "3  5044858.0      0.0  [962, 1783, 2, 1030, 2224, 2, 826, 2190, 2, 89...   \n",
      "4  3695083.0      0.0  [3042, 870, 2, 3178, 972, 2, 2940, 1108, 2, 30...   \n",
      "\n",
      "   num_keypoints  \n",
      "0             23  \n",
      "1             23  \n",
      "2             23  \n",
      "3             23  \n",
      "4             23  \n",
      "Starting precomputation for bbox_mask (57 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/query_SealID_mask.npz: Masks count: 57\n",
      "Loaded primary cache from ../dataset/data_cache/query_SealID_mask.npz: Mask: 57\n",
      "Precomputed data loaded from bbox_mask for query_SealID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 57\n",
      "first 5 rows of metadata:\n",
      "  image_id  identity                                    path original_split  \\\n",
      "0   lhczmz         1  full images/source_database/lhczmz.jpg          train   \n",
      "1   jpqwtm         3  full images/source_database/jpqwtm.jpg           test   \n",
      "2   aqwhnv        10  full images/source_database/aqwhnv.jpg           test   \n",
      "3   gzknda        14     full images/source_query/gzknda.jpg          train   \n",
      "4   eicsjp        21     full images/source_query/eicsjp.jpg          train   \n",
      "\n",
      "  original_split_reid                                       segmentation  \\\n",
      "0            database  [[3008.0, 665.5999755859375, 3001.60009765625,...   \n",
      "1            database  [[2060.800048828125, 1945.5999755859375, 2054....   \n",
      "2            database  [[1328.0, 48.0, 1324.0, 52.0, 1300.0, 52.0, 12...   \n",
      "3               query  [[1888.0, 1126.4000244140625, 1881.59997558593...   \n",
      "4               query  [[1564.800048828125, 10.800000190734863, 1561....   \n",
      "\n",
      "   height   width                                               bbox  \\\n",
      "0  4096.0  4096.0  [486.3999938964844, 665.5999755859375, 3526.40...   \n",
      "1  4096.0  4096.0  [25.600000381469727, 1945.5999755859375, 2444....   \n",
      "2  1920.0  2560.0                       [640.0, 48.0, 1916.0, 572.0]   \n",
      "3  4096.0  4096.0  [0.0, 1126.4000244140625, 4089.60009765625, 18...   \n",
      "4   892.0  2048.0  [1206.4000244140625, 10.800000190734863, 838.4...   \n",
      "\n",
      "        area  iscrowd                                          keypoints  \\\n",
      "0  6094888.0      0.0  [3551, 907, 2, 3753, 1144, 2, 3753, 1144, 2, 3...   \n",
      "1  1703096.0      0.0  [2208, 1991, 2, 2350, 2110, 2, 2279, 2110, 2, ...   \n",
      "2   731760.0      0.0  [842, 170, 2, 768, 226, 2, 768, 207, 2, 675, 3...   \n",
      "3  5335347.0      0.0  [1555, 1238, 0, 3902, 1636, 0, 3862, 1636, 2, ...   \n",
      "4   245442.0      0.0  [1674, 40, 0, 1527, 40, 0, 1993, 211, 0, 1936,...   \n",
      "\n",
      "   num_keypoints  query  \n",
      "0             23   True  \n",
      "1             23   True  \n",
      "2             23   True  \n",
      "3             23   True  \n",
      "4             23   True  \n",
      "Starting precomputation for bbox_mask (364 images)...\n",
      "Loaded mask cache from ../dataset/data_cache/gallery_SealID_mask.npz: Masks count: 364\n",
      "Loaded primary cache from ../dataset/data_cache/gallery_SealID_mask.npz: Mask: 364\n",
      "Precomputed data loaded from bbox_mask for gallery_SealID. Only to be used for processing lvl 2-5\n",
      "Precomputed data loaded:\n",
      "length of metadata: 364\n",
      "first 5 rows of metadata:\n",
      "  image_id  identity                                    path original_split  \\\n",
      "0   lphfsr         1  full images/source_database/lphfsr.jpg           test   \n",
      "1   meoqtw         1     full images/source_query/meoqtw.jpg          train   \n",
      "2   mcffwe         3     full images/source_query/mcffwe.jpg          train   \n",
      "3   pwwwgv         3  full images/source_database/pwwwgv.jpg          train   \n",
      "4   svavuh         3     full images/source_query/svavuh.jpg          train   \n",
      "\n",
      "  original_split_reid                                       segmentation  \\\n",
      "0            database  [[330.3187255859375, 210.97499084472656, 328.8...   \n",
      "1               query  [[864.0, 320.0, 860.7999877929688, 323.2000122...   \n",
      "2               query  [[2553.60009765625, 1561.5999755859375, 2547.1...   \n",
      "3            database  [[1216.0, 1408.0, 1209.5999755859375, 1414.400...   \n",
      "4               query  [[1875.199951171875, 1587.199951171875, 1868.8...   \n",
      "\n",
      "   height   width                                               bbox  \\\n",
      "0   576.0   948.0  [314.0249938964844, 210.97499084472656, 318.46...   \n",
      "1  1536.0  2048.0  [371.20001220703125, 320.0, 1347.2000122070312...   \n",
      "2  4096.0  4096.0  [25.600000381469727, 1561.5999755859375, 4064....   \n",
      "3  4096.0  4096.0  [25.600000381469727, 1408.0, 4064.000097274780...   \n",
      "4  4096.0  4096.0  [256.0, 1587.199951171875, 3833.60009765625, 1...   \n",
      "\n",
      "        area  iscrowd                                          keypoints  \\\n",
      "0    19549.0      0.0  [332, 228, 2, 332, 231, 2, 335, 231, 2, 326, 2...   \n",
      "1   702899.0      0.0  [1498, 357, 0, 1692, 525, 2, 1524, 538, 2, 169...   \n",
      "2  3694674.0      0.0  [313, 2196, 0, 3891, 2078, 0, 3773, 1999, 2, 1...   \n",
      "3  4009349.0      0.0  [381, 1510, 2, 341, 1549, 2, 262, 1589, 2, 104...   \n",
      "4  3745300.0      0.0  [3947, 2550, 2, 3836, 2699, 0, 3761, 2662, 0, ...   \n",
      "\n",
      "   num_keypoints  query  \n",
      "0             23  False  \n",
      "1             23  False  \n",
      "2             23  False  \n",
      "3             23  False  \n",
      "4             23  False  \n",
      "Round 1 Query image_ids: ['lhczmz', 'jpqwtm', 'aqwhnv', 'gzknda', 'eicsjp', 'dfzydg', 'amsbti', 'fugjon', 'lhtovf', 'btgezb', 'agfgqy', 'cyfzie', 'lkppbk', 'dlpggu', 'wtdlxu', 'biiwjz', 'gnthjz', 'dvbbrx', 'abqhgd', 'cosoaf', 'ajlykt', 'acswbh', 'bzygdy', 'axfqkn', 'ebosjo', 'dchxlr', 'fnibft', 'avjmsg', 'ahmgau', 'gheoce', 'alcucv', 'cdysne', 'bfjckk', 'boolhb', 'dgybbt', 'ebkbms', 'ccyxzc', 'fvvsyn', 'mgtyww', 'hfdkei', 'dmjauu', 'bansui', 'dttdck', 'dtdjbh', 'axxzdz', 'bhrxjf', 'geqdpx', 'cilcfp', 'bbjdhf', 'gparyw', 'ddeygu', 'bmlvzh', 'debsry', 'ajkgrp', 'jaymuz', 'jjdsrz', 'bipngj']\n",
      "Round 1 Gallery image_ids: ['meoqtw', 'lphfsr', 'mcffwe', 'pwwwgv', 'svavuh', 'zrmend', 'pcgimx', 'xkgpfr', 'ldiebp', 'wkfong', 'mjjnon', 'sniuey', 'snrzrh', 'ehayyb', 'gimobo', 'xnpcdo', 'rcveul', 'ryjjxn', 'xncyph', 'yjkzng', 'wibtpq', 'syukpe', 'eixbvt', 'kwswcz', 'skzgzf', 'wikndr', 'uwuzdg', 'koquhd', 'jxtqcf', 'igfuul', 'ycifwm', 'uduwpl', 'kldavi', 'xpwgjr', 'qtcxts', 'xlwnbh', 'vumgcy', 'ppgbuf', 'hvhnhw', 'oshmau', 'qfjwku', 'owskbn', 'quhpdr', 'jgmncg', 'frddvc', 'tpkmgc', 'dxdbyu', 'ncjofv', 'zedvqh', 'pxsrqf', 'pprcll', 'nnkiat', 'zaetni', 'nrflho', 'jjpptc', 'xcfckg', 'ujpase', 'iifgxz', 'nighhv', 'tfklpl', 'urnfmw', 'pqazkt', 'wdqrzm', 'jkjxkz', 'woflco', 'zjynaj', 'jjqqht', 'vgjhao', 'qzmtyp', 'bvjamo', 'oziwkp', 'kdtjtp', 'lmsqqa', 'zwvqje', 'tehrla', 'rcatdi', 'ccyovj', 'dmtjja', 'orzavk', 'iatdjk', 'ymvahh', 'ldwdfk', 'jphovx', 'vnekvq', 'xmmxps', 'iksrho', 'fgovum', 'fgkegk', 'rlcpuw', 'ieihbc', 'llewjh', 'uqcjqr', 'saghll', 'pvxnge', 'ktodfu', 'qqmrwk', 'nrkvgz', 'wlbkgy', 'labhvm', 'smihex', 'zmzaym', 'zsevbx', 'pxjhje', 'zdeill', 'lrcwdx', 'lwrbev', 'zwzbak', 'igyyls', 'phmxrp', 'zzveeq', 'smndnm', 'urfgaw', 'pajwrx', 'zspuxm', 'kxgioq', 'grhgrh', 'ohbntl', 'bjqish', 'nxaioa', 'qqraqt', 'lmheot', 'knekns', 'mttecw', 'wyjsly', 'encyex', 'dqplcp', 'zupujz', 'vwhspv', 'yncugu', 'izvodb', 'rzskjh', 'szufdd', 'jlewkf', 'pewmxw', 'wlixfs', 'ddybmf', 'afysik', 'ayvefe', 'wabyrn', 'adbmug', 'nmiyoy', 'olzhag', 'lobkup', 'eyupsj', 'dmtecc', 'jnnhit', 'dwpeiu', 'qzlbfe', 'rheetn', 'sdsepq', 'qgungn', 'pukuhl', 'xwvqtu', 'vnzvig', 'cdczlg', 'zlcomw', 'eruqtc', 'vflbve', 'icqdkq', 'rkwoez', 'ytszig', 'zmolwm', 'ifsejn', 'codxru', 'imvpoj', 'comkpd', 'ylupmc', 'vbwumk', 'kftnwk', 'mxymaj', 'jtjild', 'mafjgj', 'vbcnmf', 'fmzfgl', 'wvipzw', 'yjqrfy', 'fxrhgg', 'vttuyf', 'qbvctq', 'owwojn', 'ydajkg', 'mvgqxz', 'nhfsbu', 'wdcvwj', 'ikiqcb', 'rdesbe', 'gjwghj', 'xqqkwf', 'lsepbd', 'loxwrp', 'yqiksp', 'cjebqd', 'vyjeed', 'cpphyj', 'xvtpki', 'rmmarv', 'owlrkq', 'tyzctb', 'urbymc', 'rmyntm', 'zyubgj', 'twazqv', 'dhmqsu', 'pexrhp', 'xfvdvt', 'kglqxu', 'dlwfzf', 'wixvwq', 'htnnmx', 'xtzzxq', 'pxcvhw', 'xgwmap', 'ecfssz', 'siyceu', 'ubyqkv', 'vukrns', 'kenotb', 'ygnuub', 'wzazen', 'jnplru', 'hmbkqh', 'kuwpyz', 'pravvj', 'qjxcsm', 'vsjnxt', 'oqbwfl', 'qpvocn', 'qfhyid', 'eutapc', 'xztsfx', 'gkzqja', 'ggumbq', 'xicunm', 'fpbrxf', 'wvyfzo', 'uugxeh', 'zzajic', 'nhgysx', 'jtosaw', 'viwxjt', 'fmayxk', 'njvhul', 'vhbkif', 'xzlrtw', 'hotprq', 'eybruq', 'fytoxg', 'mhtgkj', 'eyfynu', 'ycaikk', 'engzda', 'nziyho', 'tecxlk', 'znsljf', 'hormjx', 'glwlxk', 'pnkbai', 'gzhwbm', 'emxcvc', 'uavnbt', 'giirjd', 'kjoxik', 'lzqtho', 'korhdh', 'sjsxtj', 'gwuraq', 'dxnbyk', 'dzhflp', 'iiwrxw', 'olybev', 'ylayjc', 'sufavp', 'qyrecy', 'ntomok', 'xgkzzy', 'nsvepd', 'rrqmmd', 'zpqeas', 'wpjzki', 'wwiqta', 'vmqlee', 'qunqxt', 'ibpgck', 'tewhjz', 'guzfmj', 'goimrh', 'gtfpkx', 'weuohj', 'lfzfgb', 'jhobbe', 'svxbbj', 'wkfkvb', 'pdwqya', 'nzfryz', 'qgzxfd', 'qrbggz', 'ylwerb', 'nmvrpc', 'zmkzjk', 'kxcrxv', 'ehjnzn', 'wknlzf', 'cytmat', 'ewyron', 'dwtyiy', 'foaoeq', 'zcgmgb', 'poqiui', 'czqoez', 'xonvwu', 'lpzfyp', 'swycwq', 'hsfeuk', 'ixofca', 'lteemf', 'cqhknc', 'pjtfvl', 'izgovi', 'woyauk', 'gyzrck', 'kaftvu', 'uinqam', 'xtkauh', 'ymgmlz', 'qakdvr', 'hqzdms', 'nearsr', 'xcyzav', 'cxjliq', 'szqfsc', 'kcsqpt', 'kxuofc', 'kzhkjy', 'jflhfu', 'ndbsqb', 'tinkny', 'ngqcrm', 'qclxoq', 'ptmuge', 'usdczg', 'tiwhzv', 'wauepq', 'yhqklm', 'vhdhkp', 'dmjnzt', 'qbizvk', 'hplrar', 'ivvzox', 'sqcquq', 'zdxvsx', 'hxnvnw', 'mfempf', 'zkxehc', 'vhsgst', 'otwghs', 'xjvntd', 'mksqoj', 'mxjggn', 'zusmsu', 'xapmps', 'pxvqlo', 'kcsbpk', 'xqdmlj', 'xnsrai']\n"
     ]
    }
   ],
   "source": [
    "path_seals = os.path.join(root, 'SealID')\n",
    "dataset_seals = datasets.SealID(path_seals)\n",
    "\n",
    "data_seals = WildlifeDataModule(\n",
    "                            metadata=dataset_seals.df,\n",
    "                            data_dir=path_seals, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_sealID.csv\",\n",
    "                            animal_cat=\"mammal\", \n",
    "                            splitter ='custom_closed', \n",
    "                            only_cache=True,\n",
    "                            wildlife_names='SealID',\n",
    "                            precompute=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>bbox</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ace33278-b65f-43d4-9c12-530e420ddef5</td>\n",
       "      <td>hyena.coco/images/train2022/000000000001.jpg</td>\n",
       "      <td>[580, 607, 1335, 899]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5260c0df-76a3-4cb1-82fc-fd2f6a6440ad</td>\n",
       "      <td>hyena.coco/images/train2022/000000000002.jpg</td>\n",
       "      <td>[331, 599, 1709, 988]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8aa6f9e4-e249-494f-a762-11e847296544</td>\n",
       "      <td>hyena.coco/images/train2022/000000000003.jpg</td>\n",
       "      <td>[181, 233, 2084, 1530]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143bf01f-d0f1-4ec9-bedd-ad0aa26e0cc2</td>\n",
       "      <td>hyena.coco/images/train2022/000000000004.jpg</td>\n",
       "      <td>[1381, 733, 654, 415]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>67006b29-4adc-41dc-9b30-39a94363a81a</td>\n",
       "      <td>hyena.coco/images/train2022/000000000005.jpg</td>\n",
       "      <td>[426, 829, 334, 294]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>3124</td>\n",
       "      <td>08626c7e-f14d-4a22-8b38-f8474c0196de</td>\n",
       "      <td>hyena.coco/images/train2022/000000003100.jpg</td>\n",
       "      <td>[612, 503, 1026, 735]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>3125</td>\n",
       "      <td>8e52a7f7-8046-4567-b92a-e5941b184745</td>\n",
       "      <td>hyena.coco/images/train2022/000000003101.jpg</td>\n",
       "      <td>[0, 202, 2339, 1891]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>3126</td>\n",
       "      <td>f1aa3589-f203-4455-a293-86f392932895</td>\n",
       "      <td>hyena.coco/images/train2022/000000003102.jpg</td>\n",
       "      <td>[980, 276, 1267, 741]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>3127</td>\n",
       "      <td>0d234988-cf58-4e62-b45b-4f23b54b1f2a</td>\n",
       "      <td>hyena.coco/images/train2022/000000003103.jpg</td>\n",
       "      <td>[1448, 717, 652, 397]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>3128</td>\n",
       "      <td>08626c7e-f14d-4a22-8b38-f8474c0196de</td>\n",
       "      <td>hyena.coco/images/train2022/000000003104.jpg</td>\n",
       "      <td>[634, 234, 1228, 1366]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3129 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                              identity  \\\n",
       "0            0  ace33278-b65f-43d4-9c12-530e420ddef5   \n",
       "1            1  5260c0df-76a3-4cb1-82fc-fd2f6a6440ad   \n",
       "2            2  8aa6f9e4-e249-494f-a762-11e847296544   \n",
       "3            3  143bf01f-d0f1-4ec9-bedd-ad0aa26e0cc2   \n",
       "4            4  67006b29-4adc-41dc-9b30-39a94363a81a   \n",
       "...        ...                                   ...   \n",
       "3124      3124  08626c7e-f14d-4a22-8b38-f8474c0196de   \n",
       "3125      3125  8e52a7f7-8046-4567-b92a-e5941b184745   \n",
       "3126      3126  f1aa3589-f203-4455-a293-86f392932895   \n",
       "3127      3127  0d234988-cf58-4e62-b45b-4f23b54b1f2a   \n",
       "3128      3128  08626c7e-f14d-4a22-8b38-f8474c0196de   \n",
       "\n",
       "                                              path                    bbox  \\\n",
       "0     hyena.coco/images/train2022/000000000001.jpg   [580, 607, 1335, 899]   \n",
       "1     hyena.coco/images/train2022/000000000002.jpg   [331, 599, 1709, 988]   \n",
       "2     hyena.coco/images/train2022/000000000003.jpg  [181, 233, 2084, 1530]   \n",
       "3     hyena.coco/images/train2022/000000000004.jpg   [1381, 733, 654, 415]   \n",
       "4     hyena.coco/images/train2022/000000000005.jpg    [426, 829, 334, 294]   \n",
       "...                                            ...                     ...   \n",
       "3124  hyena.coco/images/train2022/000000003100.jpg   [612, 503, 1026, 735]   \n",
       "3125  hyena.coco/images/train2022/000000003101.jpg    [0, 202, 2339, 1891]   \n",
       "3126  hyena.coco/images/train2022/000000003102.jpg   [980, 276, 1267, 741]   \n",
       "3127  hyena.coco/images/train2022/000000003103.jpg   [1448, 717, 652, 397]   \n",
       "3128  hyena.coco/images/train2022/000000003104.jpg  [634, 234, 1228, 1366]   \n",
       "\n",
       "     orientation  \n",
       "0          right  \n",
       "1           left  \n",
       "2          right  \n",
       "3           left  \n",
       "4           left  \n",
       "...          ...  \n",
       "3124        left  \n",
       "3125       right  \n",
       "3126        left  \n",
       "3127       right  \n",
       "3128        left  \n",
       "\n",
       "[3129 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_hyenas = os.path.join(root, 'HyenaID2022')\n",
    "dataset_hyenas = datasets.HyenaID2022(path_hyenas)\n",
    "\n",
    "dataset_hyenas.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 3129\n",
      "running segmentation on pre-existing bbox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 sheep, 942.8ms\n",
      "Speed: 4.5ms preprocess, 942.8ms inference, 8.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1 knife, 791.7ms\n",
      "Speed: 1.5ms preprocess, 791.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1008.4ms\n",
      "Speed: 1.9ms preprocess, 1008.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000003.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 878.4ms\n",
      "Speed: 1.1ms preprocess, 878.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 1 bear, 1164.4ms\n",
      "Speed: 1.6ms preprocess, 1164.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1007.3ms\n",
      "Speed: 1.2ms preprocess, 1007.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 951.2ms\n",
      "Speed: 1.6ms preprocess, 951.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 695.2ms\n",
      "Speed: 0.9ms preprocess, 695.2ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 bear, 1365.1ms\n",
      "Speed: 1.9ms preprocess, 1365.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1309.8ms\n",
      "Speed: 1.2ms preprocess, 1309.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1098.9ms\n",
      "Speed: 1.3ms preprocess, 1098.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 760.5ms\n",
      "Speed: 1.0ms preprocess, 760.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 909.7ms\n",
      "Speed: 1.9ms preprocess, 909.7ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000013.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 985.5ms\n",
      "Speed: 1.2ms preprocess, 985.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 755.3ms\n",
      "Speed: 1.4ms preprocess, 755.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000015.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 972.5ms\n",
      "Speed: 1.3ms preprocess, 972.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 2254.2ms\n",
      "Speed: 1.6ms preprocess, 2254.2ms inference, 10.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1003.1ms\n",
      "Speed: 1.6ms preprocess, 1003.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1155.3ms\n",
      "Speed: 1.4ms preprocess, 1155.3ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 790.6ms\n",
      "Speed: 1.1ms preprocess, 790.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 907.9ms\n",
      "Speed: 1.3ms preprocess, 907.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 sheeps, 1099.2ms\n",
      "Speed: 1.5ms preprocess, 1099.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 978.7ms\n",
      "Speed: 1.4ms preprocess, 978.7ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 806.8ms\n",
      "Speed: 2.0ms preprocess, 806.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000024.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 880.6ms\n",
      "Speed: 1.2ms preprocess, 880.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1292.7ms\n",
      "Speed: 1.7ms preprocess, 1292.7ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1682.9ms\n",
      "Speed: 2.2ms preprocess, 1682.9ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1309.8ms\n",
      "Speed: 1.7ms preprocess, 1309.8ms inference, 3.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1 dog, 1248.7ms\n",
      "Speed: 1.5ms preprocess, 1248.7ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1225.6ms\n",
      "Speed: 2.2ms preprocess, 1225.6ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 sheeps, 1 bear, 1119.2ms\n",
      "Speed: 1.4ms preprocess, 1119.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1236.2ms\n",
      "Speed: 1.5ms preprocess, 1236.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1143.2ms\n",
      "Speed: 1.7ms preprocess, 1143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1156.2ms\n",
      "Speed: 1.4ms preprocess, 1156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1289.2ms\n",
      "Speed: 3.2ms preprocess, 1289.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1265.8ms\n",
      "Speed: 1.4ms preprocess, 1265.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1199.2ms\n",
      "Speed: 2.1ms preprocess, 1199.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 2426.3ms\n",
      "Speed: 1.1ms preprocess, 2426.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 933.0ms\n",
      "Speed: 1.3ms preprocess, 933.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1133.0ms\n",
      "Speed: 1.4ms preprocess, 1133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 cat, 736.6ms\n",
      "Speed: 1.2ms preprocess, 736.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1005.3ms\n",
      "Speed: 1.1ms preprocess, 1005.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 889.4ms\n",
      "Speed: 1.4ms preprocess, 889.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 bear, 1264.4ms\n",
      "Speed: 1.1ms preprocess, 1264.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 bear, 963.1ms\n",
      "Speed: 1.2ms preprocess, 963.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 bear, 2258.4ms\n",
      "Speed: 2.3ms preprocess, 2258.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1514.7ms\n",
      "Speed: 1.5ms preprocess, 1514.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1619.8ms\n",
      "Speed: 1.3ms preprocess, 1619.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1498.2ms\n",
      "Speed: 1.4ms preprocess, 1498.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 sheep, 1195.5ms\n",
      "Speed: 2.8ms preprocess, 1195.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1033.0ms\n",
      "Speed: 2.4ms preprocess, 1033.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1122.5ms\n",
      "Speed: 1.5ms preprocess, 1122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1731.5ms\n",
      "Speed: 1.6ms preprocess, 1731.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 881.1ms\n",
      "Speed: 1.4ms preprocess, 881.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 cow, 1106.1ms\n",
      "Speed: 1.6ms preprocess, 1106.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1493.0ms\n",
      "Speed: 1.5ms preprocess, 1493.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 933.5ms\n",
      "Speed: 1.4ms preprocess, 933.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1630.7ms\n",
      "Speed: 2.0ms preprocess, 1630.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 bear, 1312.7ms\n",
      "Speed: 1.4ms preprocess, 1312.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1247.8ms\n",
      "Speed: 1.9ms preprocess, 1247.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 sheep, 1226.2ms\n",
      "Speed: 1.5ms preprocess, 1226.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1 giraffe, 1746.4ms\n",
      "Speed: 2.9ms preprocess, 1746.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1130.8ms\n",
      "Speed: 1.7ms preprocess, 1130.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 942.2ms\n",
      "Speed: 1.8ms preprocess, 942.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1470.5ms\n",
      "Speed: 1.4ms preprocess, 1470.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1150.7ms\n",
      "Speed: 1.7ms preprocess, 1150.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 sheep, 1 bear, 1836.8ms\n",
      "Speed: 1.3ms preprocess, 1836.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 cat, 1 dog, 979.6ms\n",
      "Speed: 1.3ms preprocess, 979.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1387.5ms\n",
      "Speed: 1.6ms preprocess, 1387.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1245.1ms\n",
      "Speed: 1.4ms preprocess, 1245.1ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000070.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1077.1ms\n",
      "Speed: 2.0ms preprocess, 1077.1ms inference, 0.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000071.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 969.6ms\n",
      "Speed: 1.2ms preprocess, 969.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1022.1ms\n",
      "Speed: 1.2ms preprocess, 1022.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1222.8ms\n",
      "Speed: 2.5ms preprocess, 1222.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1322.9ms\n",
      "Speed: 1.1ms preprocess, 1322.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1436.1ms\n",
      "Speed: 2.1ms preprocess, 1436.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 811.9ms\n",
      "Speed: 1.4ms preprocess, 811.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1213.3ms\n",
      "Speed: 1.3ms preprocess, 1213.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 sheep, 1265.7ms\n",
      "Speed: 1.9ms preprocess, 1265.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 880.9ms\n",
      "Speed: 1.2ms preprocess, 880.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1053.7ms\n",
      "Speed: 1.4ms preprocess, 1053.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1069.1ms\n",
      "Speed: 1.3ms preprocess, 1069.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1358.7ms\n",
      "Speed: 1.2ms preprocess, 1358.7ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 2189.0ms\n",
      "Speed: 1.9ms preprocess, 2189.0ms inference, 0.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000084.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1265.7ms\n",
      "Speed: 1.6ms preprocess, 1265.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 971.4ms\n",
      "Speed: 1.2ms preprocess, 971.4ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000086.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1363.3ms\n",
      "Speed: 1.5ms preprocess, 1363.3ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1324.9ms\n",
      "Speed: 1.6ms preprocess, 1324.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1161.8ms\n",
      "Speed: 1.2ms preprocess, 1161.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1413.8ms\n",
      "Speed: 1.5ms preprocess, 1413.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 952.2ms\n",
      "Speed: 1.7ms preprocess, 952.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 938.1ms\n",
      "Speed: 1.4ms preprocess, 938.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1 sheep, 1 cow, 1426.7ms\n",
      "Speed: 1.8ms preprocess, 1426.7ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1134.8ms\n",
      "Speed: 1.8ms preprocess, 1134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 horse, 843.5ms\n",
      "Speed: 1.0ms preprocess, 843.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1119.8ms\n",
      "Speed: 1.6ms preprocess, 1119.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1437.3ms\n",
      "Speed: 2.1ms preprocess, 1437.3ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1069.5ms\n",
      "Speed: 1.3ms preprocess, 1069.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 horse, 1272.9ms\n",
      "Speed: 1.6ms preprocess, 1272.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1660.1ms\n",
      "Speed: 1.8ms preprocess, 1660.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 897.6ms\n",
      "Speed: 1.1ms preprocess, 897.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 922.7ms\n",
      "Speed: 1.5ms preprocess, 922.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1703.1ms\n",
      "Speed: 1.8ms preprocess, 1703.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1645.5ms\n",
      "Speed: 2.1ms preprocess, 1645.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 cow, 1513.3ms\n",
      "Speed: 1.7ms preprocess, 1513.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1185.8ms\n",
      "Speed: 2.0ms preprocess, 1185.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cat, 1 bear, 1421.3ms\n",
      "Speed: 1.6ms preprocess, 1421.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1454.2ms\n",
      "Speed: 1.3ms preprocess, 1454.2ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1184.6ms\n",
      "Speed: 1.2ms preprocess, 1184.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1417.6ms\n",
      "Speed: 1.4ms preprocess, 1417.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1486.8ms\n",
      "Speed: 1.7ms preprocess, 1486.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1187.5ms\n",
      "Speed: 1.1ms preprocess, 1187.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 926.9ms\n",
      "Speed: 1.7ms preprocess, 926.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 cow, 949.7ms\n",
      "Speed: 1.2ms preprocess, 949.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1210.5ms\n",
      "Speed: 2.0ms preprocess, 1210.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 991.9ms\n",
      "Speed: 1.6ms preprocess, 991.9ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000116.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1199.9ms\n",
      "Speed: 2.2ms preprocess, 1199.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 901.1ms\n",
      "Speed: 1.2ms preprocess, 901.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 902.8ms\n",
      "Speed: 1.5ms preprocess, 902.8ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1000.6ms\n",
      "Speed: 1.4ms preprocess, 1000.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 2976.2ms\n",
      "Speed: 1.8ms preprocess, 2976.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 920.8ms\n",
      "Speed: 1.7ms preprocess, 920.8ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1167.0ms\n",
      "Speed: 1.3ms preprocess, 1167.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1145.8ms\n",
      "Speed: 1.6ms preprocess, 1145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1221.7ms\n",
      "Speed: 1.6ms preprocess, 1221.7ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000125.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1026.6ms\n",
      "Speed: 1.3ms preprocess, 1026.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 cow, 1338.9ms\n",
      "Speed: 1.2ms preprocess, 1338.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 915.0ms\n",
      "Speed: 0.9ms preprocess, 915.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1108.2ms\n",
      "Speed: 1.1ms preprocess, 1108.2ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000129.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1242.4ms\n",
      "Speed: 1.5ms preprocess, 1242.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x320 1 bear, 814.1ms\n",
      "Speed: 1.2ms preprocess, 814.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1213.2ms\n",
      "Speed: 1.5ms preprocess, 1213.2ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1294.5ms\n",
      "Speed: 1.6ms preprocess, 1294.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1007.8ms\n",
      "Speed: 1.4ms preprocess, 1007.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1277.1ms\n",
      "Speed: 1.2ms preprocess, 1277.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1153.4ms\n",
      "Speed: 1.7ms preprocess, 1153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 1473.7ms\n",
      "Speed: 1.7ms preprocess, 1473.7ms inference, 33.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1282.9ms\n",
      "Speed: 1.7ms preprocess, 1282.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1122.5ms\n",
      "Speed: 1.3ms preprocess, 1122.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1057.7ms\n",
      "Speed: 1.4ms preprocess, 1057.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1 dog, 1 bear, 1423.6ms\n",
      "Speed: 1.8ms preprocess, 1423.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1073.8ms\n",
      "Speed: 1.3ms preprocess, 1073.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1545.2ms\n",
      "Speed: 1.4ms preprocess, 1545.2ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1093.2ms\n",
      "Speed: 1.3ms preprocess, 1093.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1960.8ms\n",
      "Speed: 1.4ms preprocess, 1960.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 1034.1ms\n",
      "Speed: 1.6ms preprocess, 1034.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 883.1ms\n",
      "Speed: 2.3ms preprocess, 883.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 (no detections), 828.1ms\n",
      "Speed: 1.3ms preprocess, 828.1ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000148.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 bear, 1251.1ms\n",
      "Speed: 1.1ms preprocess, 1251.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1227.0ms\n",
      "Speed: 1.3ms preprocess, 1227.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 898.0ms\n",
      "Speed: 1.3ms preprocess, 898.0ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 dog, 835.4ms\n",
      "Speed: 1.1ms preprocess, 835.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 giraffe, 1436.2ms\n",
      "Speed: 2.0ms preprocess, 1436.2ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 1 cow, 731.7ms\n",
      "Speed: 0.7ms preprocess, 731.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 2479.2ms\n",
      "Speed: 2.4ms preprocess, 2479.2ms inference, 3.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1210.0ms\n",
      "Speed: 1.6ms preprocess, 1210.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1360.8ms\n",
      "Speed: 1.2ms preprocess, 1360.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 2514.3ms\n",
      "Speed: 1.6ms preprocess, 2514.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 giraffe, 1374.2ms\n",
      "Speed: 1.8ms preprocess, 1374.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1348.8ms\n",
      "Speed: 1.1ms preprocess, 1348.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 2377.4ms\n",
      "Speed: 2.1ms preprocess, 2377.4ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1240.4ms\n",
      "Speed: 1.3ms preprocess, 1240.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1112.6ms\n",
      "Speed: 1.8ms preprocess, 1112.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1485.7ms\n",
      "Speed: 1.8ms preprocess, 1485.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 giraffe, 2037.7ms\n",
      "Speed: 1.8ms preprocess, 2037.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1 giraffe, 1887.7ms\n",
      "Speed: 1.6ms preprocess, 1887.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1154.8ms\n",
      "Speed: 1.6ms preprocess, 1154.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1879.1ms\n",
      "Speed: 1.5ms preprocess, 1879.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1891.5ms\n",
      "Speed: 1.7ms preprocess, 1891.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 cow, 1171.6ms\n",
      "Speed: 1.5ms preprocess, 1171.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1388.2ms\n",
      "Speed: 1.7ms preprocess, 1388.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 1470.3ms\n",
      "Speed: 1.5ms preprocess, 1470.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1448.2ms\n",
      "Speed: 1.5ms preprocess, 1448.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1393.0ms\n",
      "Speed: 1.6ms preprocess, 1393.0ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1553.4ms\n",
      "Speed: 2.6ms preprocess, 1553.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1263.9ms\n",
      "Speed: 2.4ms preprocess, 1263.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1370.6ms\n",
      "Speed: 2.3ms preprocess, 1370.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1206.6ms\n",
      "Speed: 2.2ms preprocess, 1206.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1110.2ms\n",
      "Speed: 1.3ms preprocess, 1110.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 840.8ms\n",
      "Speed: 1.2ms preprocess, 840.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1303.7ms\n",
      "Speed: 1.4ms preprocess, 1303.7ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 924.2ms\n",
      "Speed: 1.4ms preprocess, 924.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 giraffe, 1490.9ms\n",
      "Speed: 2.0ms preprocess, 1490.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1510.2ms\n",
      "Speed: 2.6ms preprocess, 1510.2ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 bear, 1160.0ms\n",
      "Speed: 1.3ms preprocess, 1160.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1080.6ms\n",
      "Speed: 1.3ms preprocess, 1080.6ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1166.4ms\n",
      "Speed: 1.9ms preprocess, 1166.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 2 bears, 957.6ms\n",
      "Speed: 1.1ms preprocess, 957.6ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1105.2ms\n",
      "Speed: 1.2ms preprocess, 1105.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 1350.3ms\n",
      "Speed: 2.1ms preprocess, 1350.3ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1070.2ms\n",
      "Speed: 1.5ms preprocess, 1070.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1386.1ms\n",
      "Speed: 1.3ms preprocess, 1386.1ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 2 bears, 885.8ms\n",
      "Speed: 1.1ms preprocess, 885.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1349.0ms\n",
      "Speed: 1.5ms preprocess, 1349.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1112.4ms\n",
      "Speed: 1.2ms preprocess, 1112.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 carrot, 1455.1ms\n",
      "Speed: 1.6ms preprocess, 1455.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1125.3ms\n",
      "Speed: 1.2ms preprocess, 1125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1140.7ms\n",
      "Speed: 1.5ms preprocess, 1140.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1024.3ms\n",
      "Speed: 1.2ms preprocess, 1024.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1535.6ms\n",
      "Speed: 1.4ms preprocess, 1535.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 bear, 988.4ms\n",
      "Speed: 1.2ms preprocess, 988.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 930.5ms\n",
      "Speed: 1.5ms preprocess, 930.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1447.9ms\n",
      "Speed: 2.0ms preprocess, 1447.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1209.2ms\n",
      "Speed: 1.6ms preprocess, 1209.2ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1422.8ms\n",
      "Speed: 1.9ms preprocess, 1422.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1071.8ms\n",
      "Speed: 1.7ms preprocess, 1071.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 2095.2ms\n",
      "Speed: 1.4ms preprocess, 2095.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 2 bears, 542.3ms\n",
      "Speed: 0.7ms preprocess, 542.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1223.0ms\n",
      "Speed: 1.2ms preprocess, 1223.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1 cow, 1154.1ms\n",
      "Speed: 1.5ms preprocess, 1154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 974.7ms\n",
      "Speed: 1.3ms preprocess, 974.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1247.9ms\n",
      "Speed: 1.9ms preprocess, 1247.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1121.8ms\n",
      "Speed: 1.3ms preprocess, 1121.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1413.7ms\n",
      "Speed: 1.3ms preprocess, 1413.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 person, 1 dog, 1109.3ms\n",
      "Speed: 1.5ms preprocess, 1109.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 cat, 1 bear, 986.8ms\n",
      "Speed: 1.3ms preprocess, 986.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 1266.8ms\n",
      "Speed: 1.4ms preprocess, 1266.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 965.2ms\n",
      "Speed: 1.3ms preprocess, 965.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 961.4ms\n",
      "Speed: 1.1ms preprocess, 961.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 939.3ms\n",
      "Speed: 1.8ms preprocess, 939.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1108.2ms\n",
      "Speed: 1.2ms preprocess, 1108.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 bear, 667.6ms\n",
      "Speed: 1.0ms preprocess, 667.6ms inference, 0.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1571.2ms\n",
      "Speed: 1.9ms preprocess, 1571.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1409.8ms\n",
      "Speed: 1.8ms preprocess, 1409.8ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1058.5ms\n",
      "Speed: 1.8ms preprocess, 1058.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1141.6ms\n",
      "Speed: 1.1ms preprocess, 1141.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sandwich, 1094.7ms\n",
      "Speed: 1.8ms preprocess, 1094.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1099.4ms\n",
      "Speed: 1.1ms preprocess, 1099.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1589.8ms\n",
      "Speed: 1.4ms preprocess, 1589.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1078.3ms\n",
      "Speed: 1.4ms preprocess, 1078.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1381.5ms\n",
      "Speed: 1.5ms preprocess, 1381.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1508.5ms\n",
      "Speed: 5.1ms preprocess, 1508.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cow, 1556.0ms\n",
      "Speed: 1.3ms preprocess, 1556.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1170.3ms\n",
      "Speed: 1.7ms preprocess, 1170.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 person, 1 horse, 1 cow, 1518.1ms\n",
      "Speed: 2.4ms preprocess, 1518.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 couch, 1395.8ms\n",
      "Speed: 1.4ms preprocess, 1395.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1152.2ms\n",
      "Speed: 1.2ms preprocess, 1152.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1508.6ms\n",
      "Speed: 2.0ms preprocess, 1508.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 904.2ms\n",
      "Speed: 1.1ms preprocess, 904.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1302.6ms\n",
      "Speed: 1.8ms preprocess, 1302.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 giraffe, 1341.5ms\n",
      "Speed: 1.8ms preprocess, 1341.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 900.6ms\n",
      "Speed: 1.1ms preprocess, 900.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000242.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1567.8ms\n",
      "Speed: 1.8ms preprocess, 1567.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 teddy bear, 1457.6ms\n",
      "Speed: 2.0ms preprocess, 1457.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1120.1ms\n",
      "Speed: 1.4ms preprocess, 1120.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 bear, 1373.4ms\n",
      "Speed: 1.5ms preprocess, 1373.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1 cow, 1303.6ms\n",
      "Speed: 1.6ms preprocess, 1303.6ms inference, 19.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1395.1ms\n",
      "Speed: 2.6ms preprocess, 1395.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1047.0ms\n",
      "Speed: 1.5ms preprocess, 1047.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 cow, 1092.7ms\n",
      "Speed: 1.6ms preprocess, 1092.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 933.3ms\n",
      "Speed: 1.2ms preprocess, 933.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1065.8ms\n",
      "Speed: 1.5ms preprocess, 1065.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1 bear, 1183.3ms\n",
      "Speed: 1.3ms preprocess, 1183.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 (no detections), 889.3ms\n",
      "Speed: 1.1ms preprocess, 889.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 352)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000254.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1230.3ms\n",
      "Speed: 1.3ms preprocess, 1230.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1 dog, 1103.2ms\n",
      "Speed: 2.3ms preprocess, 1103.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 871.8ms\n",
      "Speed: 1.3ms preprocess, 871.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1 bear, 1192.9ms\n",
      "Speed: 1.7ms preprocess, 1192.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1254.4ms\n",
      "Speed: 1.5ms preprocess, 1254.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1242.9ms\n",
      "Speed: 2.0ms preprocess, 1242.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1444.9ms\n",
      "Speed: 2.2ms preprocess, 1444.9ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 cow, 934.0ms\n",
      "Speed: 1.0ms preprocess, 934.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1166.1ms\n",
      "Speed: 1.8ms preprocess, 1166.1ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000263.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 976.0ms\n",
      "Speed: 3.2ms preprocess, 976.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1093.7ms\n",
      "Speed: 2.1ms preprocess, 1093.7ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000265.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 cow, 1001.5ms\n",
      "Speed: 1.4ms preprocess, 1001.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1644.6ms\n",
      "Speed: 1.7ms preprocess, 1644.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1428.8ms\n",
      "Speed: 2.8ms preprocess, 1428.8ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000268.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1027.4ms\n",
      "Speed: 1.3ms preprocess, 1027.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1198.7ms\n",
      "Speed: 1.6ms preprocess, 1198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1028.4ms\n",
      "Speed: 1.7ms preprocess, 1028.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1614.1ms\n",
      "Speed: 1.8ms preprocess, 1614.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1057.5ms\n",
      "Speed: 1.4ms preprocess, 1057.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1 cow, 1342.2ms\n",
      "Speed: 1.7ms preprocess, 1342.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 2278.8ms\n",
      "Speed: 2.2ms preprocess, 2278.8ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1360.0ms\n",
      "Speed: 1.7ms preprocess, 1360.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 1388.3ms\n",
      "Speed: 1.5ms preprocess, 1388.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 2 cows, 1205.5ms\n",
      "Speed: 2.0ms preprocess, 1205.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1193.5ms\n",
      "Speed: 1.4ms preprocess, 1193.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1343.6ms\n",
      "Speed: 1.3ms preprocess, 1343.6ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000280.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 2073.2ms\n",
      "Speed: 1.6ms preprocess, 2073.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1346.1ms\n",
      "Speed: 1.6ms preprocess, 1346.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1527.4ms\n",
      "Speed: 3.3ms preprocess, 1527.4ms inference, 0.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000283.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 bear, 1300.3ms\n",
      "Speed: 1.4ms preprocess, 1300.3ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1276.6ms\n",
      "Speed: 2.0ms preprocess, 1276.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1413.2ms\n",
      "Speed: 2.4ms preprocess, 1413.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1056.2ms\n",
      "Speed: 1.3ms preprocess, 1056.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 bear, 1615.5ms\n",
      "Speed: 1.9ms preprocess, 1615.5ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1102.9ms\n",
      "Speed: 1.5ms preprocess, 1102.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 887.0ms\n",
      "Speed: 1.4ms preprocess, 887.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1412.0ms\n",
      "Speed: 1.5ms preprocess, 1412.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1560.4ms\n",
      "Speed: 1.6ms preprocess, 1560.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1 horse, 1 sheep, 1525.7ms\n",
      "Speed: 1.6ms preprocess, 1525.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 sheep, 1200.6ms\n",
      "Speed: 1.2ms preprocess, 1200.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1325.7ms\n",
      "Speed: 2.0ms preprocess, 1325.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1326.7ms\n",
      "Speed: 1.5ms preprocess, 1326.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 2765.8ms\n",
      "Speed: 1.7ms preprocess, 2765.8ms inference, 6.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1272.6ms\n",
      "Speed: 1.3ms preprocess, 1272.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1137.2ms\n",
      "Speed: 2.9ms preprocess, 1137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1410.7ms\n",
      "Speed: 1.5ms preprocess, 1410.7ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 sheep, 1414.2ms\n",
      "Speed: 1.5ms preprocess, 1414.2ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1070.9ms\n",
      "Speed: 1.5ms preprocess, 1070.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 976.1ms\n",
      "Speed: 1.2ms preprocess, 976.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 917.7ms\n",
      "Speed: 1.2ms preprocess, 917.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1222.3ms\n",
      "Speed: 1.5ms preprocess, 1222.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 horse, 1187.1ms\n",
      "Speed: 1.4ms preprocess, 1187.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 giraffe, 1648.7ms\n",
      "Speed: 2.3ms preprocess, 1648.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 2 bears, 1626.4ms\n",
      "Speed: 1.4ms preprocess, 1626.4ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1552.3ms\n",
      "Speed: 1.4ms preprocess, 1552.3ms inference, 26.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1305.7ms\n",
      "Speed: 1.9ms preprocess, 1305.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 dog, 1 frisbee, 1233.1ms\n",
      "Speed: 1.5ms preprocess, 1233.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1029.9ms\n",
      "Speed: 1.2ms preprocess, 1029.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1090.4ms\n",
      "Speed: 1.6ms preprocess, 1090.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1242.1ms\n",
      "Speed: 1.5ms preprocess, 1242.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 dog, 922.8ms\n",
      "Speed: 1.1ms preprocess, 922.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1583.6ms\n",
      "Speed: 2.2ms preprocess, 1583.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1019.7ms\n",
      "Speed: 1.4ms preprocess, 1019.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 899.2ms\n",
      "Speed: 1.2ms preprocess, 899.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1193.8ms\n",
      "Speed: 1.5ms preprocess, 1193.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1280.8ms\n",
      "Speed: 2.2ms preprocess, 1280.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1110.8ms\n",
      "Speed: 1.6ms preprocess, 1110.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1220.1ms\n",
      "Speed: 2.2ms preprocess, 1220.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000322.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 horse, 1 sheep, 1232.4ms\n",
      "Speed: 1.4ms preprocess, 1232.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1337.0ms\n",
      "Speed: 2.4ms preprocess, 1337.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000324.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 773.9ms\n",
      "Speed: 1.0ms preprocess, 773.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1226.2ms\n",
      "Speed: 1.5ms preprocess, 1226.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 bears, 930.3ms\n",
      "Speed: 1.3ms preprocess, 930.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 2132.5ms\n",
      "Speed: 2.4ms preprocess, 2132.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1631.1ms\n",
      "Speed: 2.2ms preprocess, 1631.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000329.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 933.1ms\n",
      "Speed: 1.3ms preprocess, 933.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1282.8ms\n",
      "Speed: 1.7ms preprocess, 1282.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1139.0ms\n",
      "Speed: 1.3ms preprocess, 1139.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 1 bear, 960.4ms\n",
      "Speed: 1.4ms preprocess, 960.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1787.2ms\n",
      "Speed: 1.7ms preprocess, 1787.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 dog, 943.2ms\n",
      "Speed: 1.3ms preprocess, 943.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 2 sheeps, 1144.3ms\n",
      "Speed: 1.2ms preprocess, 1144.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1273.7ms\n",
      "Speed: 1.3ms preprocess, 1273.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1231.2ms\n",
      "Speed: 1.8ms preprocess, 1231.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1602.1ms\n",
      "Speed: 1.8ms preprocess, 1602.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 bears, 1557.7ms\n",
      "Speed: 2.4ms preprocess, 1557.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1196.8ms\n",
      "Speed: 1.6ms preprocess, 1196.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1018.0ms\n",
      "Speed: 1.4ms preprocess, 1018.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1020.5ms\n",
      "Speed: 1.8ms preprocess, 1020.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1215.1ms\n",
      "Speed: 2.1ms preprocess, 1215.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 873.8ms\n",
      "Speed: 1.1ms preprocess, 873.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 horse, 1300.6ms\n",
      "Speed: 1.4ms preprocess, 1300.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 zebra, 2779.7ms\n",
      "Speed: 1.7ms preprocess, 2779.7ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1 sheep, 1641.6ms\n",
      "Speed: 2.6ms preprocess, 1641.6ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 elephant, 1 bear, 1486.2ms\n",
      "Speed: 1.6ms preprocess, 1486.2ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1360.8ms\n",
      "Speed: 1.3ms preprocess, 1360.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1427.2ms\n",
      "Speed: 2.7ms preprocess, 1427.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1431.0ms\n",
      "Speed: 1.6ms preprocess, 1431.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1117.3ms\n",
      "Speed: 1.3ms preprocess, 1117.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 891.7ms\n",
      "Speed: 2.8ms preprocess, 891.7ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000354.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1247.1ms\n",
      "Speed: 1.9ms preprocess, 1247.1ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000355.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1026.5ms\n",
      "Speed: 1.1ms preprocess, 1026.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1469.1ms\n",
      "Speed: 1.6ms preprocess, 1469.1ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000357.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 bear, 1499.9ms\n",
      "Speed: 1.5ms preprocess, 1499.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1830.9ms\n",
      "Speed: 1.7ms preprocess, 1830.9ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1309.9ms\n",
      "Speed: 1.7ms preprocess, 1309.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1612.3ms\n",
      "Speed: 1.9ms preprocess, 1612.3ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1040.0ms\n",
      "Speed: 1.3ms preprocess, 1040.0ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 (no detections), 1856.8ms\n",
      "Speed: 1.3ms preprocess, 1856.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000363.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 dog, 967.3ms\n",
      "Speed: 1.3ms preprocess, 967.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1286.5ms\n",
      "Speed: 2.1ms preprocess, 1286.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 998.2ms\n",
      "Speed: 1.3ms preprocess, 998.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 bear, 1268.6ms\n",
      "Speed: 1.6ms preprocess, 1268.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 cow, 1058.2ms\n",
      "Speed: 1.3ms preprocess, 1058.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1 sheep, 990.0ms\n",
      "Speed: 1.8ms preprocess, 990.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1484.3ms\n",
      "Speed: 1.6ms preprocess, 1484.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1290.9ms\n",
      "Speed: 1.6ms preprocess, 1290.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1 dog, 1649.6ms\n",
      "Speed: 2.0ms preprocess, 1649.6ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1298.9ms\n",
      "Speed: 1.6ms preprocess, 1298.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1458.6ms\n",
      "Speed: 1.6ms preprocess, 1458.6ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 2 cows, 1038.6ms\n",
      "Speed: 1.6ms preprocess, 1038.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1031.6ms\n",
      "Speed: 1.4ms preprocess, 1031.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1024.3ms\n",
      "Speed: 1.1ms preprocess, 1024.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 person, 1 dog, 1 carrot, 1110.7ms\n",
      "Speed: 1.8ms preprocess, 1110.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 897.3ms\n",
      "Speed: 1.8ms preprocess, 897.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 cow, 910.5ms\n",
      "Speed: 1.2ms preprocess, 910.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1752.5ms\n",
      "Speed: 2.0ms preprocess, 1752.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 2803.7ms\n",
      "Speed: 2.0ms preprocess, 2803.7ms inference, 2.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 cow, 4 bears, 817.9ms\n",
      "Speed: 1.5ms preprocess, 817.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1161.2ms\n",
      "Speed: 1.7ms preprocess, 1161.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1391.6ms\n",
      "Speed: 1.6ms preprocess, 1391.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1 sheep, 1648.6ms\n",
      "Speed: 2.5ms preprocess, 1648.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 942.8ms\n",
      "Speed: 1.3ms preprocess, 942.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1266.9ms\n",
      "Speed: 1.4ms preprocess, 1266.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1110.4ms\n",
      "Speed: 1.9ms preprocess, 1110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1266.0ms\n",
      "Speed: 1.8ms preprocess, 1266.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 1429.5ms\n",
      "Speed: 1.8ms preprocess, 1429.5ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 992.7ms\n",
      "Speed: 1.2ms preprocess, 992.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 sheeps, 1 bear, 945.3ms\n",
      "Speed: 1.0ms preprocess, 945.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 2 bears, 582.8ms\n",
      "Speed: 0.8ms preprocess, 582.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1417.9ms\n",
      "Speed: 1.6ms preprocess, 1417.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1345.5ms\n",
      "Speed: 1.5ms preprocess, 1345.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1293.9ms\n",
      "Speed: 1.6ms preprocess, 1293.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1282.7ms\n",
      "Speed: 1.5ms preprocess, 1282.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 988.2ms\n",
      "Speed: 1.5ms preprocess, 988.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 944.9ms\n",
      "Speed: 1.2ms preprocess, 944.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 bear, 1458.8ms\n",
      "Speed: 1.8ms preprocess, 1458.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1100.1ms\n",
      "Speed: 1.2ms preprocess, 1100.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 2207.3ms\n",
      "Speed: 1.6ms preprocess, 2207.3ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1 bear, 1361.9ms\n",
      "Speed: 1.5ms preprocess, 1361.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1068.7ms\n",
      "Speed: 1.7ms preprocess, 1068.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1 dog, 1466.9ms\n",
      "Speed: 1.6ms preprocess, 1466.9ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1331.9ms\n",
      "Speed: 2.0ms preprocess, 1331.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1054.1ms\n",
      "Speed: 1.6ms preprocess, 1054.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1259.4ms\n",
      "Speed: 1.6ms preprocess, 1259.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 bear, 1304.2ms\n",
      "Speed: 1.7ms preprocess, 1304.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1372.6ms\n",
      "Speed: 2.6ms preprocess, 1372.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1286.0ms\n",
      "Speed: 2.4ms preprocess, 1286.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1247.3ms\n",
      "Speed: 1.6ms preprocess, 1247.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1125.4ms\n",
      "Speed: 1.4ms preprocess, 1125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 horse, 1047.5ms\n",
      "Speed: 1.3ms preprocess, 1047.5ms inference, 2.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 horse, 971.3ms\n",
      "Speed: 2.0ms preprocess, 971.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 953.8ms\n",
      "Speed: 1.6ms preprocess, 953.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1429.6ms\n",
      "Speed: 1.6ms preprocess, 1429.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1256.7ms\n",
      "Speed: 1.9ms preprocess, 1256.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000419.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1228.3ms\n",
      "Speed: 1.4ms preprocess, 1228.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 2990.6ms\n",
      "Speed: 1.8ms preprocess, 2990.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 bear, 1170.2ms\n",
      "Speed: 1.5ms preprocess, 1170.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1316.8ms\n",
      "Speed: 1.7ms preprocess, 1316.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1165.3ms\n",
      "Speed: 1.4ms preprocess, 1165.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1 dog, 1459.0ms\n",
      "Speed: 2.0ms preprocess, 1459.0ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1304.1ms\n",
      "Speed: 1.5ms preprocess, 1304.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 968.8ms\n",
      "Speed: 1.5ms preprocess, 968.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 965.2ms\n",
      "Speed: 1.1ms preprocess, 965.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000428.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1262.9ms\n",
      "Speed: 1.4ms preprocess, 1262.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1 frisbee, 1256.9ms\n",
      "Speed: 2.0ms preprocess, 1256.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1490.0ms\n",
      "Speed: 1.6ms preprocess, 1490.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1272.4ms\n",
      "Speed: 1.5ms preprocess, 1272.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1110.4ms\n",
      "Speed: 1.5ms preprocess, 1110.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1349.2ms\n",
      "Speed: 1.8ms preprocess, 1349.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 3 bears, 1194.3ms\n",
      "Speed: 1.5ms preprocess, 1194.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1605.7ms\n",
      "Speed: 3.0ms preprocess, 1605.7ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 bear, 1432.9ms\n",
      "Speed: 1.8ms preprocess, 1432.9ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1044.3ms\n",
      "Speed: 1.4ms preprocess, 1044.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 bears, 983.4ms\n",
      "Speed: 1.4ms preprocess, 983.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 933.1ms\n",
      "Speed: 1.0ms preprocess, 933.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 1092.0ms\n",
      "Speed: 1.5ms preprocess, 1092.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1192.9ms\n",
      "Speed: 1.4ms preprocess, 1192.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1153.5ms\n",
      "Speed: 1.6ms preprocess, 1153.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1277.5ms\n",
      "Speed: 1.5ms preprocess, 1277.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 bear, 1480.5ms\n",
      "Speed: 1.8ms preprocess, 1480.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1657.2ms\n",
      "Speed: 1.7ms preprocess, 1657.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1500.6ms\n",
      "Speed: 1.5ms preprocess, 1500.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1334.5ms\n",
      "Speed: 1.7ms preprocess, 1334.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 sheep, 1689.3ms\n",
      "Speed: 2.6ms preprocess, 1689.3ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1119.1ms\n",
      "Speed: 1.3ms preprocess, 1119.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 1 bear, 577.5ms\n",
      "Speed: 0.8ms preprocess, 577.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 horse, 1271.5ms\n",
      "Speed: 1.3ms preprocess, 1271.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1221.4ms\n",
      "Speed: 1.9ms preprocess, 1221.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1224.4ms\n",
      "Speed: 1.8ms preprocess, 1224.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1226.1ms\n",
      "Speed: 1.3ms preprocess, 1226.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 2024.0ms\n",
      "Speed: 10.1ms preprocess, 2024.0ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1276.0ms\n",
      "Speed: 2.1ms preprocess, 1276.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 bears, 1000.1ms\n",
      "Speed: 1.3ms preprocess, 1000.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 horse, 1481.9ms\n",
      "Speed: 1.6ms preprocess, 1481.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1338.6ms\n",
      "Speed: 1.3ms preprocess, 1338.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1087.2ms\n",
      "Speed: 1.6ms preprocess, 1087.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1117.4ms\n",
      "Speed: 1.1ms preprocess, 1117.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1181.3ms\n",
      "Speed: 1.5ms preprocess, 1181.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1267.2ms\n",
      "Speed: 1.7ms preprocess, 1267.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 person, 1 dog, 1260.3ms\n",
      "Speed: 1.8ms preprocess, 1260.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1615.6ms\n",
      "Speed: 1.5ms preprocess, 1615.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1245.1ms\n",
      "Speed: 1.4ms preprocess, 1245.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1146.2ms\n",
      "Speed: 2.4ms preprocess, 1146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 2652.6ms\n",
      "Speed: 2.6ms preprocess, 2652.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1025.7ms\n",
      "Speed: 1.9ms preprocess, 1025.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1547.4ms\n",
      "Speed: 1.8ms preprocess, 1547.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1470.3ms\n",
      "Speed: 2.8ms preprocess, 1470.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1264.9ms\n",
      "Speed: 1.3ms preprocess, 1264.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1352.4ms\n",
      "Speed: 1.3ms preprocess, 1352.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 3 persons, 1 dog, 1 sheep, 1 knife, 1 scissors, 1289.0ms\n",
      "Speed: 1.5ms preprocess, 1289.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1589.5ms\n",
      "Speed: 3.1ms preprocess, 1589.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1601.2ms\n",
      "Speed: 2.0ms preprocess, 1601.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 bear, 1444.1ms\n",
      "Speed: 1.4ms preprocess, 1444.1ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1444.4ms\n",
      "Speed: 1.6ms preprocess, 1444.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1 sheep, 1581.1ms\n",
      "Speed: 1.9ms preprocess, 1581.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1170.6ms\n",
      "Speed: 1.3ms preprocess, 1170.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 843.1ms\n",
      "Speed: 1.1ms preprocess, 843.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1362.4ms\n",
      "Speed: 12.5ms preprocess, 1362.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x320 1 bear, 981.1ms\n",
      "Speed: 1.1ms preprocess, 981.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1120.5ms\n",
      "Speed: 1.4ms preprocess, 1120.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 980.5ms\n",
      "Speed: 1.2ms preprocess, 980.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000486.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1928.7ms\n",
      "Speed: 1.6ms preprocess, 1928.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1597.8ms\n",
      "Speed: 1.6ms preprocess, 1597.8ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1344.3ms\n",
      "Speed: 1.7ms preprocess, 1344.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 airplane, 1 cow, 1649.8ms\n",
      "Speed: 2.2ms preprocess, 1649.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 sheep, 1052.0ms\n",
      "Speed: 1.5ms preprocess, 1052.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1071.8ms\n",
      "Speed: 1.5ms preprocess, 1071.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1046.5ms\n",
      "Speed: 1.7ms preprocess, 1046.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1116.9ms\n",
      "Speed: 1.8ms preprocess, 1116.9ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000494.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1370.3ms\n",
      "Speed: 1.6ms preprocess, 1370.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1124.7ms\n",
      "Speed: 1.5ms preprocess, 1124.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1059.1ms\n",
      "Speed: 1.7ms preprocess, 1059.1ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000497.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1 cow, 1278.8ms\n",
      "Speed: 1.9ms preprocess, 1278.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 cow, 1228.9ms\n",
      "Speed: 1.4ms preprocess, 1228.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 2 sheeps, 1407.5ms\n",
      "Speed: 1.6ms preprocess, 1407.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 898.4ms\n",
      "Speed: 1.7ms preprocess, 898.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 cow, 1 bear, 754.0ms\n",
      "Speed: 1.0ms preprocess, 754.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 1 bear, 534.1ms\n",
      "Speed: 0.7ms preprocess, 534.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1408.9ms\n",
      "Speed: 1.7ms preprocess, 1408.9ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1964.6ms\n",
      "Speed: 1.7ms preprocess, 1964.6ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1384.4ms\n",
      "Speed: 3.0ms preprocess, 1384.4ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000506.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 horse, 1282.8ms\n",
      "Speed: 1.7ms preprocess, 1282.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1131.9ms\n",
      "Speed: 2.6ms preprocess, 1131.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1218.5ms\n",
      "Speed: 1.1ms preprocess, 1218.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 848.0ms\n",
      "Speed: 1.1ms preprocess, 848.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1088.0ms\n",
      "Speed: 2.0ms preprocess, 1088.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1283.0ms\n",
      "Speed: 1.7ms preprocess, 1283.0ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 bear, 918.1ms\n",
      "Speed: 1.0ms preprocess, 918.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 918.3ms\n",
      "Speed: 1.8ms preprocess, 918.3ms inference, 0.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000514.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 bear, 920.0ms\n",
      "Speed: 1.3ms preprocess, 920.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 horse, 1211.0ms\n",
      "Speed: 1.5ms preprocess, 1211.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1416.5ms\n",
      "Speed: 1.7ms preprocess, 1416.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1210.5ms\n",
      "Speed: 1.5ms preprocess, 1210.5ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1073.7ms\n",
      "Speed: 1.7ms preprocess, 1073.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000519.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 921.7ms\n",
      "Speed: 1.3ms preprocess, 921.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1174.2ms\n",
      "Speed: 1.7ms preprocess, 1174.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 bear, 1240.0ms\n",
      "Speed: 2.3ms preprocess, 1240.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1144.1ms\n",
      "Speed: 1.5ms preprocess, 1144.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 968.5ms\n",
      "Speed: 1.4ms preprocess, 968.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cow, 1 bear, 1358.1ms\n",
      "Speed: 1.6ms preprocess, 1358.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 cow, 1119.9ms\n",
      "Speed: 1.6ms preprocess, 1119.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 bear, 980.5ms\n",
      "Speed: 1.3ms preprocess, 980.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 2 bears, 542.7ms\n",
      "Speed: 0.6ms preprocess, 542.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1 bear, 1182.1ms\n",
      "Speed: 1.8ms preprocess, 1182.1ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 cow, 1665.3ms\n",
      "Speed: 1.6ms preprocess, 1665.3ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1094.3ms\n",
      "Speed: 1.2ms preprocess, 1094.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 sheep, 714.7ms\n",
      "Speed: 1.1ms preprocess, 714.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 bear, 1407.7ms\n",
      "Speed: 1.3ms preprocess, 1407.7ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1068.0ms\n",
      "Speed: 1.4ms preprocess, 1068.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 827.0ms\n",
      "Speed: 1.1ms preprocess, 827.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1372.2ms\n",
      "Speed: 2.0ms preprocess, 1372.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 904.5ms\n",
      "Speed: 1.4ms preprocess, 904.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 bear, 1156.0ms\n",
      "Speed: 1.8ms preprocess, 1156.0ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1124.1ms\n",
      "Speed: 1.4ms preprocess, 1124.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 dog, 998.6ms\n",
      "Speed: 1.5ms preprocess, 998.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 sheep, 1356.4ms\n",
      "Speed: 1.5ms preprocess, 1356.4ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1445.7ms\n",
      "Speed: 2.3ms preprocess, 1445.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000542.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 cow, 1446.1ms\n",
      "Speed: 2.4ms preprocess, 1446.1ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1313.4ms\n",
      "Speed: 1.6ms preprocess, 1313.4ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1138.4ms\n",
      "Speed: 1.6ms preprocess, 1138.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000545.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1007.7ms\n",
      "Speed: 1.9ms preprocess, 1007.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1016.3ms\n",
      "Speed: 1.4ms preprocess, 1016.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 cow, 1186.3ms\n",
      "Speed: 1.4ms preprocess, 1186.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 910.2ms\n",
      "Speed: 1.2ms preprocess, 910.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 908.6ms\n",
      "Speed: 1.4ms preprocess, 908.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1072.3ms\n",
      "Speed: 1.5ms preprocess, 1072.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1 cow, 836.0ms\n",
      "Speed: 1.2ms preprocess, 836.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 838.7ms\n",
      "Speed: 1.2ms preprocess, 838.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1098.2ms\n",
      "Speed: 1.5ms preprocess, 1098.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000554.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 giraffe, 1075.0ms\n",
      "Speed: 2.2ms preprocess, 1075.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1576.7ms\n",
      "Speed: 1.8ms preprocess, 1576.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 sheep, 1 cow, 864.8ms\n",
      "Speed: 1.2ms preprocess, 864.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 bear, 1371.2ms\n",
      "Speed: 1.2ms preprocess, 1371.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1258.6ms\n",
      "Speed: 1.6ms preprocess, 1258.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 1258.9ms\n",
      "Speed: 1.7ms preprocess, 1258.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 bear, 999.9ms\n",
      "Speed: 1.3ms preprocess, 999.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1066.0ms\n",
      "Speed: 1.6ms preprocess, 1066.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1 cow, 1511.3ms\n",
      "Speed: 1.8ms preprocess, 1511.3ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1133.3ms\n",
      "Speed: 1.3ms preprocess, 1133.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 862.8ms\n",
      "Speed: 1.2ms preprocess, 862.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1111.6ms\n",
      "Speed: 1.3ms preprocess, 1111.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 cats, 1 sheep, 1 bear, 1252.5ms\n",
      "Speed: 1.6ms preprocess, 1252.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 1 bear, 719.7ms\n",
      "Speed: 0.9ms preprocess, 719.7ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 2 bears, 1270.3ms\n",
      "Speed: 1.3ms preprocess, 1270.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1501.9ms\n",
      "Speed: 2.0ms preprocess, 1501.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 horse, 867.8ms\n",
      "Speed: 1.2ms preprocess, 867.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cow, 1256.1ms\n",
      "Speed: 2.0ms preprocess, 1256.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1 bear, 985.5ms\n",
      "Speed: 1.3ms preprocess, 985.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1081.0ms\n",
      "Speed: 1.4ms preprocess, 1081.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 915.6ms\n",
      "Speed: 1.1ms preprocess, 915.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1220.1ms\n",
      "Speed: 1.8ms preprocess, 1220.1ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 cow, 1359.6ms\n",
      "Speed: 1.7ms preprocess, 1359.6ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 832.3ms\n",
      "Speed: 1.0ms preprocess, 832.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1102.1ms\n",
      "Speed: 1.5ms preprocess, 1102.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 5 carrots, 1140.2ms\n",
      "Speed: 1.5ms preprocess, 1140.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 bears, 1702.4ms\n",
      "Speed: 1.6ms preprocess, 1702.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 2484.0ms\n",
      "Speed: 2.9ms preprocess, 2484.0ms inference, 5.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1150.8ms\n",
      "Speed: 1.7ms preprocess, 1150.8ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1213.7ms\n",
      "Speed: 2.5ms preprocess, 1213.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 797.1ms\n",
      "Speed: 1.1ms preprocess, 797.1ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000585.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 961.5ms\n",
      "Speed: 1.4ms preprocess, 961.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1400.7ms\n",
      "Speed: 2.0ms preprocess, 1400.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1127.4ms\n",
      "Speed: 1.6ms preprocess, 1127.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000588.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1395.7ms\n",
      "Speed: 1.7ms preprocess, 1395.7ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 bear, 1542.7ms\n",
      "Speed: 1.7ms preprocess, 1542.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1335.0ms\n",
      "Speed: 1.5ms preprocess, 1335.0ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 bear, 1160.8ms\n",
      "Speed: 1.2ms preprocess, 1160.8ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1535.0ms\n",
      "Speed: 2.5ms preprocess, 1535.0ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1225.9ms\n",
      "Speed: 1.5ms preprocess, 1225.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1146.6ms\n",
      "Speed: 1.4ms preprocess, 1146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1500.3ms\n",
      "Speed: 1.4ms preprocess, 1500.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1076.9ms\n",
      "Speed: 1.3ms preprocess, 1076.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 782.1ms\n",
      "Speed: 1.1ms preprocess, 782.1ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1517.5ms\n",
      "Speed: 1.9ms preprocess, 1517.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 2 bears, 959.1ms\n",
      "Speed: 1.1ms preprocess, 959.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1398.1ms\n",
      "Speed: 1.6ms preprocess, 1398.1ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 horse, 1 cow, 1163.9ms\n",
      "Speed: 1.3ms preprocess, 1163.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1624.9ms\n",
      "Speed: 1.4ms preprocess, 1624.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1 knife, 1245.8ms\n",
      "Speed: 2.1ms preprocess, 1245.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 2 bears, 1390.3ms\n",
      "Speed: 1.7ms preprocess, 1390.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 sheeps, 1086.0ms\n",
      "Speed: 1.7ms preprocess, 1086.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 989.3ms\n",
      "Speed: 1.6ms preprocess, 989.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 3149.5ms\n",
      "Speed: 1.5ms preprocess, 3149.5ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1793.1ms\n",
      "Speed: 3.9ms preprocess, 1793.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1281.0ms\n",
      "Speed: 1.4ms preprocess, 1281.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1445.3ms\n",
      "Speed: 1.5ms preprocess, 1445.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1027.2ms\n",
      "Speed: 1.3ms preprocess, 1027.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 950.0ms\n",
      "Speed: 1.3ms preprocess, 950.0ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1222.2ms\n",
      "Speed: 1.3ms preprocess, 1222.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 cow, 1034.6ms\n",
      "Speed: 1.5ms preprocess, 1034.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 horse, 1386.6ms\n",
      "Speed: 1.6ms preprocess, 1386.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 cow, 1014.6ms\n",
      "Speed: 1.3ms preprocess, 1014.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1130.9ms\n",
      "Speed: 1.6ms preprocess, 1130.9ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1513.3ms\n",
      "Speed: 1.5ms preprocess, 1513.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1276.3ms\n",
      "Speed: 1.3ms preprocess, 1276.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 1 cat, 1 bear, 657.2ms\n",
      "Speed: 1.0ms preprocess, 657.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1063.9ms\n",
      "Speed: 1.8ms preprocess, 1063.9ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1191.7ms\n",
      "Speed: 2.9ms preprocess, 1191.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 bear, 1348.2ms\n",
      "Speed: 1.4ms preprocess, 1348.2ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 898.9ms\n",
      "Speed: 1.0ms preprocess, 898.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1349.4ms\n",
      "Speed: 2.1ms preprocess, 1349.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 945.9ms\n",
      "Speed: 1.3ms preprocess, 945.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 951.9ms\n",
      "Speed: 1.0ms preprocess, 951.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 1585.3ms\n",
      "Speed: 1.8ms preprocess, 1585.3ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1637.0ms\n",
      "Speed: 2.4ms preprocess, 1637.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1320.9ms\n",
      "Speed: 1.8ms preprocess, 1320.9ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000631.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 1 bear, 635.0ms\n",
      "Speed: 1.0ms preprocess, 635.0ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1123.2ms\n",
      "Speed: 1.9ms preprocess, 1123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1419.2ms\n",
      "Speed: 1.5ms preprocess, 1419.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1026.7ms\n",
      "Speed: 1.3ms preprocess, 1026.7ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 bears, 1207.4ms\n",
      "Speed: 1.2ms preprocess, 1207.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1149.8ms\n",
      "Speed: 1.9ms preprocess, 1149.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1153.2ms\n",
      "Speed: 1.9ms preprocess, 1153.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1117.7ms\n",
      "Speed: 2.0ms preprocess, 1117.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 cow, 1466.5ms\n",
      "Speed: 1.8ms preprocess, 1466.5ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1058.3ms\n",
      "Speed: 1.5ms preprocess, 1058.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1259.5ms\n",
      "Speed: 1.7ms preprocess, 1259.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1101.1ms\n",
      "Speed: 1.2ms preprocess, 1101.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 horse, 1 bear, 1287.4ms\n",
      "Speed: 1.8ms preprocess, 1287.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 sheep, 1 cow, 1614.5ms\n",
      "Speed: 1.6ms preprocess, 1614.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 sheep, 1181.9ms\n",
      "Speed: 1.3ms preprocess, 1181.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1041.6ms\n",
      "Speed: 1.4ms preprocess, 1041.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1501.3ms\n",
      "Speed: 2.0ms preprocess, 1501.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1346.1ms\n",
      "Speed: 2.2ms preprocess, 1346.1ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1042.5ms\n",
      "Speed: 1.3ms preprocess, 1042.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1507.5ms\n",
      "Speed: 1.7ms preprocess, 1507.5ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1414.8ms\n",
      "Speed: 1.4ms preprocess, 1414.8ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1108.6ms\n",
      "Speed: 1.1ms preprocess, 1108.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 912.8ms\n",
      "Speed: 1.1ms preprocess, 912.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 horse, 1360.3ms\n",
      "Speed: 1.6ms preprocess, 1360.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1 cow, 1452.8ms\n",
      "Speed: 1.4ms preprocess, 1452.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1249.1ms\n",
      "Speed: 1.2ms preprocess, 1249.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1193.3ms\n",
      "Speed: 1.3ms preprocess, 1193.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 bear, 949.6ms\n",
      "Speed: 1.2ms preprocess, 949.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 895.5ms\n",
      "Speed: 1.1ms preprocess, 895.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1194.6ms\n",
      "Speed: 1.4ms preprocess, 1194.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 2 bears, 1596.2ms\n",
      "Speed: 1.4ms preprocess, 1596.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 2 bears, 1492.6ms\n",
      "Speed: 1.8ms preprocess, 1492.6ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1001.5ms\n",
      "Speed: 1.1ms preprocess, 1001.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1998.4ms\n",
      "Speed: 1.2ms preprocess, 1998.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1096.1ms\n",
      "Speed: 1.4ms preprocess, 1096.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 1 dog, 1 cow, 1 bear, 586.4ms\n",
      "Speed: 1.5ms preprocess, 586.4ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1264.4ms\n",
      "Speed: 1.4ms preprocess, 1264.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1355.9ms\n",
      "Speed: 2.2ms preprocess, 1355.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1332.7ms\n",
      "Speed: 1.5ms preprocess, 1332.7ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1487.9ms\n",
      "Speed: 2.7ms preprocess, 1487.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000671.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1111.2ms\n",
      "Speed: 1.4ms preprocess, 1111.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1223.7ms\n",
      "Speed: 1.5ms preprocess, 1223.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1059.0ms\n",
      "Speed: 1.2ms preprocess, 1059.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1342.8ms\n",
      "Speed: 1.5ms preprocess, 1342.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1482.4ms\n",
      "Speed: 1.3ms preprocess, 1482.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1147.4ms\n",
      "Speed: 1.6ms preprocess, 1147.4ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000677.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1188.3ms\n",
      "Speed: 2.0ms preprocess, 1188.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1345.8ms\n",
      "Speed: 2.1ms preprocess, 1345.8ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 2590.7ms\n",
      "Speed: 2.2ms preprocess, 2590.7ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000680.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1390.5ms\n",
      "Speed: 2.1ms preprocess, 1390.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1176.3ms\n",
      "Speed: 1.3ms preprocess, 1176.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1316.0ms\n",
      "Speed: 2.7ms preprocess, 1316.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bird, 1 dog, 1 sheep, 2002.7ms\n",
      "Speed: 3.4ms preprocess, 2002.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1092.3ms\n",
      "Speed: 1.4ms preprocess, 1092.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1534.3ms\n",
      "Speed: 1.5ms preprocess, 1534.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1541.2ms\n",
      "Speed: 2.6ms preprocess, 1541.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1935.7ms\n",
      "Speed: 1.8ms preprocess, 1935.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1145.6ms\n",
      "Speed: 1.5ms preprocess, 1145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1714.1ms\n",
      "Speed: 2.0ms preprocess, 1714.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1368.1ms\n",
      "Speed: 1.6ms preprocess, 1368.1ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000691.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1742.0ms\n",
      "Speed: 2.0ms preprocess, 1742.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1971.6ms\n",
      "Speed: 2.1ms preprocess, 1971.6ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 3466.9ms\n",
      "Speed: 3.0ms preprocess, 3466.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1757.6ms\n",
      "Speed: 1.9ms preprocess, 1757.6ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 2 bears, 1872.9ms\n",
      "Speed: 1.9ms preprocess, 1872.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 920.5ms\n",
      "Speed: 1.4ms preprocess, 920.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 (no detections), 912.2ms\n",
      "Speed: 1.5ms preprocess, 912.2ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000698.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 bear, 1770.0ms\n",
      "Speed: 1.6ms preprocess, 1770.0ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1537.2ms\n",
      "Speed: 2.1ms preprocess, 1537.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1256.6ms\n",
      "Speed: 1.2ms preprocess, 1256.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1063.4ms\n",
      "Speed: 1.9ms preprocess, 1063.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1347.2ms\n",
      "Speed: 2.7ms preprocess, 1347.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 bears, 1382.8ms\n",
      "Speed: 1.7ms preprocess, 1382.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 2 bears, 1 giraffe, 1568.5ms\n",
      "Speed: 1.6ms preprocess, 1568.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1825.5ms\n",
      "Speed: 1.5ms preprocess, 1825.5ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1 sheep, 1821.8ms\n",
      "Speed: 2.1ms preprocess, 1821.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1274.3ms\n",
      "Speed: 2.4ms preprocess, 1274.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 sheep, 1 cow, 1603.3ms\n",
      "Speed: 11.4ms preprocess, 1603.3ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1444.3ms\n",
      "Speed: 1.7ms preprocess, 1444.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 bear, 1775.1ms\n",
      "Speed: 2.1ms preprocess, 1775.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1001.6ms\n",
      "Speed: 1.7ms preprocess, 1001.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1255.9ms\n",
      "Speed: 1.6ms preprocess, 1255.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 cow, 1819.1ms\n",
      "Speed: 2.0ms preprocess, 1819.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1038.0ms\n",
      "Speed: 2.3ms preprocess, 1038.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1496.2ms\n",
      "Speed: 1.6ms preprocess, 1496.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1541.8ms\n",
      "Speed: 1.8ms preprocess, 1541.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1457.6ms\n",
      "Speed: 2.4ms preprocess, 1457.6ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000718.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 2 sheeps, 1156.6ms\n",
      "Speed: 1.5ms preprocess, 1156.6ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1836.1ms\n",
      "Speed: 2.3ms preprocess, 1836.1ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1 bear, 1430.0ms\n",
      "Speed: 1.5ms preprocess, 1430.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1289.2ms\n",
      "Speed: 1.7ms preprocess, 1289.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1871.7ms\n",
      "Speed: 1.7ms preprocess, 1871.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 cow, 1798.8ms\n",
      "Speed: 2.9ms preprocess, 1798.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 1 bear, 611.3ms\n",
      "Speed: 0.9ms preprocess, 611.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1 bear, 1317.3ms\n",
      "Speed: 1.2ms preprocess, 1317.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cow, 1591.9ms\n",
      "Speed: 11.5ms preprocess, 1591.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 bears, 1674.1ms\n",
      "Speed: 1.7ms preprocess, 1674.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 bear, 1281.7ms\n",
      "Speed: 1.5ms preprocess, 1281.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 (no detections), 1481.8ms\n",
      "Speed: 1.4ms preprocess, 1481.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000730.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1725.8ms\n",
      "Speed: 2.1ms preprocess, 1725.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 2280.9ms\n",
      "Speed: 2.3ms preprocess, 2280.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1 bear, 1867.5ms\n",
      "Speed: 1.6ms preprocess, 1867.5ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1187.5ms\n",
      "Speed: 1.4ms preprocess, 1187.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 bear, 1071.1ms\n",
      "Speed: 1.1ms preprocess, 1071.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 2130.6ms\n",
      "Speed: 1.8ms preprocess, 2130.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1411.8ms\n",
      "Speed: 1.8ms preprocess, 1411.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 persons, 1 bear, 1841.4ms\n",
      "Speed: 1.8ms preprocess, 1841.4ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 2572.2ms\n",
      "Speed: 2.6ms preprocess, 2572.2ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 2052.7ms\n",
      "Speed: 1.6ms preprocess, 2052.7ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 dogs, 1 sheep, 1583.6ms\n",
      "Speed: 1.8ms preprocess, 1583.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1382.2ms\n",
      "Speed: 2.5ms preprocess, 1382.2ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 2127.9ms\n",
      "Speed: 2.5ms preprocess, 2127.9ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 979.9ms\n",
      "Speed: 1.4ms preprocess, 979.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1913.5ms\n",
      "Speed: 3.1ms preprocess, 1913.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1348.6ms\n",
      "Speed: 1.6ms preprocess, 1348.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1829.7ms\n",
      "Speed: 1.9ms preprocess, 1829.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1331.5ms\n",
      "Speed: 1.6ms preprocess, 1331.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 giraffe, 1944.5ms\n",
      "Speed: 2.1ms preprocess, 1944.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2140.7ms\n",
      "Speed: 2.4ms preprocess, 2140.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 2391.5ms\n",
      "Speed: 2.7ms preprocess, 2391.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000751.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1429.0ms\n",
      "Speed: 1.6ms preprocess, 1429.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1 giraffe, 1612.9ms\n",
      "Speed: 2.0ms preprocess, 1612.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 2662.8ms\n",
      "Speed: 1.6ms preprocess, 2662.8ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cow, 1088.0ms\n",
      "Speed: 1.4ms preprocess, 1088.0ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1252.1ms\n",
      "Speed: 1.7ms preprocess, 1252.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1642.5ms\n",
      "Speed: 1.6ms preprocess, 1642.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 2760.2ms\n",
      "Speed: 1.7ms preprocess, 2760.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1435.8ms\n",
      "Speed: 1.5ms preprocess, 1435.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1568.2ms\n",
      "Speed: 1.6ms preprocess, 1568.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 zebra, 2081.6ms\n",
      "Speed: 1.9ms preprocess, 2081.6ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 dog, 1871.5ms\n",
      "Speed: 1.5ms preprocess, 1871.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1355.5ms\n",
      "Speed: 1.8ms preprocess, 1355.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cow, 2430.4ms\n",
      "Speed: 1.9ms preprocess, 2430.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 horse, 2627.4ms\n",
      "Speed: 1.9ms preprocess, 2627.4ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 cow, 1010.7ms\n",
      "Speed: 2.0ms preprocess, 1010.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 bear, 793.2ms\n",
      "Speed: 1.0ms preprocess, 793.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 bear, 1390.4ms\n",
      "Speed: 1.7ms preprocess, 1390.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1368.1ms\n",
      "Speed: 2.1ms preprocess, 1368.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1293.1ms\n",
      "Speed: 1.7ms preprocess, 1293.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1261.0ms\n",
      "Speed: 2.2ms preprocess, 1261.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1054.2ms\n",
      "Speed: 1.4ms preprocess, 1054.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 dog, 1134.8ms\n",
      "Speed: 1.5ms preprocess, 1134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1348.6ms\n",
      "Speed: 1.7ms preprocess, 1348.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1192.8ms\n",
      "Speed: 1.2ms preprocess, 1192.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1242.5ms\n",
      "Speed: 1.8ms preprocess, 1242.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 777.1ms\n",
      "Speed: 1.0ms preprocess, 777.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1174.5ms\n",
      "Speed: 1.9ms preprocess, 1174.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1163.9ms\n",
      "Speed: 1.4ms preprocess, 1163.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 2276.4ms\n",
      "Speed: 1.9ms preprocess, 2276.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000780.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1289.9ms\n",
      "Speed: 1.7ms preprocess, 1289.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1960.3ms\n",
      "Speed: 1.9ms preprocess, 1960.3ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1154.3ms\n",
      "Speed: 1.3ms preprocess, 1154.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 giraffe, 1605.6ms\n",
      "Speed: 1.8ms preprocess, 1605.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 dog, 1 bear, 1652.6ms\n",
      "Speed: 1.5ms preprocess, 1652.6ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 2 dogs, 1 horse, 1220.2ms\n",
      "Speed: 1.5ms preprocess, 1220.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1664.7ms\n",
      "Speed: 2.0ms preprocess, 1664.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2827.1ms\n",
      "Speed: 2.0ms preprocess, 2827.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 dog, 1159.6ms\n",
      "Speed: 1.5ms preprocess, 1159.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 cow, 1 bear, 1495.5ms\n",
      "Speed: 1.6ms preprocess, 1495.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 1895.7ms\n",
      "Speed: 1.9ms preprocess, 1895.7ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 cat, 1029.6ms\n",
      "Speed: 1.5ms preprocess, 1029.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1453.4ms\n",
      "Speed: 3.1ms preprocess, 1453.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 bear, 973.1ms\n",
      "Speed: 2.4ms preprocess, 973.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 sheep, 1638.7ms\n",
      "Speed: 1.7ms preprocess, 1638.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1536.3ms\n",
      "Speed: 1.9ms preprocess, 1536.3ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1132.2ms\n",
      "Speed: 1.3ms preprocess, 1132.2ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 traffic light, 1 bear, 1205.6ms\n",
      "Speed: 1.3ms preprocess, 1205.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 bear, 1336.9ms\n",
      "Speed: 1.9ms preprocess, 1336.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 2 dogs, 1239.8ms\n",
      "Speed: 1.5ms preprocess, 1239.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 sheep, 1409.3ms\n",
      "Speed: 1.6ms preprocess, 1409.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1511.4ms\n",
      "Speed: 1.7ms preprocess, 1511.4ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1401.1ms\n",
      "Speed: 1.9ms preprocess, 1401.1ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000803.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 horse, 1298.3ms\n",
      "Speed: 1.8ms preprocess, 1298.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 2 bears, 1528.4ms\n",
      "Speed: 2.8ms preprocess, 1528.4ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 2640.9ms\n",
      "Speed: 1.8ms preprocess, 2640.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 horse, 1622.8ms\n",
      "Speed: 1.9ms preprocess, 1622.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1413.5ms\n",
      "Speed: 1.4ms preprocess, 1413.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1276.4ms\n",
      "Speed: 1.7ms preprocess, 1276.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1322.9ms\n",
      "Speed: 2.0ms preprocess, 1322.9ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000810.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1229.2ms\n",
      "Speed: 1.7ms preprocess, 1229.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1217.9ms\n",
      "Speed: 1.5ms preprocess, 1217.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1115.0ms\n",
      "Speed: 1.8ms preprocess, 1115.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1516.5ms\n",
      "Speed: 1.3ms preprocess, 1516.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1492.1ms\n",
      "Speed: 2.2ms preprocess, 1492.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1218.2ms\n",
      "Speed: 1.4ms preprocess, 1218.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 bear, 2389.2ms\n",
      "Speed: 1.7ms preprocess, 2389.2ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1067.1ms\n",
      "Speed: 1.5ms preprocess, 1067.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1460.2ms\n",
      "Speed: 1.5ms preprocess, 1460.2ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000819.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 952.6ms\n",
      "Speed: 1.4ms preprocess, 952.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1404.9ms\n",
      "Speed: 1.9ms preprocess, 1404.9ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1128.2ms\n",
      "Speed: 1.2ms preprocess, 1128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1193.3ms\n",
      "Speed: 1.6ms preprocess, 1193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1331.4ms\n",
      "Speed: 1.7ms preprocess, 1331.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1230.1ms\n",
      "Speed: 1.9ms preprocess, 1230.1ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000825.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 931.0ms\n",
      "Speed: 1.3ms preprocess, 931.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1011.4ms\n",
      "Speed: 1.7ms preprocess, 1011.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1 giraffe, 1711.6ms\n",
      "Speed: 2.2ms preprocess, 1711.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1541.9ms\n",
      "Speed: 2.2ms preprocess, 1541.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1319.1ms\n",
      "Speed: 1.6ms preprocess, 1319.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 2921.2ms\n",
      "Speed: 1.5ms preprocess, 2921.2ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1315.0ms\n",
      "Speed: 1.5ms preprocess, 1315.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1166.3ms\n",
      "Speed: 1.6ms preprocess, 1166.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1197.1ms\n",
      "Speed: 1.6ms preprocess, 1197.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1127.4ms\n",
      "Speed: 1.4ms preprocess, 1127.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000835.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 899.9ms\n",
      "Speed: 1.1ms preprocess, 899.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1592.4ms\n",
      "Speed: 2.4ms preprocess, 1592.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 bear, 1528.8ms\n",
      "Speed: 1.4ms preprocess, 1528.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1 sheep, 1362.0ms\n",
      "Speed: 1.7ms preprocess, 1362.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 2 dogs, 1 bear, 1541.5ms\n",
      "Speed: 1.8ms preprocess, 1541.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1696.6ms\n",
      "Speed: 1.9ms preprocess, 1696.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1329.7ms\n",
      "Speed: 1.3ms preprocess, 1329.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1647.0ms\n",
      "Speed: 1.4ms preprocess, 1647.0ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 bear, 2789.5ms\n",
      "Speed: 1.8ms preprocess, 2789.5ms inference, 2.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1 bear, 1166.3ms\n",
      "Speed: 1.4ms preprocess, 1166.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1121.3ms\n",
      "Speed: 1.6ms preprocess, 1121.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1256.4ms\n",
      "Speed: 1.6ms preprocess, 1256.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 986.5ms\n",
      "Speed: 1.2ms preprocess, 986.5ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000848.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 915.7ms\n",
      "Speed: 1.1ms preprocess, 915.7ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000849.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 887.4ms\n",
      "Speed: 1.3ms preprocess, 887.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1191.3ms\n",
      "Speed: 1.5ms preprocess, 1191.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 957.8ms\n",
      "Speed: 1.1ms preprocess, 957.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000852.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1119.9ms\n",
      "Speed: 1.1ms preprocess, 1119.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cow, 1 bear, 830.3ms\n",
      "Speed: 0.9ms preprocess, 830.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1193.3ms\n",
      "Speed: 1.3ms preprocess, 1193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1791.9ms\n",
      "Speed: 1.5ms preprocess, 1791.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1256.2ms\n",
      "Speed: 7.2ms preprocess, 1256.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1574.8ms\n",
      "Speed: 1.8ms preprocess, 1574.8ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1472.0ms\n",
      "Speed: 1.9ms preprocess, 1472.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 2 cows, 2219.2ms\n",
      "Speed: 1.9ms preprocess, 2219.2ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1340.5ms\n",
      "Speed: 2.0ms preprocess, 1340.5ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000861.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1706.3ms\n",
      "Speed: 1.9ms preprocess, 1706.3ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 980.2ms\n",
      "Speed: 1.6ms preprocess, 980.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1186.0ms\n",
      "Speed: 1.7ms preprocess, 1186.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1165.5ms\n",
      "Speed: 1.4ms preprocess, 1165.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1054.2ms\n",
      "Speed: 1.6ms preprocess, 1054.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 1555.0ms\n",
      "Speed: 1.6ms preprocess, 1555.0ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 cow, 1007.1ms\n",
      "Speed: 1.2ms preprocess, 1007.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 bear, 1346.7ms\n",
      "Speed: 1.4ms preprocess, 1346.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 carrot, 2011.5ms\n",
      "Speed: 2.2ms preprocess, 2011.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1546.4ms\n",
      "Speed: 2.2ms preprocess, 1546.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 giraffe, 1622.2ms\n",
      "Speed: 2.1ms preprocess, 1622.2ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 2021.5ms\n",
      "Speed: 1.8ms preprocess, 2021.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 dog, 1 horse, 1 cow, 1305.0ms\n",
      "Speed: 1.8ms preprocess, 1305.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 2 bears, 1137.8ms\n",
      "Speed: 1.9ms preprocess, 1137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1197.9ms\n",
      "Speed: 1.7ms preprocess, 1197.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1166.9ms\n",
      "Speed: 1.4ms preprocess, 1166.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1040.2ms\n",
      "Speed: 1.8ms preprocess, 1040.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 955.8ms\n",
      "Speed: 1.7ms preprocess, 955.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1778.2ms\n",
      "Speed: 1.7ms preprocess, 1778.2ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2133.8ms\n",
      "Speed: 1.8ms preprocess, 2133.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1457.8ms\n",
      "Speed: 1.8ms preprocess, 1457.8ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 giraffe, 1415.0ms\n",
      "Speed: 3.3ms preprocess, 1415.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 cat, 1849.9ms\n",
      "Speed: 2.4ms preprocess, 1849.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1932.0ms\n",
      "Speed: 3.0ms preprocess, 1932.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 person, 1 dog, 2965.0ms\n",
      "Speed: 4.4ms preprocess, 2965.0ms inference, 3.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 bear, 1150.8ms\n",
      "Speed: 1.8ms preprocess, 1150.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 dog, 1 sheep, 1074.5ms\n",
      "Speed: 1.4ms preprocess, 1074.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1376.0ms\n",
      "Speed: 1.6ms preprocess, 1376.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1 cow, 1624.4ms\n",
      "Speed: 1.7ms preprocess, 1624.4ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1495.7ms\n",
      "Speed: 2.1ms preprocess, 1495.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1330.1ms\n",
      "Speed: 1.9ms preprocess, 1330.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1098.1ms\n",
      "Speed: 1.4ms preprocess, 1098.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1928.0ms\n",
      "Speed: 2.4ms preprocess, 1928.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1579.6ms\n",
      "Speed: 2.0ms preprocess, 1579.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 horse, 2131.9ms\n",
      "Speed: 1.7ms preprocess, 2131.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1445.4ms\n",
      "Speed: 1.8ms preprocess, 1445.4ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1294.4ms\n",
      "Speed: 1.5ms preprocess, 1294.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 sheep, 1337.7ms\n",
      "Speed: 1.5ms preprocess, 1337.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cake, 998.0ms\n",
      "Speed: 1.2ms preprocess, 998.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1165.0ms\n",
      "Speed: 1.4ms preprocess, 1165.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1059.9ms\n",
      "Speed: 1.4ms preprocess, 1059.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1147.7ms\n",
      "Speed: 1.3ms preprocess, 1147.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 person, 1 dog, 1 sheep, 1397.9ms\n",
      "Speed: 1.8ms preprocess, 1397.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1050.5ms\n",
      "Speed: 1.7ms preprocess, 1050.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1255.4ms\n",
      "Speed: 1.5ms preprocess, 1255.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 horse, 1 sheep, 1083.9ms\n",
      "Speed: 1.3ms preprocess, 1083.9ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1689.6ms\n",
      "Speed: 1.9ms preprocess, 1689.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1727.1ms\n",
      "Speed: 1.3ms preprocess, 1727.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1049.8ms\n",
      "Speed: 1.5ms preprocess, 1049.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1163.9ms\n",
      "Speed: 1.5ms preprocess, 1163.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 dog, 1048.3ms\n",
      "Speed: 1.2ms preprocess, 1048.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1165.5ms\n",
      "Speed: 1.7ms preprocess, 1165.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1230.2ms\n",
      "Speed: 1.4ms preprocess, 1230.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1300.2ms\n",
      "Speed: 6.7ms preprocess, 1300.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1274.6ms\n",
      "Speed: 1.7ms preprocess, 1274.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1160.2ms\n",
      "Speed: 1.5ms preprocess, 1160.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 sheep, 1289.0ms\n",
      "Speed: 1.3ms preprocess, 1289.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1 sheep, 916.3ms\n",
      "Speed: 1.3ms preprocess, 916.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1335.4ms\n",
      "Speed: 1.2ms preprocess, 1335.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000920.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1319.5ms\n",
      "Speed: 1.9ms preprocess, 1319.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1683.4ms\n",
      "Speed: 1.2ms preprocess, 1683.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1851.0ms\n",
      "Speed: 1.9ms preprocess, 1851.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1589.5ms\n",
      "Speed: 1.9ms preprocess, 1589.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 dog, 1429.0ms\n",
      "Speed: 1.5ms preprocess, 1429.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1611.3ms\n",
      "Speed: 1.8ms preprocess, 1611.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 999.6ms\n",
      "Speed: 1.7ms preprocess, 999.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 997.2ms\n",
      "Speed: 1.4ms preprocess, 997.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1215.5ms\n",
      "Speed: 1.7ms preprocess, 1215.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1770.9ms\n",
      "Speed: 2.3ms preprocess, 1770.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1566.1ms\n",
      "Speed: 6.4ms preprocess, 1566.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x320 1 horse, 1071.5ms\n",
      "Speed: 1.4ms preprocess, 1071.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 320)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1390.9ms\n",
      "Speed: 1.3ms preprocess, 1390.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1 sheep, 1729.2ms\n",
      "Speed: 2.0ms preprocess, 1729.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1558.5ms\n",
      "Speed: 1.4ms preprocess, 1558.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1040.1ms\n",
      "Speed: 1.2ms preprocess, 1040.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1724.1ms\n",
      "Speed: 2.3ms preprocess, 1724.1ms inference, 0.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000937.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 2 sheeps, 993.0ms\n",
      "Speed: 1.3ms preprocess, 993.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1549.5ms\n",
      "Speed: 1.8ms preprocess, 1549.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 sheep, 1 bear, 1460.0ms\n",
      "Speed: 1.5ms preprocess, 1460.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1324.1ms\n",
      "Speed: 1.7ms preprocess, 1324.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1 bear, 1225.6ms\n",
      "Speed: 1.7ms preprocess, 1225.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1692.6ms\n",
      "Speed: 1.8ms preprocess, 1692.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 cats, 1357.7ms\n",
      "Speed: 2.0ms preprocess, 1357.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 elephant, 1334.3ms\n",
      "Speed: 1.7ms preprocess, 1334.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 horse, 1 sheep, 1132.6ms\n",
      "Speed: 1.3ms preprocess, 1132.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 1 sheep, 2 bears, 627.8ms\n",
      "Speed: 0.9ms preprocess, 627.8ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1153.0ms\n",
      "Speed: 1.6ms preprocess, 1153.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1588.4ms\n",
      "Speed: 1.7ms preprocess, 1588.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 2080.8ms\n",
      "Speed: 1.5ms preprocess, 2080.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1 bear, 1664.3ms\n",
      "Speed: 1.5ms preprocess, 1664.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1516.5ms\n",
      "Speed: 2.3ms preprocess, 1516.5ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1284.9ms\n",
      "Speed: 1.3ms preprocess, 1284.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 968.7ms\n",
      "Speed: 1.5ms preprocess, 968.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1581.5ms\n",
      "Speed: 1.7ms preprocess, 1581.5ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1311.3ms\n",
      "Speed: 1.7ms preprocess, 1311.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 (no detections), 1262.9ms\n",
      "Speed: 1.6ms preprocess, 1262.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000957.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1437.4ms\n",
      "Speed: 1.7ms preprocess, 1437.4ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1 sheep, 1538.6ms\n",
      "Speed: 1.7ms preprocess, 1538.6ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1320.9ms\n",
      "Speed: 1.6ms preprocess, 1320.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1 bear, 1567.1ms\n",
      "Speed: 1.9ms preprocess, 1567.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1472.9ms\n",
      "Speed: 1.6ms preprocess, 1472.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 2169.0ms\n",
      "Speed: 1.6ms preprocess, 2169.0ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 935.1ms\n",
      "Speed: 1.4ms preprocess, 935.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x320 1 dog, 1 bear, 895.5ms\n",
      "Speed: 1.2ms preprocess, 895.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1034.4ms\n",
      "Speed: 1.5ms preprocess, 1034.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000966.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 bears, 1351.8ms\n",
      "Speed: 1.8ms preprocess, 1351.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1388.1ms\n",
      "Speed: 2.9ms preprocess, 1388.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000968.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1349.5ms\n",
      "Speed: 1.5ms preprocess, 1349.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1478.5ms\n",
      "Speed: 1.6ms preprocess, 1478.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 horse, 1670.7ms\n",
      "Speed: 2.9ms preprocess, 1670.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1489.3ms\n",
      "Speed: 2.0ms preprocess, 1489.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000972.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1226.8ms\n",
      "Speed: 1.8ms preprocess, 1226.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 1137.4ms\n",
      "Speed: 1.8ms preprocess, 1137.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 cow, 1 carrot, 1230.7ms\n",
      "Speed: 1.7ms preprocess, 1230.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1707.3ms\n",
      "Speed: 1.7ms preprocess, 1707.3ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1232.1ms\n",
      "Speed: 1.4ms preprocess, 1232.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 2015.0ms\n",
      "Speed: 2.6ms preprocess, 2015.0ms inference, 0.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000978.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 horse, 1290.4ms\n",
      "Speed: 1.9ms preprocess, 1290.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1026.0ms\n",
      "Speed: 1.5ms preprocess, 1026.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000000980.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1128.1ms\n",
      "Speed: 1.4ms preprocess, 1128.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1327.3ms\n",
      "Speed: 1.4ms preprocess, 1327.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1673.5ms\n",
      "Speed: 1.7ms preprocess, 1673.5ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 sheep, 1316.2ms\n",
      "Speed: 1.6ms preprocess, 1316.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1429.0ms\n",
      "Speed: 2.2ms preprocess, 1429.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1263.2ms\n",
      "Speed: 1.6ms preprocess, 1263.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1416.2ms\n",
      "Speed: 2.0ms preprocess, 1416.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1355.9ms\n",
      "Speed: 1.8ms preprocess, 1355.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 bear, 1823.2ms\n",
      "Speed: 2.3ms preprocess, 1823.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1308.0ms\n",
      "Speed: 1.8ms preprocess, 1308.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1437.5ms\n",
      "Speed: 1.5ms preprocess, 1437.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1317.5ms\n",
      "Speed: 1.9ms preprocess, 1317.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1761.6ms\n",
      "Speed: 2.0ms preprocess, 1761.6ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1 bear, 2390.5ms\n",
      "Speed: 2.7ms preprocess, 2390.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1089.7ms\n",
      "Speed: 1.2ms preprocess, 1089.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 bears, 1450.5ms\n",
      "Speed: 2.0ms preprocess, 1450.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 cat, 1092.0ms\n",
      "Speed: 1.4ms preprocess, 1092.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 2039.5ms\n",
      "Speed: 1.9ms preprocess, 2039.5ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1849.2ms\n",
      "Speed: 1.6ms preprocess, 1849.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1400.1ms\n",
      "Speed: 1.9ms preprocess, 1400.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1428.4ms\n",
      "Speed: 1.6ms preprocess, 1428.4ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 2673.1ms\n",
      "Speed: 1.6ms preprocess, 2673.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1824.5ms\n",
      "Speed: 1.9ms preprocess, 1824.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 sheep, 1463.8ms\n",
      "Speed: 1.8ms preprocess, 1463.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 potted plant, 1447.3ms\n",
      "Speed: 1.5ms preprocess, 1447.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 1664.3ms\n",
      "Speed: 1.9ms preprocess, 1664.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1689.9ms\n",
      "Speed: 1.6ms preprocess, 1689.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1158.2ms\n",
      "Speed: 1.4ms preprocess, 1158.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1403.3ms\n",
      "Speed: 1.6ms preprocess, 1403.3ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 1 cow, 1570.3ms\n",
      "Speed: 1.6ms preprocess, 1570.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1228.5ms\n",
      "Speed: 1.5ms preprocess, 1228.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1603.4ms\n",
      "Speed: 1.7ms preprocess, 1603.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 949.0ms\n",
      "Speed: 1.2ms preprocess, 949.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1398.4ms\n",
      "Speed: 1.3ms preprocess, 1398.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 2742.1ms\n",
      "Speed: 2.3ms preprocess, 2742.1ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1181.8ms\n",
      "Speed: 1.8ms preprocess, 1181.8ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1301.5ms\n",
      "Speed: 1.7ms preprocess, 1301.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1303.5ms\n",
      "Speed: 1.8ms preprocess, 1303.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 cow, 1525.2ms\n",
      "Speed: 1.4ms preprocess, 1525.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1159.9ms\n",
      "Speed: 1.4ms preprocess, 1159.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1237.8ms\n",
      "Speed: 1.7ms preprocess, 1237.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1279.8ms\n",
      "Speed: 2.1ms preprocess, 1279.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 horse, 1571.1ms\n",
      "Speed: 2.0ms preprocess, 1571.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cow, 1569.4ms\n",
      "Speed: 1.5ms preprocess, 1569.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1090.0ms\n",
      "Speed: 1.6ms preprocess, 1090.0ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1703.5ms\n",
      "Speed: 1.9ms preprocess, 1703.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 2353.5ms\n",
      "Speed: 1.3ms preprocess, 2353.5ms inference, 9.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1667.7ms\n",
      "Speed: 3.7ms preprocess, 1667.7ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001028.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 1692.2ms\n",
      "Speed: 2.3ms preprocess, 1692.2ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cow, 1 bear, 1770.0ms\n",
      "Speed: 2.4ms preprocess, 1770.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1 giraffe, 2116.0ms\n",
      "Speed: 1.7ms preprocess, 2116.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 bear, 1337.6ms\n",
      "Speed: 1.6ms preprocess, 1337.6ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1525.6ms\n",
      "Speed: 1.9ms preprocess, 1525.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1242.3ms\n",
      "Speed: 1.6ms preprocess, 1242.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1 bear, 1791.1ms\n",
      "Speed: 1.9ms preprocess, 1791.1ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1823.7ms\n",
      "Speed: 1.5ms preprocess, 1823.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1637.5ms\n",
      "Speed: 2.1ms preprocess, 1637.5ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1194.0ms\n",
      "Speed: 1.3ms preprocess, 1194.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1338.1ms\n",
      "Speed: 2.2ms preprocess, 1338.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001039.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1642.2ms\n",
      "Speed: 2.2ms preprocess, 1642.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x288 1 bear, 856.5ms\n",
      "Speed: 1.1ms preprocess, 856.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1432.8ms\n",
      "Speed: 1.5ms preprocess, 1432.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 sheep, 1452.3ms\n",
      "Speed: 1.9ms preprocess, 1452.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1494.5ms\n",
      "Speed: 2.1ms preprocess, 1494.5ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001044.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1476.6ms\n",
      "Speed: 2.2ms preprocess, 1476.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1438.0ms\n",
      "Speed: 1.9ms preprocess, 1438.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 1 bear, 1055.8ms\n",
      "Speed: 1.5ms preprocess, 1055.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 2 bears, 1215.8ms\n",
      "Speed: 1.6ms preprocess, 1215.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 2691.4ms\n",
      "Speed: 1.6ms preprocess, 2691.4ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1450.1ms\n",
      "Speed: 2.1ms preprocess, 1450.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 899.4ms\n",
      "Speed: 1.1ms preprocess, 899.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1 cow, 1186.9ms\n",
      "Speed: 1.5ms preprocess, 1186.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1143.9ms\n",
      "Speed: 1.4ms preprocess, 1143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1370.4ms\n",
      "Speed: 1.6ms preprocess, 1370.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1162.3ms\n",
      "Speed: 1.6ms preprocess, 1162.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 horse, 1605.9ms\n",
      "Speed: 1.6ms preprocess, 1605.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1404.2ms\n",
      "Speed: 1.8ms preprocess, 1404.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1165.0ms\n",
      "Speed: 1.4ms preprocess, 1165.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1733.5ms\n",
      "Speed: 2.0ms preprocess, 1733.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 car, 1 bear, 1676.1ms\n",
      "Speed: 1.9ms preprocess, 1676.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1195.0ms\n",
      "Speed: 1.5ms preprocess, 1195.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1832.5ms\n",
      "Speed: 1.5ms preprocess, 1832.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1136.5ms\n",
      "Speed: 1.4ms preprocess, 1136.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1654.0ms\n",
      "Speed: 1.7ms preprocess, 1654.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1297.8ms\n",
      "Speed: 3.9ms preprocess, 1297.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1421.9ms\n",
      "Speed: 1.9ms preprocess, 1421.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 2 cows, 1094.4ms\n",
      "Speed: 1.4ms preprocess, 1094.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 dog, 1 bear, 1122.9ms\n",
      "Speed: 1.1ms preprocess, 1122.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1461.2ms\n",
      "Speed: 1.9ms preprocess, 1461.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001069.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 cow, 1973.6ms\n",
      "Speed: 2.8ms preprocess, 1973.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1408.1ms\n",
      "Speed: 1.9ms preprocess, 1408.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 bear, 1700.9ms\n",
      "Speed: 1.9ms preprocess, 1700.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1249.4ms\n",
      "Speed: 1.6ms preprocess, 1249.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 2073.0ms\n",
      "Speed: 2.3ms preprocess, 2073.0ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 1543.5ms\n",
      "Speed: 1.5ms preprocess, 1543.5ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cow, 1638.3ms\n",
      "Speed: 2.0ms preprocess, 1638.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bird, 2 bears, 1418.2ms\n",
      "Speed: 1.7ms preprocess, 1418.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 sheep, 1334.9ms\n",
      "Speed: 1.9ms preprocess, 1334.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1 bear, 1517.3ms\n",
      "Speed: 1.7ms preprocess, 1517.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 1678.1ms\n",
      "Speed: 1.8ms preprocess, 1678.1ms inference, 0.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001080.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 (no detections), 1671.1ms\n",
      "Speed: 3.2ms preprocess, 1671.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001081.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1274.0ms\n",
      "Speed: 1.7ms preprocess, 1274.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1600.9ms\n",
      "Speed: 1.6ms preprocess, 1600.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1138.3ms\n",
      "Speed: 1.4ms preprocess, 1138.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 giraffe, 1481.0ms\n",
      "Speed: 2.0ms preprocess, 1481.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 2604.4ms\n",
      "Speed: 1.7ms preprocess, 2604.4ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 2318.5ms\n",
      "Speed: 3.0ms preprocess, 2318.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1370.3ms\n",
      "Speed: 1.4ms preprocess, 1370.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 bear, 1502.4ms\n",
      "Speed: 1.8ms preprocess, 1502.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1526.3ms\n",
      "Speed: 1.9ms preprocess, 1526.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1191.6ms\n",
      "Speed: 1.5ms preprocess, 1191.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 2256.9ms\n",
      "Speed: 4.8ms preprocess, 2256.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1529.8ms\n",
      "Speed: 1.9ms preprocess, 1529.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1 giraffe, 1435.9ms\n",
      "Speed: 1.6ms preprocess, 1435.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 bear, 1462.0ms\n",
      "Speed: 1.8ms preprocess, 1462.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1705.6ms\n",
      "Speed: 2.2ms preprocess, 1705.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1277.0ms\n",
      "Speed: 1.8ms preprocess, 1277.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 horse, 3062.5ms\n",
      "Speed: 1.6ms preprocess, 3062.5ms inference, 3.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1646.5ms\n",
      "Speed: 1.6ms preprocess, 1646.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1635.3ms\n",
      "Speed: 2.1ms preprocess, 1635.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 bear, 818.4ms\n",
      "Speed: 1.2ms preprocess, 818.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1 sheep, 1121.7ms\n",
      "Speed: 1.4ms preprocess, 1121.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1579.5ms\n",
      "Speed: 2.1ms preprocess, 1579.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 sheep, 1 bear, 2498.7ms\n",
      "Speed: 2.7ms preprocess, 2498.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 2643.5ms\n",
      "Speed: 2.2ms preprocess, 2643.5ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1285.2ms\n",
      "Speed: 1.3ms preprocess, 1285.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 2166.4ms\n",
      "Speed: 2.5ms preprocess, 2166.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1301.1ms\n",
      "Speed: 1.9ms preprocess, 1301.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1117.8ms\n",
      "Speed: 1.3ms preprocess, 1117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001109.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 bear, 2312.9ms\n",
      "Speed: 2.4ms preprocess, 2312.9ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1691.9ms\n",
      "Speed: 1.7ms preprocess, 1691.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1375.9ms\n",
      "Speed: 1.9ms preprocess, 1375.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1170.5ms\n",
      "Speed: 1.5ms preprocess, 1170.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1054.7ms\n",
      "Speed: 1.3ms preprocess, 1054.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1080.8ms\n",
      "Speed: 1.9ms preprocess, 1080.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001115.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1166.7ms\n",
      "Speed: 1.6ms preprocess, 1166.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001116.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1628.2ms\n",
      "Speed: 1.5ms preprocess, 1628.2ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1558.3ms\n",
      "Speed: 1.6ms preprocess, 1558.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1502.0ms\n",
      "Speed: 1.7ms preprocess, 1502.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1 bear, 2924.8ms\n",
      "Speed: 1.8ms preprocess, 2924.8ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1489.6ms\n",
      "Speed: 1.7ms preprocess, 1489.6ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001121.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1449.2ms\n",
      "Speed: 2.1ms preprocess, 1449.2ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1594.8ms\n",
      "Speed: 1.5ms preprocess, 1594.8ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001123.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 2 bears, 1577.1ms\n",
      "Speed: 1.9ms preprocess, 1577.1ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1489.8ms\n",
      "Speed: 2.1ms preprocess, 1489.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1 bear, 1312.1ms\n",
      "Speed: 1.6ms preprocess, 1312.1ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1399.5ms\n",
      "Speed: 1.8ms preprocess, 1399.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1477.3ms\n",
      "Speed: 1.6ms preprocess, 1477.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1386.2ms\n",
      "Speed: 1.6ms preprocess, 1386.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 cow, 1078.7ms\n",
      "Speed: 1.7ms preprocess, 1078.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 988.2ms\n",
      "Speed: 1.2ms preprocess, 988.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1872.0ms\n",
      "Speed: 2.3ms preprocess, 1872.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 3857.4ms\n",
      "Speed: 2.0ms preprocess, 3857.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 2794.0ms\n",
      "Speed: 2.4ms preprocess, 2794.0ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1853.4ms\n",
      "Speed: 1.9ms preprocess, 1853.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1582.7ms\n",
      "Speed: 1.5ms preprocess, 1582.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1533.7ms\n",
      "Speed: 1.8ms preprocess, 1533.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1581.8ms\n",
      "Speed: 2.1ms preprocess, 1581.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 elephant, 1797.6ms\n",
      "Speed: 1.7ms preprocess, 1797.6ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1574.8ms\n",
      "Speed: 2.3ms preprocess, 1574.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1 sheep, 1703.5ms\n",
      "Speed: 2.0ms preprocess, 1703.5ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1141.9ms\n",
      "Speed: 1.5ms preprocess, 1141.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1331.3ms\n",
      "Speed: 1.7ms preprocess, 1331.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 1753.5ms\n",
      "Speed: 1.7ms preprocess, 1753.5ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001144.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 cow, 1448.4ms\n",
      "Speed: 1.5ms preprocess, 1448.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 2260.7ms\n",
      "Speed: 1.7ms preprocess, 2260.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1348.7ms\n",
      "Speed: 1.7ms preprocess, 1348.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1691.0ms\n",
      "Speed: 1.5ms preprocess, 1691.0ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1656.8ms\n",
      "Speed: 1.8ms preprocess, 1656.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 giraffe, 2099.9ms\n",
      "Speed: 2.1ms preprocess, 2099.9ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1427.8ms\n",
      "Speed: 1.4ms preprocess, 1427.8ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001151.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 898.1ms\n",
      "Speed: 1.2ms preprocess, 898.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1095.5ms\n",
      "Speed: 1.5ms preprocess, 1095.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 car, 1 bear, 1527.9ms\n",
      "Speed: 1.6ms preprocess, 1527.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1727.3ms\n",
      "Speed: 2.0ms preprocess, 1727.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 (no detections), 1638.7ms\n",
      "Speed: 2.0ms preprocess, 1638.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001156.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1075.7ms\n",
      "Speed: 1.7ms preprocess, 1075.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001157.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1875.1ms\n",
      "Speed: 1.7ms preprocess, 1875.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 bear, 1493.3ms\n",
      "Speed: 1.6ms preprocess, 1493.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1145.8ms\n",
      "Speed: 1.7ms preprocess, 1145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1969.8ms\n",
      "Speed: 2.1ms preprocess, 1969.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 2103.7ms\n",
      "Speed: 2.4ms preprocess, 2103.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1723.4ms\n",
      "Speed: 2.1ms preprocess, 1723.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1223.3ms\n",
      "Speed: 1.9ms preprocess, 1223.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 bear, 2695.0ms\n",
      "Speed: 1.7ms preprocess, 2695.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1536.7ms\n",
      "Speed: 1.6ms preprocess, 1536.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1247.1ms\n",
      "Speed: 1.7ms preprocess, 1247.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1705.5ms\n",
      "Speed: 1.6ms preprocess, 1705.5ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 (no detections), 935.0ms\n",
      "Speed: 8.5ms preprocess, 935.0ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001169.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1330.0ms\n",
      "Speed: 1.5ms preprocess, 1330.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 elephant, 1716.6ms\n",
      "Speed: 2.0ms preprocess, 1716.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1730.2ms\n",
      "Speed: 2.1ms preprocess, 1730.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001172.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1430.1ms\n",
      "Speed: 1.8ms preprocess, 1430.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1 bear, 1144.5ms\n",
      "Speed: 1.6ms preprocess, 1144.5ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 giraffe, 1403.9ms\n",
      "Speed: 2.4ms preprocess, 1403.9ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1242.1ms\n",
      "Speed: 2.0ms preprocess, 1242.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1931.8ms\n",
      "Speed: 2.0ms preprocess, 1931.8ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 3850.7ms\n",
      "Speed: 2.3ms preprocess, 3850.7ms inference, 4.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 cats, 1867.1ms\n",
      "Speed: 1.9ms preprocess, 1867.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1658.3ms\n",
      "Speed: 2.0ms preprocess, 1658.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 3071.7ms\n",
      "Speed: 1.8ms preprocess, 3071.7ms inference, 0.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001181.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1277.6ms\n",
      "Speed: 4.0ms preprocess, 1277.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 birds, 1 horse, 1 giraffe, 1891.8ms\n",
      "Speed: 2.4ms preprocess, 1891.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 bears, 1960.2ms\n",
      "Speed: 2.4ms preprocess, 1960.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1795.5ms\n",
      "Speed: 1.8ms preprocess, 1795.5ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bird, 1 bear, 1655.8ms\n",
      "Speed: 2.0ms preprocess, 1655.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1690.1ms\n",
      "Speed: 2.3ms preprocess, 1690.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 2302.1ms\n",
      "Speed: 1.9ms preprocess, 2302.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 cow, 3059.2ms\n",
      "Speed: 2.2ms preprocess, 3059.2ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1663.7ms\n",
      "Speed: 2.0ms preprocess, 1663.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1650.8ms\n",
      "Speed: 2.5ms preprocess, 1650.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1550.3ms\n",
      "Speed: 2.3ms preprocess, 1550.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1387.9ms\n",
      "Speed: 1.7ms preprocess, 1387.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 2996.3ms\n",
      "Speed: 1.8ms preprocess, 2996.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1102.4ms\n",
      "Speed: 1.3ms preprocess, 1102.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1053.4ms\n",
      "Speed: 1.4ms preprocess, 1053.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1410.5ms\n",
      "Speed: 1.5ms preprocess, 1410.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1192.6ms\n",
      "Speed: 1.3ms preprocess, 1192.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 1883.7ms\n",
      "Speed: 2.3ms preprocess, 1883.7ms inference, 3.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1818.5ms\n",
      "Speed: 2.3ms preprocess, 1818.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1336.9ms\n",
      "Speed: 2.1ms preprocess, 1336.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1264.1ms\n",
      "Speed: 2.3ms preprocess, 1264.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001202.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1238.0ms\n",
      "Speed: 1.5ms preprocess, 1238.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1372.5ms\n",
      "Speed: 1.5ms preprocess, 1372.5ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001204.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 3233.7ms\n",
      "Speed: 2.7ms preprocess, 3233.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1699.5ms\n",
      "Speed: 2.0ms preprocess, 1699.5ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 1602.7ms\n",
      "Speed: 2.0ms preprocess, 1602.7ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 cat, 1587.1ms\n",
      "Speed: 1.9ms preprocess, 1587.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1137.0ms\n",
      "Speed: 1.8ms preprocess, 1137.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1451.4ms\n",
      "Speed: 1.4ms preprocess, 1451.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1112.7ms\n",
      "Speed: 1.8ms preprocess, 1112.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 (no detections), 764.7ms\n",
      "Speed: 1.2ms preprocess, 764.7ms inference, 0.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001212.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1185.5ms\n",
      "Speed: 1.5ms preprocess, 1185.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 2 bears, 1003.0ms\n",
      "Speed: 1.2ms preprocess, 1003.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cat, 1 dog, 1622.3ms\n",
      "Speed: 1.8ms preprocess, 1622.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1423.6ms\n",
      "Speed: 1.7ms preprocess, 1423.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 sheep, 1 cow, 2617.4ms\n",
      "Speed: 1.6ms preprocess, 2617.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1284.4ms\n",
      "Speed: 1.9ms preprocess, 1284.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 3 horses, 1049.2ms\n",
      "Speed: 1.7ms preprocess, 1049.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1235.8ms\n",
      "Speed: 2.0ms preprocess, 1235.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1232.5ms\n",
      "Speed: 1.8ms preprocess, 1232.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1198.0ms\n",
      "Speed: 1.4ms preprocess, 1198.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1028.1ms\n",
      "Speed: 1.5ms preprocess, 1028.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1218.2ms\n",
      "Speed: 1.5ms preprocess, 1218.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1410.5ms\n",
      "Speed: 1.9ms preprocess, 1410.5ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001225.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1 bear, 1232.3ms\n",
      "Speed: 1.6ms preprocess, 1232.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1702.4ms\n",
      "Speed: 2.1ms preprocess, 1702.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 giraffe, 2356.2ms\n",
      "Speed: 2.4ms preprocess, 2356.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 sheeps, 1478.2ms\n",
      "Speed: 1.7ms preprocess, 1478.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1265.6ms\n",
      "Speed: 1.8ms preprocess, 1265.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1618.5ms\n",
      "Speed: 2.8ms preprocess, 1618.5ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1 bear, 1523.5ms\n",
      "Speed: 2.0ms preprocess, 1523.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1124.8ms\n",
      "Speed: 1.4ms preprocess, 1124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 sheep, 1 cow, 1446.2ms\n",
      "Speed: 1.7ms preprocess, 1446.2ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1558.9ms\n",
      "Speed: 2.1ms preprocess, 1558.9ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 sheep, 1837.8ms\n",
      "Speed: 1.7ms preprocess, 1837.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1441.9ms\n",
      "Speed: 1.9ms preprocess, 1441.9ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 bear, 2050.1ms\n",
      "Speed: 1.9ms preprocess, 2050.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 2557.1ms\n",
      "Speed: 2.0ms preprocess, 2557.1ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1606.9ms\n",
      "Speed: 3.5ms preprocess, 1606.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1806.6ms\n",
      "Speed: 1.5ms preprocess, 1806.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 sheep, 1713.2ms\n",
      "Speed: 2.0ms preprocess, 1713.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1883.3ms\n",
      "Speed: 1.5ms preprocess, 1883.3ms inference, 3.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1680.8ms\n",
      "Speed: 2.2ms preprocess, 1680.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1834.1ms\n",
      "Speed: 2.2ms preprocess, 1834.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 2157.6ms\n",
      "Speed: 2.1ms preprocess, 2157.6ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1 giraffe, 1178.0ms\n",
      "Speed: 1.2ms preprocess, 1178.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1787.8ms\n",
      "Speed: 2.0ms preprocess, 1787.8ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1718.6ms\n",
      "Speed: 1.6ms preprocess, 1718.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 2050.9ms\n",
      "Speed: 1.7ms preprocess, 2050.9ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001250.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1483.5ms\n",
      "Speed: 1.6ms preprocess, 1483.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1383.3ms\n",
      "Speed: 2.1ms preprocess, 1383.3ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001252.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 bear, 1800.7ms\n",
      "Speed: 1.8ms preprocess, 1800.7ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 1379.2ms\n",
      "Speed: 1.4ms preprocess, 1379.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001254.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 2808.7ms\n",
      "Speed: 1.9ms preprocess, 2808.7ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 bear, 1990.6ms\n",
      "Speed: 3.1ms preprocess, 1990.6ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1927.6ms\n",
      "Speed: 1.7ms preprocess, 1927.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 1358.8ms\n",
      "Speed: 2.9ms preprocess, 1358.8ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001258.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 sheep, 1622.3ms\n",
      "Speed: 2.3ms preprocess, 1622.3ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1 cow, 1009.5ms\n",
      "Speed: 2.1ms preprocess, 1009.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 horse, 1534.9ms\n",
      "Speed: 1.7ms preprocess, 1534.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 4 cows, 1274.1ms\n",
      "Speed: 19.8ms preprocess, 1274.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 bear, 1042.5ms\n",
      "Speed: 1.3ms preprocess, 1042.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 bear, 1372.6ms\n",
      "Speed: 1.6ms preprocess, 1372.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 cat, 1 pizza, 1512.5ms\n",
      "Speed: 1.5ms preprocess, 1512.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1505.8ms\n",
      "Speed: 1.8ms preprocess, 1505.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1190.4ms\n",
      "Speed: 1.6ms preprocess, 1190.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 bear, 1184.3ms\n",
      "Speed: 1.5ms preprocess, 1184.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1396.1ms\n",
      "Speed: 1.6ms preprocess, 1396.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 cow, 2029.4ms\n",
      "Speed: 2.0ms preprocess, 2029.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1188.5ms\n",
      "Speed: 1.7ms preprocess, 1188.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1162.2ms\n",
      "Speed: 2.2ms preprocess, 1162.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1313.0ms\n",
      "Speed: 1.5ms preprocess, 1313.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1707.8ms\n",
      "Speed: 2.7ms preprocess, 1707.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1 giraffe, 1317.7ms\n",
      "Speed: 1.9ms preprocess, 1317.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1359.6ms\n",
      "Speed: 1.5ms preprocess, 1359.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 936.6ms\n",
      "Speed: 1.4ms preprocess, 936.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 sheep, 1774.1ms\n",
      "Speed: 1.9ms preprocess, 1774.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1370.0ms\n",
      "Speed: 1.6ms preprocess, 1370.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1405.6ms\n",
      "Speed: 1.9ms preprocess, 1405.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1491.5ms\n",
      "Speed: 1.6ms preprocess, 1491.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1212.2ms\n",
      "Speed: 1.9ms preprocess, 1212.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 2140.2ms\n",
      "Speed: 1.4ms preprocess, 2140.2ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 carrot, 1119.3ms\n",
      "Speed: 2.9ms preprocess, 1119.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1199.1ms\n",
      "Speed: 1.5ms preprocess, 1199.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1057.5ms\n",
      "Speed: 1.1ms preprocess, 1057.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1079.1ms\n",
      "Speed: 2.2ms preprocess, 1079.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1341.4ms\n",
      "Speed: 1.9ms preprocess, 1341.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1313.3ms\n",
      "Speed: 1.8ms preprocess, 1313.3ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001289.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1637.4ms\n",
      "Speed: 2.3ms preprocess, 1637.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1 dog, 1505.2ms\n",
      "Speed: 1.7ms preprocess, 1505.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1751.3ms\n",
      "Speed: 2.5ms preprocess, 1751.3ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1872.4ms\n",
      "Speed: 2.4ms preprocess, 1872.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1360.3ms\n",
      "Speed: 1.6ms preprocess, 1360.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1407.7ms\n",
      "Speed: 1.6ms preprocess, 1407.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1657.6ms\n",
      "Speed: 1.5ms preprocess, 1657.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1037.7ms\n",
      "Speed: 1.3ms preprocess, 1037.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1097.0ms\n",
      "Speed: 1.6ms preprocess, 1097.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1 elephant, 1081.6ms\n",
      "Speed: 1.4ms preprocess, 1081.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1068.6ms\n",
      "Speed: 1.6ms preprocess, 1068.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1638.6ms\n",
      "Speed: 1.8ms preprocess, 1638.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 2320.1ms\n",
      "Speed: 2.0ms preprocess, 2320.1ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 cow, 1309.8ms\n",
      "Speed: 1.6ms preprocess, 1309.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1194.5ms\n",
      "Speed: 2.1ms preprocess, 1194.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 horse, 1627.5ms\n",
      "Speed: 1.8ms preprocess, 1627.5ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 traffic light, 1 horse, 1 cow, 1275.2ms\n",
      "Speed: 1.5ms preprocess, 1275.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 cow, 1 elephant, 991.8ms\n",
      "Speed: 2.0ms preprocess, 991.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1712.9ms\n",
      "Speed: 2.0ms preprocess, 1712.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1649.5ms\n",
      "Speed: 2.0ms preprocess, 1649.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1502.7ms\n",
      "Speed: 1.6ms preprocess, 1502.7ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 1612.5ms\n",
      "Speed: 1.4ms preprocess, 1612.5ms inference, 3.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1393.9ms\n",
      "Speed: 1.7ms preprocess, 1393.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 1059.5ms\n",
      "Speed: 1.9ms preprocess, 1059.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1243.3ms\n",
      "Speed: 1.5ms preprocess, 1243.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1915.9ms\n",
      "Speed: 1.6ms preprocess, 1915.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1168.3ms\n",
      "Speed: 1.7ms preprocess, 1168.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1630.5ms\n",
      "Speed: 1.6ms preprocess, 1630.5ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1708.6ms\n",
      "Speed: 2.0ms preprocess, 1708.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1115.6ms\n",
      "Speed: 1.2ms preprocess, 1115.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1000.7ms\n",
      "Speed: 1.5ms preprocess, 1000.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001320.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 1 bear, 1621.6ms\n",
      "Speed: 2.0ms preprocess, 1621.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1 bear, 1144.6ms\n",
      "Speed: 1.5ms preprocess, 1144.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1428.5ms\n",
      "Speed: 1.6ms preprocess, 1428.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1404.7ms\n",
      "Speed: 1.6ms preprocess, 1404.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1383.3ms\n",
      "Speed: 1.9ms preprocess, 1383.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1245.5ms\n",
      "Speed: 1.4ms preprocess, 1245.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1782.0ms\n",
      "Speed: 1.4ms preprocess, 1782.0ms inference, 45.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 elephant, 1 bear, 1928.0ms\n",
      "Speed: 1.9ms preprocess, 1928.0ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1353.9ms\n",
      "Speed: 1.6ms preprocess, 1353.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 giraffe, 1829.5ms\n",
      "Speed: 2.1ms preprocess, 1829.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1168.8ms\n",
      "Speed: 1.8ms preprocess, 1168.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 bear, 1469.7ms\n",
      "Speed: 1.9ms preprocess, 1469.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1386.8ms\n",
      "Speed: 1.5ms preprocess, 1386.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 1185.3ms\n",
      "Speed: 1.9ms preprocess, 1185.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1251.3ms\n",
      "Speed: 1.8ms preprocess, 1251.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 1 bear, 907.2ms\n",
      "Speed: 1.2ms preprocess, 907.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 bear, 1252.5ms\n",
      "Speed: 1.5ms preprocess, 1252.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 cow, 1881.5ms\n",
      "Speed: 1.5ms preprocess, 1881.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 1715.8ms\n",
      "Speed: 3.0ms preprocess, 1715.8ms inference, 0.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001339.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 bear, 1030.5ms\n",
      "Speed: 1.4ms preprocess, 1030.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 995.2ms\n",
      "Speed: 1.3ms preprocess, 995.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1112.2ms\n",
      "Speed: 1.7ms preprocess, 1112.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 bears, 991.6ms\n",
      "Speed: 2.1ms preprocess, 991.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 horse, 1451.6ms\n",
      "Speed: 1.6ms preprocess, 1451.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 sheep, 1138.8ms\n",
      "Speed: 1.4ms preprocess, 1138.8ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1591.9ms\n",
      "Speed: 1.7ms preprocess, 1591.9ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1431.0ms\n",
      "Speed: 9.1ms preprocess, 1431.0ms inference, 0.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001347.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 1 cow, 628.9ms\n",
      "Speed: 0.8ms preprocess, 628.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1 bear, 1151.7ms\n",
      "Speed: 1.3ms preprocess, 1151.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1507.3ms\n",
      "Speed: 1.7ms preprocess, 1507.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 bear, 748.3ms\n",
      "Speed: 1.1ms preprocess, 748.3ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1236.8ms\n",
      "Speed: 2.2ms preprocess, 1236.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 sheep, 1605.4ms\n",
      "Speed: 1.6ms preprocess, 1605.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1094.8ms\n",
      "Speed: 2.3ms preprocess, 1094.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 929.4ms\n",
      "Speed: 1.0ms preprocess, 929.4ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1291.7ms\n",
      "Speed: 4.4ms preprocess, 1291.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 sheep, 2012.2ms\n",
      "Speed: 1.9ms preprocess, 2012.2ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 bear, 1284.9ms\n",
      "Speed: 1.7ms preprocess, 1284.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1325.7ms\n",
      "Speed: 1.7ms preprocess, 1325.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 cows, 1052.5ms\n",
      "Speed: 10.7ms preprocess, 1052.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 915.7ms\n",
      "Speed: 1.8ms preprocess, 915.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1302.0ms\n",
      "Speed: 1.6ms preprocess, 1302.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 1597.2ms\n",
      "Speed: 1.5ms preprocess, 1597.2ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1392.4ms\n",
      "Speed: 2.0ms preprocess, 1392.4ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001364.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1328.7ms\n",
      "Speed: 1.5ms preprocess, 1328.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 2164.7ms\n",
      "Speed: 2.0ms preprocess, 2164.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cat, 1655.3ms\n",
      "Speed: 1.9ms preprocess, 1655.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 1631.6ms\n",
      "Speed: 2.7ms preprocess, 1631.6ms inference, 0.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001368.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1196.9ms\n",
      "Speed: 1.5ms preprocess, 1196.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 bear, 1297.5ms\n",
      "Speed: 1.5ms preprocess, 1297.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1397.3ms\n",
      "Speed: 1.8ms preprocess, 1397.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1312.2ms\n",
      "Speed: 4.8ms preprocess, 1312.2ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001372.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 sheeps, 1 bear, 1249.9ms\n",
      "Speed: 1.9ms preprocess, 1249.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1499.9ms\n",
      "Speed: 1.4ms preprocess, 1499.9ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1297.5ms\n",
      "Speed: 1.7ms preprocess, 1297.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1284.6ms\n",
      "Speed: 1.7ms preprocess, 1284.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1222.5ms\n",
      "Speed: 1.6ms preprocess, 1222.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1150.3ms\n",
      "Speed: 2.1ms preprocess, 1150.3ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001378.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1322.8ms\n",
      "Speed: 1.4ms preprocess, 1322.8ms inference, 17.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1673.9ms\n",
      "Speed: 2.0ms preprocess, 1673.9ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1032.0ms\n",
      "Speed: 1.6ms preprocess, 1032.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001381.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1372.5ms\n",
      "Speed: 1.3ms preprocess, 1372.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 1 sheep, 747.7ms\n",
      "Speed: 1.1ms preprocess, 747.7ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1 cow, 1335.1ms\n",
      "Speed: 1.7ms preprocess, 1335.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1658.8ms\n",
      "Speed: 2.5ms preprocess, 1658.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 frisbee, 1428.1ms\n",
      "Speed: 1.7ms preprocess, 1428.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1155.2ms\n",
      "Speed: 1.6ms preprocess, 1155.2ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001387.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1432.6ms\n",
      "Speed: 1.7ms preprocess, 1432.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 192x640 1 cat, 566.5ms\n",
      "Speed: 0.7ms preprocess, 566.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1352.3ms\n",
      "Speed: 1.8ms preprocess, 1352.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1 elephant, 1 giraffe, 1677.5ms\n",
      "Speed: 2.9ms preprocess, 1677.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1073.3ms\n",
      "Speed: 1.5ms preprocess, 1073.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1613.0ms\n",
      "Speed: 1.5ms preprocess, 1613.0ms inference, 82.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1254.7ms\n",
      "Speed: 1.5ms preprocess, 1254.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1085.8ms\n",
      "Speed: 1.7ms preprocess, 1085.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 2 cows, 1 bear, 810.3ms\n",
      "Speed: 0.9ms preprocess, 810.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1675.7ms\n",
      "Speed: 2.1ms preprocess, 1675.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1130.6ms\n",
      "Speed: 1.6ms preprocess, 1130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1184.4ms\n",
      "Speed: 1.7ms preprocess, 1184.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1 bear, 1386.4ms\n",
      "Speed: 1.8ms preprocess, 1386.4ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1670.4ms\n",
      "Speed: 2.3ms preprocess, 1670.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1 bear, 1547.2ms\n",
      "Speed: 5.6ms preprocess, 1547.2ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 1110.5ms\n",
      "Speed: 9.9ms preprocess, 1110.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 cow, 1604.6ms\n",
      "Speed: 2.1ms preprocess, 1604.6ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1677.9ms\n",
      "Speed: 2.2ms preprocess, 1677.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1432.1ms\n",
      "Speed: 1.4ms preprocess, 1432.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 2 bears, 1302.6ms\n",
      "Speed: 2.5ms preprocess, 1302.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1277.4ms\n",
      "Speed: 1.4ms preprocess, 1277.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 horse, 1555.5ms\n",
      "Speed: 1.8ms preprocess, 1555.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1 cow, 2482.5ms\n",
      "Speed: 2.0ms preprocess, 2482.5ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1441.7ms\n",
      "Speed: 1.8ms preprocess, 1441.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 2437.5ms\n",
      "Speed: 2.4ms preprocess, 2437.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1710.6ms\n",
      "Speed: 1.8ms preprocess, 1710.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 2072.9ms\n",
      "Speed: 1.8ms preprocess, 2072.9ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 4066.0ms\n",
      "Speed: 4.0ms preprocess, 4066.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001415.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 person, 1 dog, 1 horse, 1722.1ms\n",
      "Speed: 2.3ms preprocess, 1722.1ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 dog, 1197.8ms\n",
      "Speed: 1.3ms preprocess, 1197.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 cow, 1388.9ms\n",
      "Speed: 1.6ms preprocess, 1388.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1539.3ms\n",
      "Speed: 1.4ms preprocess, 1539.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1605.0ms\n",
      "Speed: 2.3ms preprocess, 1605.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1463.7ms\n",
      "Speed: 1.9ms preprocess, 1463.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1392.1ms\n",
      "Speed: 2.0ms preprocess, 1392.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 2121.0ms\n",
      "Speed: 1.8ms preprocess, 2121.0ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1476.3ms\n",
      "Speed: 1.8ms preprocess, 1476.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 2307.4ms\n",
      "Speed: 2.8ms preprocess, 2307.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 3284.0ms\n",
      "Speed: 2.0ms preprocess, 3284.0ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 2057.6ms\n",
      "Speed: 2.5ms preprocess, 2057.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1705.3ms\n",
      "Speed: 2.5ms preprocess, 1705.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 2991.3ms\n",
      "Speed: 2.4ms preprocess, 2991.3ms inference, 8.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 1680.8ms\n",
      "Speed: 2.1ms preprocess, 1680.8ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1624.2ms\n",
      "Speed: 13.1ms preprocess, 1624.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1669.8ms\n",
      "Speed: 1.7ms preprocess, 1669.8ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 sheep, 2173.3ms\n",
      "Speed: 2.5ms preprocess, 2173.3ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1766.4ms\n",
      "Speed: 1.9ms preprocess, 1766.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 2368.0ms\n",
      "Speed: 2.1ms preprocess, 2368.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1559.6ms\n",
      "Speed: 3.1ms preprocess, 1559.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1449.5ms\n",
      "Speed: 1.7ms preprocess, 1449.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1859.9ms\n",
      "Speed: 2.0ms preprocess, 1859.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 904.0ms\n",
      "Speed: 1.2ms preprocess, 904.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1186.2ms\n",
      "Speed: 1.6ms preprocess, 1186.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1604.3ms\n",
      "Speed: 1.8ms preprocess, 1604.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1537.5ms\n",
      "Speed: 2.2ms preprocess, 1537.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1244.9ms\n",
      "Speed: 1.7ms preprocess, 1244.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1549.8ms\n",
      "Speed: 2.3ms preprocess, 1549.8ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 1 bear, 1608.5ms\n",
      "Speed: 17.9ms preprocess, 1608.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1381.0ms\n",
      "Speed: 1.7ms preprocess, 1381.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1728.8ms\n",
      "Speed: 2.1ms preprocess, 1728.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1 bear, 1195.2ms\n",
      "Speed: 1.6ms preprocess, 1195.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1 horse, 1459.5ms\n",
      "Speed: 2.0ms preprocess, 1459.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 sheep, 808.4ms\n",
      "Speed: 1.0ms preprocess, 808.4ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 giraffe, 1354.8ms\n",
      "Speed: 1.9ms preprocess, 1354.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 1 bear, 803.9ms\n",
      "Speed: 1.0ms preprocess, 803.9ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1718.1ms\n",
      "Speed: 3.1ms preprocess, 1718.1ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 bear, 1746.3ms\n",
      "Speed: 2.1ms preprocess, 1746.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 958.8ms\n",
      "Speed: 1.1ms preprocess, 958.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 cow, 1433.0ms\n",
      "Speed: 2.5ms preprocess, 1433.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 giraffe, 1857.7ms\n",
      "Speed: 2.1ms preprocess, 1857.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 sheep, 1207.8ms\n",
      "Speed: 1.4ms preprocess, 1207.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1264.3ms\n",
      "Speed: 1.7ms preprocess, 1264.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1121.5ms\n",
      "Speed: 1.4ms preprocess, 1121.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1560.8ms\n",
      "Speed: 1.9ms preprocess, 1560.8ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 bear, 816.6ms\n",
      "Speed: 1.8ms preprocess, 816.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1399.0ms\n",
      "Speed: 2.3ms preprocess, 1399.0ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001463.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1559.6ms\n",
      "Speed: 1.7ms preprocess, 1559.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1279.7ms\n",
      "Speed: 1.6ms preprocess, 1279.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1312.4ms\n",
      "Speed: 8.1ms preprocess, 1312.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 sheep, 3044.3ms\n",
      "Speed: 1.8ms preprocess, 3044.3ms inference, 3.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1642.0ms\n",
      "Speed: 1.5ms preprocess, 1642.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1427.6ms\n",
      "Speed: 2.1ms preprocess, 1427.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1865.1ms\n",
      "Speed: 2.1ms preprocess, 1865.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1247.4ms\n",
      "Speed: 1.8ms preprocess, 1247.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 cow, 1 bear, 1989.1ms\n",
      "Speed: 1.7ms preprocess, 1989.1ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 1 dog, 926.6ms\n",
      "Speed: 1.2ms preprocess, 926.6ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1519.8ms\n",
      "Speed: 1.8ms preprocess, 1519.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 banana, 1016.6ms\n",
      "Speed: 1.4ms preprocess, 1016.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 1105.9ms\n",
      "Speed: 1.2ms preprocess, 1105.9ms inference, 0.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001476.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 3053.9ms\n",
      "Speed: 2.4ms preprocess, 3053.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001477.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 2039.0ms\n",
      "Speed: 2.5ms preprocess, 2039.0ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1 cow, 1540.1ms\n",
      "Speed: 2.8ms preprocess, 1540.1ms inference, 2.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 2610.8ms\n",
      "Speed: 2.7ms preprocess, 2610.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 2068.3ms\n",
      "Speed: 2.8ms preprocess, 2068.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1602.8ms\n",
      "Speed: 2.2ms preprocess, 1602.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 persons, 1 cat, 1 dog, 1384.9ms\n",
      "Speed: 1.9ms preprocess, 1384.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 1 bear, 1583.4ms\n",
      "Speed: 2.4ms preprocess, 1583.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1362.7ms\n",
      "Speed: 1.5ms preprocess, 1362.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 cat, 1 horse, 1673.7ms\n",
      "Speed: 2.0ms preprocess, 1673.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 giraffe, 1594.0ms\n",
      "Speed: 7.7ms preprocess, 1594.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 giraffe, 1442.5ms\n",
      "Speed: 1.5ms preprocess, 1442.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1409.1ms\n",
      "Speed: 1.6ms preprocess, 1409.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 horse, 2 bears, 1441.3ms\n",
      "Speed: 2.0ms preprocess, 1441.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1588.2ms\n",
      "Speed: 1.8ms preprocess, 1588.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 dog, 993.8ms\n",
      "Speed: 1.2ms preprocess, 993.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1414.9ms\n",
      "Speed: 1.8ms preprocess, 1414.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1177.5ms\n",
      "Speed: 1.4ms preprocess, 1177.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1325.5ms\n",
      "Speed: 1.7ms preprocess, 1325.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001495.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1024.2ms\n",
      "Speed: 1.7ms preprocess, 1024.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1353.2ms\n",
      "Speed: 1.8ms preprocess, 1353.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 959.5ms\n",
      "Speed: 1.3ms preprocess, 959.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1218.7ms\n",
      "Speed: 1.8ms preprocess, 1218.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1471.4ms\n",
      "Speed: 1.3ms preprocess, 1471.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1500.5ms\n",
      "Speed: 1.3ms preprocess, 1500.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 giraffe, 2175.6ms\n",
      "Speed: 1.9ms preprocess, 2175.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1 dog, 3535.5ms\n",
      "Speed: 1.9ms preprocess, 3535.5ms inference, 3.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1 cow, 1159.0ms\n",
      "Speed: 1.6ms preprocess, 1159.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1276.5ms\n",
      "Speed: 1.7ms preprocess, 1276.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 806.3ms\n",
      "Speed: 1.2ms preprocess, 806.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1220.8ms\n",
      "Speed: 1.4ms preprocess, 1220.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1838.5ms\n",
      "Speed: 2.0ms preprocess, 1838.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 (no detections), 778.5ms\n",
      "Speed: 1.1ms preprocess, 778.5ms inference, 0.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001509.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1726.3ms\n",
      "Speed: 2.0ms preprocess, 1726.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1685.8ms\n",
      "Speed: 2.3ms preprocess, 1685.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1010.6ms\n",
      "Speed: 1.5ms preprocess, 1010.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1529.0ms\n",
      "Speed: 1.8ms preprocess, 1529.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 bear, 1554.7ms\n",
      "Speed: 1.7ms preprocess, 1554.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1091.7ms\n",
      "Speed: 1.4ms preprocess, 1091.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1806.4ms\n",
      "Speed: 2.7ms preprocess, 1806.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 2107.6ms\n",
      "Speed: 2.0ms preprocess, 2107.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001517.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 dog, 1 horse, 1501.8ms\n",
      "Speed: 1.7ms preprocess, 1501.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1680.8ms\n",
      "Speed: 2.5ms preprocess, 1680.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001519.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1110.1ms\n",
      "Speed: 1.5ms preprocess, 1110.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1093.1ms\n",
      "Speed: 1.4ms preprocess, 1093.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 2 bears, 1111.2ms\n",
      "Speed: 1.3ms preprocess, 1111.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 2239.5ms\n",
      "Speed: 2.0ms preprocess, 2239.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 2327.8ms\n",
      "Speed: 2.1ms preprocess, 2327.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 1449.9ms\n",
      "Speed: 1.5ms preprocess, 1449.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1377.2ms\n",
      "Speed: 1.7ms preprocess, 1377.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1326.5ms\n",
      "Speed: 1.5ms preprocess, 1326.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 2736.3ms\n",
      "Speed: 1.5ms preprocess, 2736.3ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1754.5ms\n",
      "Speed: 7.1ms preprocess, 1754.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1996.4ms\n",
      "Speed: 2.1ms preprocess, 1996.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1186.7ms\n",
      "Speed: 1.2ms preprocess, 1186.7ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001531.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1229.0ms\n",
      "Speed: 1.7ms preprocess, 1229.0ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001532.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1561.8ms\n",
      "Speed: 1.8ms preprocess, 1561.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 giraffe, 1258.2ms\n",
      "Speed: 1.8ms preprocess, 1258.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 cow, 1901.0ms\n",
      "Speed: 2.3ms preprocess, 1901.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1821.1ms\n",
      "Speed: 2.4ms preprocess, 1821.1ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001536.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1675.7ms\n",
      "Speed: 2.0ms preprocess, 1675.7ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1714.1ms\n",
      "Speed: 2.0ms preprocess, 1714.1ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 bear, 1309.3ms\n",
      "Speed: 1.8ms preprocess, 1309.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1645.1ms\n",
      "Speed: 1.6ms preprocess, 1645.1ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001540.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 1830.5ms\n",
      "Speed: 2.6ms preprocess, 1830.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cow, 1767.8ms\n",
      "Speed: 16.6ms preprocess, 1767.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 2 bears, 1384.1ms\n",
      "Speed: 1.5ms preprocess, 1384.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1906.9ms\n",
      "Speed: 2.1ms preprocess, 1906.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1173.1ms\n",
      "Speed: 1.6ms preprocess, 1173.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1528.5ms\n",
      "Speed: 1.7ms preprocess, 1528.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 2 persons, 1 dog, 1728.9ms\n",
      "Speed: 2.3ms preprocess, 1728.9ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1631.0ms\n",
      "Speed: 1.7ms preprocess, 1631.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 giraffe, 1657.9ms\n",
      "Speed: 17.8ms preprocess, 1657.9ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1511.0ms\n",
      "Speed: 2.0ms preprocess, 1511.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 2280.3ms\n",
      "Speed: 1.7ms preprocess, 2280.3ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1837.0ms\n",
      "Speed: 3.0ms preprocess, 1837.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1232.3ms\n",
      "Speed: 1.6ms preprocess, 1232.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1594.9ms\n",
      "Speed: 2.7ms preprocess, 1594.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1243.8ms\n",
      "Speed: 1.8ms preprocess, 1243.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1266.1ms\n",
      "Speed: 1.0ms preprocess, 1266.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001556.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 cow, 1345.1ms\n",
      "Speed: 1.6ms preprocess, 1345.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 bears, 1509.1ms\n",
      "Speed: 1.4ms preprocess, 1509.1ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 giraffe, 1577.2ms\n",
      "Speed: 2.0ms preprocess, 1577.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1760.4ms\n",
      "Speed: 1.6ms preprocess, 1760.4ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cow, 1702.5ms\n",
      "Speed: 1.6ms preprocess, 1702.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1530.6ms\n",
      "Speed: 3.1ms preprocess, 1530.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 3029.3ms\n",
      "Speed: 2.1ms preprocess, 3029.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 2 sheeps, 1 cow, 1505.4ms\n",
      "Speed: 1.9ms preprocess, 1505.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1207.7ms\n",
      "Speed: 1.6ms preprocess, 1207.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 elephant, 1412.7ms\n",
      "Speed: 2.1ms preprocess, 1412.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1585.7ms\n",
      "Speed: 1.9ms preprocess, 1585.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1679.8ms\n",
      "Speed: 2.6ms preprocess, 1679.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 192x640 2 bears, 523.7ms\n",
      "Speed: 0.7ms preprocess, 523.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1599.1ms\n",
      "Speed: 28.5ms preprocess, 1599.1ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1343.6ms\n",
      "Speed: 1.5ms preprocess, 1343.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1127.8ms\n",
      "Speed: 1.7ms preprocess, 1127.8ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1054.0ms\n",
      "Speed: 1.2ms preprocess, 1054.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cat, 1 dog, 1 horse, 2428.1ms\n",
      "Speed: 1.6ms preprocess, 2428.1ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 bear, 1198.4ms\n",
      "Speed: 1.2ms preprocess, 1198.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1738.0ms\n",
      "Speed: 1.8ms preprocess, 1738.0ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 sheep, 1424.1ms\n",
      "Speed: 1.6ms preprocess, 1424.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1154.8ms\n",
      "Speed: 1.4ms preprocess, 1154.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1772.8ms\n",
      "Speed: 2.3ms preprocess, 1772.8ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1178.3ms\n",
      "Speed: 1.7ms preprocess, 1178.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1554.8ms\n",
      "Speed: 2.3ms preprocess, 1554.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1320.3ms\n",
      "Speed: 1.4ms preprocess, 1320.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 sheep, 1 bear, 1348.6ms\n",
      "Speed: 1.4ms preprocess, 1348.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 bear, 1485.9ms\n",
      "Speed: 1.7ms preprocess, 1485.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1527.4ms\n",
      "Speed: 2.0ms preprocess, 1527.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1916.2ms\n",
      "Speed: 1.5ms preprocess, 1916.2ms inference, 3.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1748.6ms\n",
      "Speed: 2.1ms preprocess, 1748.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1 bear, 1292.4ms\n",
      "Speed: 1.3ms preprocess, 1292.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1706.9ms\n",
      "Speed: 1.8ms preprocess, 1706.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1397.3ms\n",
      "Speed: 1.6ms preprocess, 1397.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1732.8ms\n",
      "Speed: 1.7ms preprocess, 1732.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001591.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 giraffe, 1226.3ms\n",
      "Speed: 11.3ms preprocess, 1226.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1 cow, 1136.4ms\n",
      "Speed: 2.2ms preprocess, 1136.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1468.8ms\n",
      "Speed: 1.9ms preprocess, 1468.8ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1434.7ms\n",
      "Speed: 1.7ms preprocess, 1434.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1564.7ms\n",
      "Speed: 1.6ms preprocess, 1564.7ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1320.1ms\n",
      "Speed: 1.4ms preprocess, 1320.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 cow, 1701.1ms\n",
      "Speed: 2.0ms preprocess, 1701.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 sheeps, 2460.7ms\n",
      "Speed: 1.5ms preprocess, 2460.7ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1213.8ms\n",
      "Speed: 2.2ms preprocess, 1213.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 976.8ms\n",
      "Speed: 1.8ms preprocess, 976.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1 dog, 1908.5ms\n",
      "Speed: 1.9ms preprocess, 1908.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1459.4ms\n",
      "Speed: 2.4ms preprocess, 1459.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1138.1ms\n",
      "Speed: 21.3ms preprocess, 1138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1348.9ms\n",
      "Speed: 2.4ms preprocess, 1348.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1697.9ms\n",
      "Speed: 2.0ms preprocess, 1697.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1478.4ms\n",
      "Speed: 1.5ms preprocess, 1478.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1229.4ms\n",
      "Speed: 1.5ms preprocess, 1229.4ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001608.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 1694.5ms\n",
      "Speed: 1.6ms preprocess, 1694.5ms inference, 71.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 dog, 1 bear, 1605.0ms\n",
      "Speed: 1.8ms preprocess, 1605.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1198.3ms\n",
      "Speed: 1.8ms preprocess, 1198.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1916.6ms\n",
      "Speed: 1.9ms preprocess, 1916.6ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 2213.2ms\n",
      "Speed: 1.5ms preprocess, 2213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 cow, 1576.6ms\n",
      "Speed: 1.3ms preprocess, 1576.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 2609.7ms\n",
      "Speed: 2.0ms preprocess, 2609.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 2570.7ms\n",
      "Speed: 1.8ms preprocess, 2570.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 1932.2ms\n",
      "Speed: 2.1ms preprocess, 1932.2ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1447.0ms\n",
      "Speed: 2.9ms preprocess, 1447.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1104.0ms\n",
      "Speed: 2.1ms preprocess, 1104.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1520.4ms\n",
      "Speed: 1.7ms preprocess, 1520.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1291.7ms\n",
      "Speed: 1.6ms preprocess, 1291.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 2 sheeps, 1 cow, 1765.7ms\n",
      "Speed: 1.7ms preprocess, 1765.7ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1717.9ms\n",
      "Speed: 1.6ms preprocess, 1717.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1 dog, 2247.1ms\n",
      "Speed: 4.2ms preprocess, 2247.1ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1996.8ms\n",
      "Speed: 3.4ms preprocess, 1996.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1524.5ms\n",
      "Speed: 15.8ms preprocess, 1524.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1531.2ms\n",
      "Speed: 1.7ms preprocess, 1531.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 2068.9ms\n",
      "Speed: 2.3ms preprocess, 2068.9ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 dog, 1444.6ms\n",
      "Speed: 1.7ms preprocess, 1444.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1441.9ms\n",
      "Speed: 38.0ms preprocess, 1441.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001630.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1702.4ms\n",
      "Speed: 1.7ms preprocess, 1702.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1684.3ms\n",
      "Speed: 2.6ms preprocess, 1684.3ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 sheep, 2026.0ms\n",
      "Speed: 2.0ms preprocess, 2026.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1219.8ms\n",
      "Speed: 2.5ms preprocess, 1219.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 1340.5ms\n",
      "Speed: 1.6ms preprocess, 1340.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1743.5ms\n",
      "Speed: 1.8ms preprocess, 1743.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1 horse, 1811.4ms\n",
      "Speed: 1.9ms preprocess, 1811.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1723.8ms\n",
      "Speed: 2.0ms preprocess, 1723.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 2036.5ms\n",
      "Speed: 2.0ms preprocess, 2036.5ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1497.2ms\n",
      "Speed: 1.8ms preprocess, 1497.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1378.3ms\n",
      "Speed: 1.7ms preprocess, 1378.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1921.0ms\n",
      "Speed: 1.7ms preprocess, 1921.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1157.1ms\n",
      "Speed: 1.6ms preprocess, 1157.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cow, 1885.4ms\n",
      "Speed: 1.8ms preprocess, 1885.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1163.4ms\n",
      "Speed: 1.7ms preprocess, 1163.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 cat, 1 dog, 1707.8ms\n",
      "Speed: 16.8ms preprocess, 1707.8ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1368.0ms\n",
      "Speed: 2.6ms preprocess, 1368.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 sheep, 1686.3ms\n",
      "Speed: 1.9ms preprocess, 1686.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1909.2ms\n",
      "Speed: 2.0ms preprocess, 1909.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1686.9ms\n",
      "Speed: 15.4ms preprocess, 1686.9ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001650.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 cow, 1109.4ms\n",
      "Speed: 1.5ms preprocess, 1109.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1371.5ms\n",
      "Speed: 1.7ms preprocess, 1371.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1 horse, 3148.9ms\n",
      "Speed: 3.1ms preprocess, 3148.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 giraffe, 2348.0ms\n",
      "Speed: 3.1ms preprocess, 2348.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1944.2ms\n",
      "Speed: 2.1ms preprocess, 1944.2ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1521.0ms\n",
      "Speed: 1.7ms preprocess, 1521.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001656.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 288x640 1 cat, 846.4ms\n",
      "Speed: 1.0ms preprocess, 846.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1069.7ms\n",
      "Speed: 1.6ms preprocess, 1069.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1912.1ms\n",
      "Speed: 2.8ms preprocess, 1912.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1295.4ms\n",
      "Speed: 1.7ms preprocess, 1295.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1630.0ms\n",
      "Speed: 1.5ms preprocess, 1630.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1859.0ms\n",
      "Speed: 2.2ms preprocess, 1859.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1376.8ms\n",
      "Speed: 1.9ms preprocess, 1376.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1851.8ms\n",
      "Speed: 2.1ms preprocess, 1851.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 2891.2ms\n",
      "Speed: 2.0ms preprocess, 2891.2ms inference, 3.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1588.2ms\n",
      "Speed: 7.4ms preprocess, 1588.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 2138.8ms\n",
      "Speed: 2.2ms preprocess, 2138.8ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 giraffe, 2723.6ms\n",
      "Speed: 3.0ms preprocess, 2723.6ms inference, 3.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 sheep, 1 cow, 1150.8ms\n",
      "Speed: 1.4ms preprocess, 1150.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 2009.9ms\n",
      "Speed: 1.9ms preprocess, 2009.9ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1468.2ms\n",
      "Speed: 1.4ms preprocess, 1468.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 cows, 1474.6ms\n",
      "Speed: 1.7ms preprocess, 1474.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 3 bears, 2092.7ms\n",
      "Speed: 2.3ms preprocess, 2092.7ms inference, 2.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1649.6ms\n",
      "Speed: 28.9ms preprocess, 1649.6ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 sheep, 2339.8ms\n",
      "Speed: 2.1ms preprocess, 2339.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 bear, 3354.2ms\n",
      "Speed: 2.0ms preprocess, 3354.2ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1 horse, 1939.5ms\n",
      "Speed: 1.9ms preprocess, 1939.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 2353.2ms\n",
      "Speed: 2.3ms preprocess, 2353.2ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001678.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 2123.6ms\n",
      "Speed: 3.0ms preprocess, 2123.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1927.8ms\n",
      "Speed: 15.8ms preprocess, 1927.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 2056.4ms\n",
      "Speed: 2.3ms preprocess, 2056.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 sheep, 1274.2ms\n",
      "Speed: 1.6ms preprocess, 1274.2ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 2113.4ms\n",
      "Speed: 2.9ms preprocess, 2113.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1498.1ms\n",
      "Speed: 16.6ms preprocess, 1498.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1416.5ms\n",
      "Speed: 1.7ms preprocess, 1416.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1607.4ms\n",
      "Speed: 1.7ms preprocess, 1607.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 3198.2ms\n",
      "Speed: 2.3ms preprocess, 3198.2ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 2183.8ms\n",
      "Speed: 2.9ms preprocess, 2183.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1982.8ms\n",
      "Speed: 1.9ms preprocess, 1982.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1 sheep, 2418.0ms\n",
      "Speed: 2.4ms preprocess, 2418.0ms inference, 2.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1695.2ms\n",
      "Speed: 2.0ms preprocess, 1695.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 bear, 2155.6ms\n",
      "Speed: 1.6ms preprocess, 2155.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1890.5ms\n",
      "Speed: 1.7ms preprocess, 1890.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1509.6ms\n",
      "Speed: 2.0ms preprocess, 1509.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1 bear, 1512.9ms\n",
      "Speed: 2.0ms preprocess, 1512.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1882.0ms\n",
      "Speed: 2.3ms preprocess, 1882.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1416.4ms\n",
      "Speed: 1.5ms preprocess, 1416.4ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 cow, 2280.0ms\n",
      "Speed: 1.5ms preprocess, 2280.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1487.6ms\n",
      "Speed: 1.6ms preprocess, 1487.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 bear, 1850.9ms\n",
      "Speed: 3.4ms preprocess, 1850.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1078.4ms\n",
      "Speed: 2.1ms preprocess, 1078.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1769.1ms\n",
      "Speed: 2.0ms preprocess, 1769.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 sheep, 1650.2ms\n",
      "Speed: 2.6ms preprocess, 1650.2ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1299.5ms\n",
      "Speed: 2.3ms preprocess, 1299.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1110.7ms\n",
      "Speed: 2.2ms preprocess, 1110.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 banana, 1701.4ms\n",
      "Speed: 12.7ms preprocess, 1701.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1286.6ms\n",
      "Speed: 2.3ms preprocess, 1286.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001707.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1101.4ms\n",
      "Speed: 20.8ms preprocess, 1101.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1640.7ms\n",
      "Speed: 1.8ms preprocess, 1640.7ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 cow, 1 bear, 884.1ms\n",
      "Speed: 1.0ms preprocess, 884.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 (no detections), 2592.5ms\n",
      "Speed: 1.4ms preprocess, 2592.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001711.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 bear, 1433.3ms\n",
      "Speed: 1.7ms preprocess, 1433.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1345.8ms\n",
      "Speed: 2.1ms preprocess, 1345.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1547.1ms\n",
      "Speed: 1.2ms preprocess, 1547.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1270.2ms\n",
      "Speed: 1.3ms preprocess, 1270.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1021.7ms\n",
      "Speed: 8.5ms preprocess, 1021.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1400.6ms\n",
      "Speed: 2.2ms preprocess, 1400.6ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001717.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1 sheep, 1689.7ms\n",
      "Speed: 2.3ms preprocess, 1689.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1257.5ms\n",
      "Speed: 1.6ms preprocess, 1257.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1691.3ms\n",
      "Speed: 2.3ms preprocess, 1691.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1059.8ms\n",
      "Speed: 1.3ms preprocess, 1059.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1181.7ms\n",
      "Speed: 1.4ms preprocess, 1181.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 970.8ms\n",
      "Speed: 1.7ms preprocess, 970.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1530.1ms\n",
      "Speed: 3.6ms preprocess, 1530.1ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001724.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 1 bear, 1000.9ms\n",
      "Speed: 1.5ms preprocess, 1000.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 876.4ms\n",
      "Speed: 1.2ms preprocess, 876.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 person, 1 dog, 926.5ms\n",
      "Speed: 1.8ms preprocess, 926.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 cow, 1212.5ms\n",
      "Speed: 1.3ms preprocess, 1212.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1439.3ms\n",
      "Speed: 2.6ms preprocess, 1439.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1288.1ms\n",
      "Speed: 1.5ms preprocess, 1288.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 dog, 1298.2ms\n",
      "Speed: 1.5ms preprocess, 1298.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1037.1ms\n",
      "Speed: 1.9ms preprocess, 1037.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 1580.0ms\n",
      "Speed: 1.8ms preprocess, 1580.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1202.5ms\n",
      "Speed: 13.5ms preprocess, 1202.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1422.4ms\n",
      "Speed: 1.8ms preprocess, 1422.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1914.1ms\n",
      "Speed: 1.3ms preprocess, 1914.1ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1258.4ms\n",
      "Speed: 2.5ms preprocess, 1258.4ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001737.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 bear, 1154.9ms\n",
      "Speed: 1.7ms preprocess, 1154.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1205.8ms\n",
      "Speed: 2.0ms preprocess, 1205.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1028.8ms\n",
      "Speed: 1.7ms preprocess, 1028.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1247.9ms\n",
      "Speed: 1.9ms preprocess, 1247.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 horse, 1 cow, 1618.7ms\n",
      "Speed: 2.0ms preprocess, 1618.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 1276.7ms\n",
      "Speed: 1.6ms preprocess, 1276.7ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001743.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1272.4ms\n",
      "Speed: 1.5ms preprocess, 1272.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1147.9ms\n",
      "Speed: 1.5ms preprocess, 1147.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1019.6ms\n",
      "Speed: 1.2ms preprocess, 1019.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 sheep, 1147.4ms\n",
      "Speed: 1.5ms preprocess, 1147.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 2531.0ms\n",
      "Speed: 1.5ms preprocess, 2531.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1339.6ms\n",
      "Speed: 1.4ms preprocess, 1339.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1093.2ms\n",
      "Speed: 1.3ms preprocess, 1093.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 horse, 1686.1ms\n",
      "Speed: 1.9ms preprocess, 1686.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1544.0ms\n",
      "Speed: 21.3ms preprocess, 1544.0ms inference, 0.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001752.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1190.4ms\n",
      "Speed: 1.8ms preprocess, 1190.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 cat, 2 bears, 843.8ms\n",
      "Speed: 1.1ms preprocess, 843.8ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1 cow, 1292.0ms\n",
      "Speed: 1.5ms preprocess, 1292.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 bear, 1277.6ms\n",
      "Speed: 1.2ms preprocess, 1277.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cow, 1078.8ms\n",
      "Speed: 2.1ms preprocess, 1078.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 bear, 1381.9ms\n",
      "Speed: 1.6ms preprocess, 1381.9ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1685.3ms\n",
      "Speed: 1.3ms preprocess, 1685.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sandwich, 1815.5ms\n",
      "Speed: 46.6ms preprocess, 1815.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1291.4ms\n",
      "Speed: 2.1ms preprocess, 1291.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001761.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 horse, 1 sheep, 1108.7ms\n",
      "Speed: 15.3ms preprocess, 1108.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1186.4ms\n",
      "Speed: 1.7ms preprocess, 1186.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1307.8ms\n",
      "Speed: 10.3ms preprocess, 1307.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001764.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 992.1ms\n",
      "Speed: 1.2ms preprocess, 992.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 2121.3ms\n",
      "Speed: 1.8ms preprocess, 2121.3ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001766.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x352 1 horse, 1046.9ms\n",
      "Speed: 1.0ms preprocess, 1046.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1081.5ms\n",
      "Speed: 2.1ms preprocess, 1081.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 (no detections), 2333.8ms\n",
      "Speed: 2.2ms preprocess, 2333.8ms inference, 0.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001769.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 cow, 1437.4ms\n",
      "Speed: 1.8ms preprocess, 1437.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1 horse, 1751.0ms\n",
      "Speed: 1.8ms preprocess, 1751.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 sheep, 1 cow, 1444.3ms\n",
      "Speed: 1.5ms preprocess, 1444.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1298.6ms\n",
      "Speed: 2.2ms preprocess, 1298.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1234.5ms\n",
      "Speed: 1.7ms preprocess, 1234.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1001.3ms\n",
      "Speed: 1.4ms preprocess, 1001.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 cat, 999.2ms\n",
      "Speed: 24.3ms preprocess, 999.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1533.1ms\n",
      "Speed: 2.5ms preprocess, 1533.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1473.1ms\n",
      "Speed: 9.9ms preprocess, 1473.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 horse, 1566.7ms\n",
      "Speed: 1.5ms preprocess, 1566.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 bear, 1645.2ms\n",
      "Speed: 1.4ms preprocess, 1645.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 elephant, 1899.5ms\n",
      "Speed: 1.8ms preprocess, 1899.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1362.8ms\n",
      "Speed: 1.5ms preprocess, 1362.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 bear, 1185.8ms\n",
      "Speed: 1.4ms preprocess, 1185.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1909.2ms\n",
      "Speed: 37.1ms preprocess, 1909.2ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1681.2ms\n",
      "Speed: 2.3ms preprocess, 1681.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1189.8ms\n",
      "Speed: 9.7ms preprocess, 1189.8ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1838.4ms\n",
      "Speed: 1.9ms preprocess, 1838.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1763.6ms\n",
      "Speed: 22.1ms preprocess, 1763.6ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1663.4ms\n",
      "Speed: 1.8ms preprocess, 1663.4ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 2788.9ms\n",
      "Speed: 1.7ms preprocess, 2788.9ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 1776.9ms\n",
      "Speed: 2.6ms preprocess, 1776.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1348.5ms\n",
      "Speed: 2.1ms preprocess, 1348.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 1485.5ms\n",
      "Speed: 1.5ms preprocess, 1485.5ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001793.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1360.9ms\n",
      "Speed: 19.6ms preprocess, 1360.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1721.0ms\n",
      "Speed: 2.4ms preprocess, 1721.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1799.3ms\n",
      "Speed: 1.8ms preprocess, 1799.3ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1027.3ms\n",
      "Speed: 1.3ms preprocess, 1027.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1571.1ms\n",
      "Speed: 1.6ms preprocess, 1571.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1446.4ms\n",
      "Speed: 1.8ms preprocess, 1446.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1426.3ms\n",
      "Speed: 1.5ms preprocess, 1426.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 2581.5ms\n",
      "Speed: 4.4ms preprocess, 2581.5ms inference, 64.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1447.3ms\n",
      "Speed: 2.3ms preprocess, 1447.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 sheeps, 1242.0ms\n",
      "Speed: 2.2ms preprocess, 1242.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 horse, 1466.8ms\n",
      "Speed: 18.8ms preprocess, 1466.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1444.1ms\n",
      "Speed: 2.1ms preprocess, 1444.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 2043.3ms\n",
      "Speed: 1.5ms preprocess, 2043.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2124.6ms\n",
      "Speed: 2.4ms preprocess, 2124.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1888.9ms\n",
      "Speed: 1.9ms preprocess, 1888.9ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1273.6ms\n",
      "Speed: 1.6ms preprocess, 1273.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1692.5ms\n",
      "Speed: 3.2ms preprocess, 1692.5ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 2349.2ms\n",
      "Speed: 2.4ms preprocess, 2349.2ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1679.6ms\n",
      "Speed: 1.5ms preprocess, 1679.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2030.8ms\n",
      "Speed: 2.0ms preprocess, 2030.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1877.8ms\n",
      "Speed: 1.9ms preprocess, 1877.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1597.7ms\n",
      "Speed: 1.7ms preprocess, 1597.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 3172.0ms\n",
      "Speed: 2.5ms preprocess, 3172.0ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 bear, 2163.9ms\n",
      "Speed: 2.5ms preprocess, 2163.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 2461.0ms\n",
      "Speed: 2.3ms preprocess, 2461.0ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1745.4ms\n",
      "Speed: 2.2ms preprocess, 1745.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1176.8ms\n",
      "Speed: 10.7ms preprocess, 1176.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1222.7ms\n",
      "Speed: 1.5ms preprocess, 1222.7ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001821.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1234.8ms\n",
      "Speed: 2.3ms preprocess, 1234.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cow, 1831.8ms\n",
      "Speed: 2.1ms preprocess, 1831.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 horse, 1587.6ms\n",
      "Speed: 1.9ms preprocess, 1587.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 sheep, 1078.0ms\n",
      "Speed: 1.4ms preprocess, 1078.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1323.1ms\n",
      "Speed: 9.5ms preprocess, 1323.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1276.7ms\n",
      "Speed: 1.4ms preprocess, 1276.7ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001827.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 bear, 1553.7ms\n",
      "Speed: 1.4ms preprocess, 1553.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1124.9ms\n",
      "Speed: 2.1ms preprocess, 1124.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1820.5ms\n",
      "Speed: 1.8ms preprocess, 1820.5ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1042.3ms\n",
      "Speed: 1.3ms preprocess, 1042.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 bear, 1175.0ms\n",
      "Speed: 1.9ms preprocess, 1175.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1233.2ms\n",
      "Speed: 1.6ms preprocess, 1233.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 (no detections), 1340.3ms\n",
      "Speed: 1.5ms preprocess, 1340.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001834.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1698.4ms\n",
      "Speed: 1.7ms preprocess, 1698.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 995.2ms\n",
      "Speed: 1.2ms preprocess, 995.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 cat, 1461.9ms\n",
      "Speed: 1.5ms preprocess, 1461.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x320 (no detections), 891.5ms\n",
      "Speed: 1.2ms preprocess, 891.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 320)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001838.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 sheep, 1 cow, 1206.4ms\n",
      "Speed: 1.8ms preprocess, 1206.4ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 2340.1ms\n",
      "Speed: 20.3ms preprocess, 2340.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001840.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1740.9ms\n",
      "Speed: 2.2ms preprocess, 1740.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1593.1ms\n",
      "Speed: 2.1ms preprocess, 1593.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1307.9ms\n",
      "Speed: 2.1ms preprocess, 1307.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1562.0ms\n",
      "Speed: 19.2ms preprocess, 1562.0ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1199.9ms\n",
      "Speed: 1.4ms preprocess, 1199.9ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 3 bears, 1468.0ms\n",
      "Speed: 1.7ms preprocess, 1468.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1169.6ms\n",
      "Speed: 1.9ms preprocess, 1169.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1022.5ms\n",
      "Speed: 11.6ms preprocess, 1022.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001848.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1483.2ms\n",
      "Speed: 1.6ms preprocess, 1483.2ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cat, 1905.1ms\n",
      "Speed: 2.1ms preprocess, 1905.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 horse, 1561.3ms\n",
      "Speed: 1.7ms preprocess, 1561.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1537.8ms\n",
      "Speed: 1.9ms preprocess, 1537.8ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1326.2ms\n",
      "Speed: 2.3ms preprocess, 1326.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1768.7ms\n",
      "Speed: 2.8ms preprocess, 1768.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001854.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 (no detections), 2126.0ms\n",
      "Speed: 2.0ms preprocess, 2126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001855.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cat, 1 bear, 2851.8ms\n",
      "Speed: 2.3ms preprocess, 2851.8ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1507.9ms\n",
      "Speed: 9.1ms preprocess, 1507.9ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001857.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 cow, 1369.8ms\n",
      "Speed: 2.7ms preprocess, 1369.8ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 cat, 1580.1ms\n",
      "Speed: 1.7ms preprocess, 1580.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 cats, 1195.6ms\n",
      "Speed: 1.6ms preprocess, 1195.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1331.4ms\n",
      "Speed: 1.2ms preprocess, 1331.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1354.3ms\n",
      "Speed: 1.7ms preprocess, 1354.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 sheeps, 1 cow, 1247.0ms\n",
      "Speed: 1.5ms preprocess, 1247.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1298.8ms\n",
      "Speed: 2.1ms preprocess, 1298.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1239.4ms\n",
      "Speed: 3.4ms preprocess, 1239.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1363.5ms\n",
      "Speed: 2.2ms preprocess, 1363.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 (no detections), 1135.3ms\n",
      "Speed: 1.2ms preprocess, 1135.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001867.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cat, 1031.5ms\n",
      "Speed: 1.2ms preprocess, 1031.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 sheep, 1634.0ms\n",
      "Speed: 2.5ms preprocess, 1634.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1184.9ms\n",
      "Speed: 1.6ms preprocess, 1184.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1181.1ms\n",
      "Speed: 15.0ms preprocess, 1181.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1 sheep, 1311.3ms\n",
      "Speed: 1.6ms preprocess, 1311.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1567.3ms\n",
      "Speed: 1.9ms preprocess, 1567.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 2442.0ms\n",
      "Speed: 0.9ms preprocess, 2442.0ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1795.7ms\n",
      "Speed: 2.1ms preprocess, 1795.7ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 (no detections), 1281.6ms\n",
      "Speed: 1.7ms preprocess, 1281.6ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001876.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1625.1ms\n",
      "Speed: 1.6ms preprocess, 1625.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 966.1ms\n",
      "Speed: 2.0ms preprocess, 966.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 cow, 1292.0ms\n",
      "Speed: 1.7ms preprocess, 1292.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1234.8ms\n",
      "Speed: 2.2ms preprocess, 1234.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 sheep, 1596.4ms\n",
      "Speed: 1.9ms preprocess, 1596.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 1 dog, 1 cow, 1633.7ms\n",
      "Speed: 1.8ms preprocess, 1633.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1308.4ms\n",
      "Speed: 1.4ms preprocess, 1308.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1 bear, 1269.8ms\n",
      "Speed: 1.6ms preprocess, 1269.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 sheeps, 1 bear, 1757.0ms\n",
      "Speed: 5.5ms preprocess, 1757.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1205.4ms\n",
      "Speed: 1.5ms preprocess, 1205.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 cow, 1521.3ms\n",
      "Speed: 1.8ms preprocess, 1521.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 (no detections), 1111.9ms\n",
      "Speed: 1.9ms preprocess, 1111.9ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001888.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1153.8ms\n",
      "Speed: 13.3ms preprocess, 1153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1 bear, 1461.1ms\n",
      "Speed: 1.7ms preprocess, 1461.1ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 1713.3ms\n",
      "Speed: 1.5ms preprocess, 1713.3ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 cat, 1103.7ms\n",
      "Speed: 1.3ms preprocess, 1103.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1844.8ms\n",
      "Speed: 1.6ms preprocess, 1844.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1813.4ms\n",
      "Speed: 2.6ms preprocess, 1813.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1234.3ms\n",
      "Speed: 1.2ms preprocess, 1234.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 943.3ms\n",
      "Speed: 1.1ms preprocess, 943.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1 dog, 2137.9ms\n",
      "Speed: 1.8ms preprocess, 2137.9ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1291.3ms\n",
      "Speed: 1.5ms preprocess, 1291.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 880.7ms\n",
      "Speed: 1.0ms preprocess, 880.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 horse, 1356.1ms\n",
      "Speed: 1.6ms preprocess, 1356.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1347.6ms\n",
      "Speed: 1.3ms preprocess, 1347.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 cow, 1595.5ms\n",
      "Speed: 1.5ms preprocess, 1595.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1511.0ms\n",
      "Speed: 1.7ms preprocess, 1511.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1353.0ms\n",
      "Speed: 1.8ms preprocess, 1353.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1057.6ms\n",
      "Speed: 1.4ms preprocess, 1057.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1606.6ms\n",
      "Speed: 1.8ms preprocess, 1606.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 2 bears, 1546.0ms\n",
      "Speed: 1.4ms preprocess, 1546.0ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 2 bears, 1229.1ms\n",
      "Speed: 1.3ms preprocess, 1229.1ms inference, 2.2ms postprocess per image at shape (1, 3, 256, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 (no detections), 2025.1ms\n",
      "Speed: 2.2ms preprocess, 2025.1ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001909.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 2726.5ms\n",
      "Speed: 2.0ms preprocess, 2726.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 (no detections), 1769.5ms\n",
      "Speed: 2.5ms preprocess, 1769.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001911.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x544 1 dog, 1532.2ms\n",
      "Speed: 1.7ms preprocess, 1532.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x608 2 bears, 1716.0ms\n",
      "Speed: 2.0ms preprocess, 1716.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1353.9ms\n",
      "Speed: 1.3ms preprocess, 1353.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1231.7ms\n",
      "Speed: 2.1ms preprocess, 1231.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1063.0ms\n",
      "Speed: 1.5ms preprocess, 1063.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1376.1ms\n",
      "Speed: 1.3ms preprocess, 1376.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 903.2ms\n",
      "Speed: 1.4ms preprocess, 903.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 dog, 1 bear, 1489.4ms\n",
      "Speed: 1.9ms preprocess, 1489.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 horse, 1731.7ms\n",
      "Speed: 1.7ms preprocess, 1731.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1330.9ms\n",
      "Speed: 1.7ms preprocess, 1330.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 5 bears, 1343.6ms\n",
      "Speed: 1.6ms preprocess, 1343.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1749.9ms\n",
      "Speed: 2.7ms preprocess, 1749.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1676.6ms\n",
      "Speed: 2.3ms preprocess, 1676.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cat, 1480.9ms\n",
      "Speed: 1.8ms preprocess, 1480.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x576 1 dog, 1555.9ms\n",
      "Speed: 1.9ms preprocess, 1555.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 1717.5ms\n",
      "Speed: 1.9ms preprocess, 1717.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 2708.8ms\n",
      "Speed: 1.9ms preprocess, 2708.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1180.5ms\n",
      "Speed: 1.3ms preprocess, 1180.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 cow, 1969.5ms\n",
      "Speed: 1.7ms preprocess, 1969.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1417.8ms\n",
      "Speed: 1.7ms preprocess, 1417.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1328.6ms\n",
      "Speed: 1.4ms preprocess, 1328.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1310.9ms\n",
      "Speed: 1.4ms preprocess, 1310.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 horse, 1 sheep, 2131.1ms\n",
      "Speed: 2.2ms preprocess, 2131.1ms inference, 2.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1478.3ms\n",
      "Speed: 5.0ms preprocess, 1478.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 horse, 2819.7ms\n",
      "Speed: 2.2ms preprocess, 2819.7ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 bear, 1749.6ms\n",
      "Speed: 2.2ms preprocess, 1749.6ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1 cow, 1293.3ms\n",
      "Speed: 1.6ms preprocess, 1293.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 cow, 1101.6ms\n",
      "Speed: 1.7ms preprocess, 1101.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 320x640 1 bear, 917.0ms\n",
      "Speed: 1.2ms preprocess, 917.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1159.3ms\n",
      "Speed: 1.5ms preprocess, 1159.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1 sheep, 1008.5ms\n",
      "Speed: 1.3ms preprocess, 1008.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1 cow, 1329.6ms\n",
      "Speed: 1.8ms preprocess, 1329.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 2079.6ms\n",
      "Speed: 1.7ms preprocess, 2079.6ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1446.1ms\n",
      "Speed: 1.6ms preprocess, 1446.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 cow, 1491.4ms\n",
      "Speed: 2.0ms preprocess, 1491.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 1 sheep, 1603.9ms\n",
      "Speed: 2.3ms preprocess, 1603.9ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1106.7ms\n",
      "Speed: 1.5ms preprocess, 1106.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1 cow, 1276.5ms\n",
      "Speed: 1.5ms preprocess, 1276.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 cow, 1195.4ms\n",
      "Speed: 10.4ms preprocess, 1195.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1313.8ms\n",
      "Speed: 2.1ms preprocess, 1313.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 1649.2ms\n",
      "Speed: 2.3ms preprocess, 1649.2ms inference, 0.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001952.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 cow, 1687.2ms\n",
      "Speed: 1.9ms preprocess, 1687.2ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 2836.1ms\n",
      "Speed: 1.5ms preprocess, 2836.1ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1368.4ms\n",
      "Speed: 1.4ms preprocess, 1368.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1595.5ms\n",
      "Speed: 1.8ms preprocess, 1595.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 cow, 1237.4ms\n",
      "Speed: 1.8ms preprocess, 1237.4ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 cat, 1 bear, 1 potted plant, 1639.7ms\n",
      "Speed: 1.8ms preprocess, 1639.7ms inference, 2.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x448 1 bear, 1188.4ms\n",
      "Speed: 1.4ms preprocess, 1188.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1368.1ms\n",
      "Speed: 1.5ms preprocess, 1368.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1638.7ms\n",
      "Speed: 2.1ms preprocess, 1638.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 2089.8ms\n",
      "Speed: 3.0ms preprocess, 2089.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 2820.1ms\n",
      "Speed: 2.0ms preprocess, 2820.1ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1734.5ms\n",
      "Speed: 2.5ms preprocess, 1734.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 256x640 (no detections), 809.0ms\n",
      "Speed: 1.3ms preprocess, 809.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000001965.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 bear, 1105.4ms\n",
      "Speed: 1.3ms preprocess, 1105.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 dog, 1635.1ms\n",
      "Speed: 1.9ms preprocess, 1635.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1 sheep, 1875.1ms\n",
      "Speed: 1.5ms preprocess, 1875.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 dog, 1607.0ms\n",
      "Speed: 1.7ms preprocess, 1607.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1704.3ms\n",
      "Speed: 2.0ms preprocess, 1704.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 1760.1ms\n",
      "Speed: 2.0ms preprocess, 1760.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 horse, 1 cow, 1717.2ms\n",
      "Speed: 1.6ms preprocess, 1717.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 bear, 1902.8ms\n",
      "Speed: 3.0ms preprocess, 1902.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1657.1ms\n",
      "Speed: 2.0ms preprocess, 1657.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1297.8ms\n",
      "Speed: 1.5ms preprocess, 1297.8ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 banana, 1700.2ms\n",
      "Speed: 2.4ms preprocess, 1700.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1265.4ms\n",
      "Speed: 1.7ms preprocess, 1265.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1 bear, 4076.0ms\n",
      "Speed: 1.7ms preprocess, 4076.0ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 4005.4ms\n",
      "Speed: 10.6ms preprocess, 4005.4ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1687.1ms\n",
      "Speed: 1.8ms preprocess, 1687.1ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 608x640 1 dog, 1 bear, 2160.7ms\n",
      "Speed: 2.2ms preprocess, 2160.7ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1574.2ms\n",
      "Speed: 2.1ms preprocess, 1574.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1595.9ms\n",
      "Speed: 2.0ms preprocess, 1595.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1 cow, 1888.4ms\n",
      "Speed: 2.2ms preprocess, 1888.4ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 cow, 1627.3ms\n",
      "Speed: 1.9ms preprocess, 1627.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 horse, 1676.0ms\n",
      "Speed: 1.2ms preprocess, 1676.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 2425.0ms\n",
      "Speed: 1.9ms preprocess, 2425.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 2 bears, 2258.1ms\n",
      "Speed: 2.9ms preprocess, 2258.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 bear, 1794.5ms\n",
      "Speed: 2.1ms preprocess, 1794.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x512 1 bear, 1728.7ms\n",
      "Speed: 2.2ms preprocess, 1728.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 bear, 1958.2ms\n",
      "Speed: 2.1ms preprocess, 1958.2ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 2206.8ms\n",
      "Speed: 1.5ms preprocess, 2206.8ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 dog, 1189.1ms\n",
      "Speed: 1.4ms preprocess, 1189.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1536.3ms\n",
      "Speed: 1.5ms preprocess, 1536.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 sheep, 1 bear, 1976.1ms\n",
      "Speed: 2.1ms preprocess, 1976.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 dog, 1 sheep, 1200.4ms\n",
      "Speed: 1.4ms preprocess, 1200.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x480 1 bear, 1413.8ms\n",
      "Speed: 1.5ms preprocess, 1413.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 dog, 1 sheep, 1111.0ms\n",
      "Speed: 1.8ms preprocess, 1111.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 2 sheeps, 1686.5ms\n",
      "Speed: 1.7ms preprocess, 1686.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 bear, 1362.5ms\n",
      "Speed: 1.3ms preprocess, 1362.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 dog, 2145.4ms\n",
      "Speed: 2.9ms preprocess, 2145.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 bear, 3617.2ms\n",
      "Speed: 1.8ms preprocess, 3617.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 1 dog, 1 horse, 2005.1ms\n",
      "Speed: 2.2ms preprocess, 2005.1ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 sheep, 1259.3ms\n",
      "Speed: 1.7ms preprocess, 1259.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 horse, 1 sheep, 1429.4ms\n",
      "Speed: 2.3ms preprocess, 1429.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x384 1 sheep, 1782.0ms\n",
      "Speed: 1.3ms preprocess, 1782.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1922.6ms\n",
      "Speed: 2.1ms preprocess, 1922.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 bear, 1922.8ms\n",
      "Speed: 1.6ms preprocess, 1922.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x416 1 horse, 1541.1ms\n",
      "Speed: 1.5ms preprocess, 1541.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1 bear, 1783.8ms\n",
      "Speed: 8.9ms preprocess, 1783.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 2 bears, 1585.9ms\n",
      "Speed: 2.5ms preprocess, 1585.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 dog, 1604.2ms\n",
      "Speed: 1.4ms preprocess, 1604.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1 cow, 1602.1ms\n",
      "Speed: 2.0ms preprocess, 1602.1ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cat, 1 dog, 1741.2ms\n",
      "Speed: 1.8ms preprocess, 1741.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1651.5ms\n",
      "Speed: 1.5ms preprocess, 1651.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1648.0ms\n",
      "Speed: 3.3ms preprocess, 1648.0ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 horse, 1789.2ms\n",
      "Speed: 1.8ms preprocess, 1789.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1656.3ms\n",
      "Speed: 2.1ms preprocess, 1656.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 horse, 1261.8ms\n",
      "Speed: 1.3ms preprocess, 1261.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 horse, 1545.3ms\n",
      "Speed: 1.8ms preprocess, 1545.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1350.3ms\n",
      "Speed: 1.3ms preprocess, 1350.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 640x640 1 cake, 2812.7ms\n",
      "Speed: 2.3ms preprocess, 2812.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 448x640 1 sheep, 1345.5ms\n",
      "Speed: 1.5ms preprocess, 1345.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 sheep, 1538.1ms\n",
      "Speed: 2.4ms preprocess, 1538.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cow, 1480.1ms\n",
      "Speed: 2.1ms preprocess, 1480.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 224x640 2 bears, 701.9ms\n",
      "Speed: 0.8ms preprocess, 701.9ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 cow, 1507.9ms\n",
      "Speed: 1.7ms preprocess, 1507.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 544x640 1 sheep, 1530.2ms\n",
      "Speed: 2.0ms preprocess, 1530.2ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 (no detections), 1128.2ms\n",
      "Speed: 1.5ms preprocess, 1128.2ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000002029.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 bear, 1326.2ms\n",
      "Speed: 2.5ms preprocess, 1326.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 3072.8ms\n",
      "Speed: 2.4ms preprocess, 3072.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 352x640 1 dog, 1220.1ms\n",
      "Speed: 1.4ms preprocess, 1220.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 sheep, 1 cow, 1252.0ms\n",
      "Speed: 1.3ms preprocess, 1252.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 cat, 1 dog, 1677.1ms\n",
      "Speed: 2.1ms preprocess, 1677.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 512x640 1 sheep, 1845.6ms\n",
      "Speed: 3.2ms preprocess, 1845.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 416x640 1 sheep, 1571.6ms\n",
      "Speed: 2.1ms preprocess, 1571.6ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 480x640 1 bear, 1788.7ms\n",
      "Speed: 1.9ms preprocess, 1788.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 576x640 (no detections), 2199.2ms\n",
      "Speed: 1.9ms preprocess, 2199.2ms inference, 0.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "No mask found for image: hyena.coco/images/train2022/000000002038.jpg\n",
      "running segmentation on pre-existing bbox\n",
      "\n",
      "0: 384x640 1 bear, 1536.2ms\n",
      "Speed: 1.5ms preprocess, 1536.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "running segmentation on pre-existing bbox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_hyenas = os.path.join(root, 'HyenaID2022')\n",
    "dataset_hyenas = datasets.HyenaID2022(path_hyenas)\n",
    "\n",
    "data_hyenas = WildlifeDataModule(\n",
    "                            metadata=dataset_hyenas.df,\n",
    "                            data_dir=path_hyenas, \n",
    "                            preprocess_lvl=2,\n",
    "                            batch_size=4, \n",
    "                            cache_path=\"/Users/amee/Documents/code/master-thesis/EagleID/dataset/dataframe/cache_hyenas.csv\",\n",
    "                            animal_cat=\"mammal\", \n",
    "                            splitter ='custom_closed', \n",
    "                            wildlife_names='hyenas',\n",
    "                            precompute=True,\n",
    "                            only_cache=False,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nonwild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from wildlife_datasets import analysis, datasets, loader\n",
    "\n",
    "sys.path.append('..')\n",
    "dataset = datasets.WhaleSharkID('/Users/amee/Documents/code/master-thesis/datasets/EDA-Whaleshark/')\n",
    "dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.raptors_wildlife import GoldensWildlife\n",
    "dataset_goleag = GoldensWildlife(root='../../datasets/raptor_individuals_cropped', include_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>species</th>\n",
       "      <th>identity_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>from_video</th>\n",
       "      <th>video</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267</td>\n",
       "      <td>goleag</td>\n",
       "      <td>32</td>\n",
       "      <td>SouthScotland_spiritG26</td>\n",
       "      <td>goleag/SouthScotland_spiritG26/img-0098-mull-m...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268</td>\n",
       "      <td>goleag</td>\n",
       "      <td>32</td>\n",
       "      <td>SouthScotland_spiritG26</td>\n",
       "      <td>goleag/SouthScotland_spiritG26/img-4927-mull-m...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "      <td>goleag</td>\n",
       "      <td>33</td>\n",
       "      <td>Alabama_natchez</td>\n",
       "      <td>goleag/Alabama_natchez/mfdc6688_crop.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270</td>\n",
       "      <td>goleag</td>\n",
       "      <td>33</td>\n",
       "      <td>Alabama_natchez</td>\n",
       "      <td>goleag/Alabama_natchez/Natchez.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271</td>\n",
       "      <td>goleag</td>\n",
       "      <td>33</td>\n",
       "      <td>Alabama_natchez</td>\n",
       "      <td>goleag/Alabama_natchez/bostonmmountains.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>504</td>\n",
       "      <td>goleag</td>\n",
       "      <td>68</td>\n",
       "      <td>SouthScotland_tallaF15</td>\n",
       "      <td>goleag/SouthScotland_tallaF15/img-0180-ardveri...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>505</td>\n",
       "      <td>goleag</td>\n",
       "      <td>68</td>\n",
       "      <td>SouthScotland_tallaF15</td>\n",
       "      <td>goleag/SouthScotland_tallaF15/7db26611-09d3-4b...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>506</td>\n",
       "      <td>goleag</td>\n",
       "      <td>69</td>\n",
       "      <td>SouthScotland_sulaB50</td>\n",
       "      <td>goleag/SouthScotland_sulaB50/p2920352-loch-eri...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>507</td>\n",
       "      <td>goleag</td>\n",
       "      <td>69</td>\n",
       "      <td>SouthScotland_sulaB50</td>\n",
       "      <td>goleag/SouthScotland_sulaB50/p2920354-moment-a...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>508</td>\n",
       "      <td>goleag</td>\n",
       "      <td>69</td>\n",
       "      <td>SouthScotland_sulaB50</td>\n",
       "      <td>goleag/SouthScotland_sulaB50/img-0485-loch-eri...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id species  identity_id                 identity  \\\n",
       "0         267  goleag           32  SouthScotland_spiritG26   \n",
       "1         268  goleag           32  SouthScotland_spiritG26   \n",
       "2         269  goleag           33          Alabama_natchez   \n",
       "3         270  goleag           33          Alabama_natchez   \n",
       "4         271  goleag           33          Alabama_natchez   \n",
       "..        ...     ...          ...                      ...   \n",
       "237       504  goleag           68   SouthScotland_tallaF15   \n",
       "238       505  goleag           68   SouthScotland_tallaF15   \n",
       "239       506  goleag           69    SouthScotland_sulaB50   \n",
       "240       507  goleag           69    SouthScotland_sulaB50   \n",
       "241       508  goleag           69    SouthScotland_sulaB50   \n",
       "\n",
       "                                                  path  from_video video  date  \n",
       "0    goleag/SouthScotland_spiritG26/img-0098-mull-m...       False  None  2000  \n",
       "1    goleag/SouthScotland_spiritG26/img-4927-mull-m...       False  None  2023  \n",
       "2             goleag/Alabama_natchez/mfdc6688_crop.jpg       False  None  2000  \n",
       "3                   goleag/Alabama_natchez/Natchez.jpg       False  None  2000  \n",
       "4          goleag/Alabama_natchez/bostonmmountains.jpg       False  None  2000  \n",
       "..                                                 ...         ...   ...   ...  \n",
       "237  goleag/SouthScotland_tallaF15/img-0180-ardveri...       False  None  2000  \n",
       "238  goleag/SouthScotland_tallaF15/7db26611-09d3-4b...       False  None  2000  \n",
       "239  goleag/SouthScotland_sulaB50/p2920352-loch-eri...       False  None  2022  \n",
       "240  goleag/SouthScotland_sulaB50/p2920354-moment-a...       False  None  2000  \n",
       "241  goleag/SouthScotland_sulaB50/img-0485-loch-eri...       False  None  2022  \n",
       "\n",
       "[242 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_goleag.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before pre-processing and cleaning: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x544 1 bench, 1 bird, 1 dog, 1334.5ms\n",
      "Speed: 3.5ms preprocess, 1334.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 480x640 1 bird, 1196.0ms\n",
      "Speed: 1.2ms preprocess, 1196.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 192x640 1 cow, 573.6ms\n",
      "Speed: 0.5ms preprocess, 573.6ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 car, 1 bird, 1158.7ms\n",
      "Speed: 1.5ms preprocess, 1158.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 bird, 734.3ms\n",
      "Speed: 0.9ms preprocess, 734.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bird, 1036.8ms\n",
      "Speed: 1.2ms preprocess, 1036.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bird, 1135.8ms\n",
      "Speed: 1.7ms preprocess, 1135.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bird, 1072.1ms\n",
      "Speed: 2.2ms preprocess, 1072.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 1 bird, 1007.6ms\n",
      "Speed: 1.4ms preprocess, 1007.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 998.0ms\n",
      "Speed: 0.9ms preprocess, 998.0ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1049.2ms\n",
      "Speed: 1.2ms preprocess, 1049.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x512 1 bird, 1039.9ms\n",
      "Speed: 0.9ms preprocess, 1039.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 973.0ms\n",
      "Speed: 1.4ms preprocess, 973.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 2 birds, 1079.8ms\n",
      "Speed: 1.1ms preprocess, 1079.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1116.5ms\n",
      "Speed: 0.6ms preprocess, 1116.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 288x640 1 bird, 853.5ms\n",
      "Speed: 0.7ms preprocess, 853.5ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 352x640 1 bird, 935.4ms\n",
      "Speed: 1.1ms preprocess, 935.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1248.9ms\n",
      "Speed: 1.1ms preprocess, 1248.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1495.4ms\n",
      "Speed: 0.9ms preprocess, 1495.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 bird, 2039.1ms\n",
      "Speed: 1.3ms preprocess, 2039.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 544x640 2 birds, 2006.1ms\n",
      "Speed: 1.3ms preprocess, 2006.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1323.9ms\n",
      "Speed: 1.8ms preprocess, 1323.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1181.1ms\n",
      "Speed: 1.1ms preprocess, 1181.1ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 544x640 4 birds, 1787.5ms\n",
      "Speed: 1.5ms preprocess, 1787.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 640x608 1 bird, 1537.1ms\n",
      "Speed: 1.5ms preprocess, 1537.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 512x640 2 birds, 1322.1ms\n",
      "Speed: 1.0ms preprocess, 1322.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 416x640 2 birds, 1447.4ms\n",
      "Speed: 1.5ms preprocess, 1447.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1364.4ms\n",
      "Speed: 5.1ms preprocess, 1364.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x480 1 bench, 1 bear, 1408.1ms\n",
      "Speed: 1.3ms preprocess, 1408.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 bird, 1181.6ms\n",
      "Speed: 1.5ms preprocess, 1181.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1131.4ms\n",
      "Speed: 0.9ms preprocess, 1131.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x576 1 bird, 1373.9ms\n",
      "Speed: 1.3ms preprocess, 1373.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 640x576 2 birds, 1301.9ms\n",
      "Speed: 1.4ms preprocess, 1301.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 512x640 1 bird, 1334.8ms\n",
      "Speed: 1.1ms preprocess, 1334.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 608x640 1 bird, 2011.3ms\n",
      "Speed: 1.2ms preprocess, 2011.3ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 448x640 3 birds, 1192.1ms\n",
      "Speed: 0.9ms preprocess, 1192.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1373.1ms\n",
      "Speed: 1.0ms preprocess, 1373.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 bird, 2973.3ms\n",
      "Speed: 3.6ms preprocess, 2973.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 512x640 1 bird, 2434.8ms\n",
      "Speed: 3.9ms preprocess, 2434.8ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 608x640 1 bird, 2695.5ms\n",
      "Speed: 2.0ms preprocess, 2695.5ms inference, 2.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 576x640 4 birds, 2518.3ms\n",
      "Speed: 2.6ms preprocess, 2518.3ms inference, 5.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x512 1 bird, 3020.1ms\n",
      "Speed: 1.9ms preprocess, 3020.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 448x640 1 bird, 2424.5ms\n",
      "Speed: 2.5ms preprocess, 2424.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 birds, 1203.6ms\n",
      "Speed: 1.6ms preprocess, 1203.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1176.0ms\n",
      "Speed: 1.5ms preprocess, 1176.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1570.6ms\n",
      "Speed: 1.2ms preprocess, 1570.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bird, 862.3ms\n",
      "Speed: 1.4ms preprocess, 862.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bird, 1353.3ms\n",
      "Speed: 1.2ms preprocess, 1353.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bird, 1390.0ms\n",
      "Speed: 1.0ms preprocess, 1390.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1440.2ms\n",
      "Speed: 2.7ms preprocess, 1440.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 1 bench, 3 birds, 1236.2ms\n",
      "Speed: 1.3ms preprocess, 1236.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1086.5ms\n",
      "Speed: 1.3ms preprocess, 1086.5ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1578.3ms\n",
      "Speed: 1.6ms preprocess, 1578.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x416 1 bird, 1133.1ms\n",
      "Speed: 1.0ms preprocess, 1133.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 640x384 1 person, 955.1ms\n",
      "Speed: 0.9ms preprocess, 955.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 416x640 1 person, 1159.7ms\n",
      "Speed: 0.8ms preprocess, 1159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bench, 1 bird, 2519.5ms\n",
      "Speed: 1.7ms preprocess, 2519.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 416x640 2 birds, 1257.1ms\n",
      "Speed: 1.5ms preprocess, 1257.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1584.6ms\n",
      "Speed: 2.5ms preprocess, 1584.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x576 1 bird, 1490.3ms\n",
      "Speed: 2.2ms preprocess, 1490.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 320x640 1 bird, 805.3ms\n",
      "Speed: 0.8ms preprocess, 805.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1134.5ms\n",
      "Speed: 1.1ms preprocess, 1134.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1426.5ms\n",
      "Speed: 1.1ms preprocess, 1426.5ms inference, 0.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1089.1ms\n",
      "Speed: 1.0ms preprocess, 1089.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1323.0ms\n",
      "Speed: 1.3ms preprocess, 1323.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1288.7ms\n",
      "Speed: 1.1ms preprocess, 1288.7ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 bird, 1389.6ms\n",
      "Speed: 1.1ms preprocess, 1389.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1393.7ms\n",
      "Speed: 1.1ms preprocess, 1393.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 birds, 1271.4ms\n",
      "Speed: 1.0ms preprocess, 1271.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1348.6ms\n",
      "Speed: 1.2ms preprocess, 1348.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x608 1 bird, 1515.1ms\n",
      "Speed: 1.4ms preprocess, 1515.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 544x640 2 birds, 1934.7ms\n",
      "Speed: 1.1ms preprocess, 1934.7ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1572.9ms\n",
      "Speed: 1.7ms preprocess, 1572.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x608 1 bird, 1657.2ms\n",
      "Speed: 1.5ms preprocess, 1657.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 448x640 2 birds, 1138.3ms\n",
      "Speed: 1.1ms preprocess, 1138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1189.7ms\n",
      "Speed: 1.4ms preprocess, 1189.7ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1072.5ms\n",
      "Speed: 1.2ms preprocess, 1072.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x416 2 birds, 1327.6ms\n",
      "Speed: 1.0ms preprocess, 1327.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 512x640 1 bird, 1321.1ms\n",
      "Speed: 1.4ms preprocess, 1321.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1430.0ms\n",
      "Speed: 1.2ms preprocess, 1430.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x640 1 bird, 1417.5ms\n",
      "Speed: 1.2ms preprocess, 1417.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 bird, 1050.5ms\n",
      "Speed: 1.1ms preprocess, 1050.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 544x640 1 bird, 1174.8ms\n",
      "Speed: 1.3ms preprocess, 1174.8ms inference, 0.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1162.8ms\n",
      "Speed: 1.3ms preprocess, 1162.8ms inference, 0.9ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 608x640 1 bird, 1341.2ms\n",
      "Speed: 1.3ms preprocess, 1341.2ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1084.0ms\n",
      "Speed: 1.1ms preprocess, 1084.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 1 suitcase, 1046.6ms\n",
      "Speed: 1.5ms preprocess, 1046.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 1 person, 1197.6ms\n",
      "Speed: 1.3ms preprocess, 1197.6ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1351.9ms\n",
      "Speed: 1.3ms preprocess, 1351.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1511.2ms\n",
      "Speed: 1.8ms preprocess, 1511.2ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1475.5ms\n",
      "Speed: 1.4ms preprocess, 1475.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1376.3ms\n",
      "Speed: 1.1ms preprocess, 1376.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 birds, 1767.3ms\n",
      "Speed: 1.1ms preprocess, 1767.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1428.2ms\n",
      "Speed: 1.2ms preprocess, 1428.2ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1645.4ms\n",
      "Speed: 2.5ms preprocess, 1645.4ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 2 birds, 1824.0ms\n",
      "Speed: 1.9ms preprocess, 1824.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 7 birds, 1749.4ms\n",
      "Speed: 1.4ms preprocess, 1749.4ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 5 birds, 1255.5ms\n",
      "Speed: 1.3ms preprocess, 1255.5ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 512x640 4 birds, 1108.5ms\n",
      "Speed: 1.1ms preprocess, 1108.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1131.6ms\n",
      "Speed: 1.4ms preprocess, 1131.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 608x640 1 bird, 1 bear, 1455.2ms\n",
      "Speed: 1.5ms preprocess, 1455.2ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 640x640 1 bird, 1720.9ms\n",
      "Speed: 1.6ms preprocess, 1720.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bird, 1745.8ms\n",
      "Speed: 1.8ms preprocess, 1745.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 416x640 1 bird, 948.0ms\n",
      "Speed: 1.2ms preprocess, 948.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x448 2 birds, 1115.0ms\n",
      "Speed: 1.3ms preprocess, 1115.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x512 1 bird, 1104.3ms\n",
      "Speed: 1.2ms preprocess, 1104.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 bird, 1384.3ms\n",
      "Speed: 1.4ms preprocess, 1384.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 1 bird, 1082.4ms\n",
      "Speed: 1.4ms preprocess, 1082.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1687.5ms\n",
      "Speed: 1.3ms preprocess, 1687.5ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1393.9ms\n",
      "Speed: 1.9ms preprocess, 1393.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1178.8ms\n",
      "Speed: 1.5ms preprocess, 1178.8ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1231.9ms\n",
      "Speed: 1.7ms preprocess, 1231.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1227.4ms\n",
      "Speed: 1.3ms preprocess, 1227.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x448 1 bird, 1153.0ms\n",
      "Speed: 1.6ms preprocess, 1153.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 192x640 1 bird, 435.1ms\n",
      "Speed: 0.6ms preprocess, 435.1ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 640x480 1 bird, 1100.2ms\n",
      "Speed: 1.9ms preprocess, 1100.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 384x640 1 bird, 1066.7ms\n",
      "Speed: 1.2ms preprocess, 1066.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1281.6ms\n",
      "Speed: 1.7ms preprocess, 1281.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1326.8ms\n",
      "Speed: 1.3ms preprocess, 1326.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1550.1ms\n",
      "Speed: 1.5ms preprocess, 1550.1ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x512 2 birds, 2775.3ms\n",
      "Speed: 1.5ms preprocess, 2775.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 416x640 1 bird, 1000.7ms\n",
      "Speed: 1.6ms preprocess, 1000.7ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x320 2 birds, 1 sink, 752.8ms\n",
      "Speed: 0.9ms preprocess, 752.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 384x640 1 bird, 829.9ms\n",
      "Speed: 1.1ms preprocess, 829.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1247.6ms\n",
      "Speed: 1.6ms preprocess, 1247.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 416x640 1 bird, 1 tv, 1191.4ms\n",
      "Speed: 1.3ms preprocess, 1191.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1243.7ms\n",
      "Speed: 1.4ms preprocess, 1243.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 512x640 1 bird, 1092.6ms\n",
      "Speed: 1.6ms preprocess, 1092.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 320x640 1 bird, 689.0ms\n",
      "Speed: 1.0ms preprocess, 689.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 352x640 1 bird, 990.6ms\n",
      "Speed: 1.1ms preprocess, 990.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1921.9ms\n",
      "Speed: 1.4ms preprocess, 1921.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1718.4ms\n",
      "Speed: 1.3ms preprocess, 1718.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x544 2 birds, 1444.3ms\n",
      "Speed: 2.2ms preprocess, 1444.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 1 bird, 2096.1ms\n",
      "Speed: 1.2ms preprocess, 2096.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1777.7ms\n",
      "Speed: 1.4ms preprocess, 1777.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 480x640 1 bird, 1827.8ms\n",
      "Speed: 1.9ms preprocess, 1827.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1561.4ms\n",
      "Speed: 1.8ms preprocess, 1561.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 bird, 1362.4ms\n",
      "Speed: 1.6ms preprocess, 1362.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 416x640 1 bird, 1018.5ms\n",
      "Speed: 1.6ms preprocess, 1018.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 2 birds, 876.9ms\n",
      "Speed: 1.7ms preprocess, 876.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1327.0ms\n",
      "Speed: 1.6ms preprocess, 1327.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 352x640 1 bird, 1015.6ms\n",
      "Speed: 1.1ms preprocess, 1015.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1075.3ms\n",
      "Speed: 1.7ms preprocess, 1075.3ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 2 birds, 1 tv, 1213.4ms\n",
      "Speed: 1.5ms preprocess, 1213.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 1 bird, 2162.2ms\n",
      "Speed: 1.4ms preprocess, 2162.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 2 birds, 1 sheep, 1867.6ms\n",
      "Speed: 2.2ms preprocess, 1867.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1674.9ms\n",
      "Speed: 1.6ms preprocess, 1674.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 480x640 1 person, 1 skis, 1471.3ms\n",
      "Speed: 1.4ms preprocess, 1471.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1 tv, 1325.2ms\n",
      "Speed: 1.5ms preprocess, 1325.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1716.8ms\n",
      "Speed: 1.6ms preprocess, 1716.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x640 2 birds, 1522.3ms\n",
      "Speed: 1.9ms preprocess, 1522.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1366.5ms\n",
      "Speed: 1.8ms preprocess, 1366.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 480x640 1 bird, 1116.8ms\n",
      "Speed: 1.3ms preprocess, 1116.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x640 1 bird, 1 toothbrush, 728.0ms\n",
      "Speed: 0.8ms preprocess, 728.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1286.2ms\n",
      "Speed: 1.6ms preprocess, 1286.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 512x640 1 bird, 1210.1ms\n",
      "Speed: 1.7ms preprocess, 1210.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1197.1ms\n",
      "Speed: 1.3ms preprocess, 1197.1ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1214.8ms\n",
      "Speed: 1.2ms preprocess, 1214.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1027.3ms\n",
      "Speed: 1.5ms preprocess, 1027.3ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 256x640 1 airplane, 570.4ms\n",
      "Speed: 0.8ms preprocess, 570.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 640x544 1 bear, 1279.7ms\n",
      "Speed: 1.0ms preprocess, 1279.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 train, 1 bird, 1509.8ms\n",
      "Speed: 1.5ms preprocess, 1509.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 bird, 1570.5ms\n",
      "Speed: 1.7ms preprocess, 1570.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 416x640 1 bird, 1 tv, 1612.5ms\n",
      "Speed: 1.8ms preprocess, 1612.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 384x640 1 bird, 1422.2ms\n",
      "Speed: 1.3ms preprocess, 1422.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1587.9ms\n",
      "Speed: 0.7ms preprocess, 1587.9ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1 bear, 1390.8ms\n",
      "Speed: 1.6ms preprocess, 1390.8ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x640 1 airplane, 1776.4ms\n",
      "Speed: 1.3ms preprocess, 1776.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1 dog, 1 tv, 1376.6ms\n",
      "Speed: 1.5ms preprocess, 1376.6ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1364.4ms\n",
      "Speed: 1.1ms preprocess, 1364.4ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1294.5ms\n",
      "Speed: 1.3ms preprocess, 1294.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1959.3ms\n",
      "Speed: 1.6ms preprocess, 1959.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1 clock, 1956.2ms\n",
      "Speed: 2.0ms preprocess, 1956.2ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1115.9ms\n",
      "Speed: 1.9ms preprocess, 1115.9ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 608x640 1 bird, 2180.1ms\n",
      "Speed: 2.4ms preprocess, 2180.1ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 608x640 1 person, 2547.5ms\n",
      "Speed: 1.8ms preprocess, 2547.5ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 416x640 2 birds, 1 sports ball, 1 tv, 1 clock, 1532.7ms\n",
      "Speed: 1.5ms preprocess, 1532.7ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x640 2 birds, 3182.5ms\n",
      "Speed: 1.8ms preprocess, 3182.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 1 bird, 2542.5ms\n",
      "Speed: 2.0ms preprocess, 2542.5ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 1 bird, 1529.6ms\n",
      "Speed: 1.3ms preprocess, 1529.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 bird, 1452.9ms\n",
      "Speed: 1.1ms preprocess, 1452.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1357.2ms\n",
      "Speed: 1.2ms preprocess, 1357.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 608x640 1 bird, 1426.0ms\n",
      "Speed: 1.6ms preprocess, 1426.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1144.2ms\n",
      "Speed: 1.1ms preprocess, 1144.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 416x640 1 bird, 897.7ms\n",
      "Speed: 1.4ms preprocess, 897.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x480 1 bird, 1085.3ms\n",
      "Speed: 1.0ms preprocess, 1085.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x576 1 bird, 1286.8ms\n",
      "Speed: 1.4ms preprocess, 1286.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 512x640 1 bird, 1385.0ms\n",
      "Speed: 2.1ms preprocess, 1385.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1018.3ms\n",
      "Speed: 1.6ms preprocess, 1018.3ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1933.1ms\n",
      "Speed: 1.1ms preprocess, 1933.1ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 3 birds, 2 kites, 1680.8ms\n",
      "Speed: 1.8ms preprocess, 1680.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1785.8ms\n",
      "Speed: 2.0ms preprocess, 1785.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 1 bear, 2179.2ms\n",
      "Speed: 2.3ms preprocess, 2179.2ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 1 bird, 2076.1ms\n",
      "Speed: 1.5ms preprocess, 2076.1ms inference, 20.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x544 1 bird, 2245.5ms\n",
      "Speed: 4.5ms preprocess, 2245.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x640 2 birds, 2150.4ms\n",
      "Speed: 2.5ms preprocess, 2150.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1502.6ms\n",
      "Speed: 1.9ms preprocess, 1502.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 512x640 1 bird, 1592.1ms\n",
      "Speed: 2.3ms preprocess, 1592.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 608x640 1 bird, 1731.8ms\n",
      "Speed: 2.7ms preprocess, 1731.8ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 416x640 1 bench, 1 bird, 1091.3ms\n",
      "Speed: 1.5ms preprocess, 1091.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 512x640 2 birds, 1633.7ms\n",
      "Speed: 4.8ms preprocess, 1633.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 bird, 1354.8ms\n",
      "Speed: 1.4ms preprocess, 1354.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 bench, 1 bird, 1502.0ms\n",
      "Speed: 1.5ms preprocess, 1502.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 bench, 1 bird, 1388.7ms\n",
      "Speed: 2.0ms preprocess, 1388.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x416 1 bird, 982.3ms\n",
      "Speed: 1.0ms preprocess, 982.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 640x544 1 bird, 1337.2ms\n",
      "Speed: 1.7ms preprocess, 1337.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 512x640 1 bird, 1380.2ms\n",
      "Speed: 1.2ms preprocess, 1380.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 544x640 1 bird, 1395.7ms\n",
      "Speed: 1.1ms preprocess, 1395.7ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1226.9ms\n",
      "Speed: 1.2ms preprocess, 1226.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1306.9ms\n",
      "Speed: 1.5ms preprocess, 1306.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 608x640 1 bird, 1772.6ms\n",
      "Speed: 1.5ms preprocess, 1772.6ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 576x640 1 bird, 2920.3ms\n",
      "Speed: 2.8ms preprocess, 2920.3ms inference, 3.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1605.9ms\n",
      "Speed: 5.9ms preprocess, 1605.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x576 1 bird, 1637.2ms\n",
      "Speed: 1.2ms preprocess, 1637.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 256x640 1 bird, 924.6ms\n",
      "Speed: 0.7ms preprocess, 924.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1320.6ms\n",
      "Speed: 1.7ms preprocess, 1320.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bird, 2236.0ms\n",
      "Speed: 1.7ms preprocess, 2236.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 donut, 2663.0ms\n",
      "Speed: 1.6ms preprocess, 2663.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x608 1 bird, 1580.9ms\n",
      "Speed: 1.8ms preprocess, 1580.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 608x640 1 bird, 1 bear, 1569.5ms\n",
      "Speed: 2.0ms preprocess, 1569.5ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 640x576 1 bird, 1988.4ms\n",
      "Speed: 1.6ms preprocess, 1988.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 608x640 1 person, 1 baseball glove, 1472.4ms\n",
      "Speed: 1.7ms preprocess, 1472.4ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 416x640 2 birds, 1 tv, 1092.1ms\n",
      "Speed: 1.5ms preprocess, 1092.1ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x640 1 bird, 1 sheep, 1784.5ms\n",
      "Speed: 2.4ms preprocess, 1784.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 1 airplane, 1621.9ms\n",
      "Speed: 1.1ms preprocess, 1621.9ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 416x640 1 bird, 1161.1ms\n",
      "Speed: 2.1ms preprocess, 1161.1ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1512.2ms\n",
      "Speed: 1.6ms preprocess, 1512.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x480 1 bird, 1332.5ms\n",
      "Speed: 1.2ms preprocess, 1332.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x576 1 bird, 1644.7ms\n",
      "Speed: 1.5ms preprocess, 1644.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 480x640 1 bird, 2014.2ms\n",
      "Speed: 1.5ms preprocess, 2014.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 bird, 2695.2ms\n",
      "Speed: 2.0ms preprocess, 2695.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 bird, 1365.6ms\n",
      "Speed: 1.6ms preprocess, 1365.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 2 birds, 2123.1ms\n",
      "Speed: 2.0ms preprocess, 2123.1ms inference, 4.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 512x640 1 bird, 2189.0ms\n",
      "Speed: 2.4ms preprocess, 2189.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 bird, 1065.9ms\n",
      "Speed: 1.3ms preprocess, 1065.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 576x640 1 person, 1 dog, 1320.6ms\n",
      "Speed: 1.3ms preprocess, 1320.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 bird, 1316.8ms\n",
      "Speed: 1.5ms preprocess, 1316.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 bird, 1106.6ms\n",
      "Speed: 1.2ms preprocess, 1106.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 bird, 1141.0ms\n",
      "Speed: 1.5ms preprocess, 1141.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 608x640 3 birds, 1 bear, 1419.2ms\n",
      "Speed: 1.2ms preprocess, 1419.2ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 640x544 1 bird, 1225.3ms\n",
      "Speed: 1.5ms preprocess, 1225.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 bird, 1251.0ms\n",
      "Speed: 1.5ms preprocess, 1251.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Removed 0 rows with invalid segmentation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/animal_2d_keypoint/topdown_heatmap/animal_kingdom/td-hm_hrnet-w32_8xb32-300e_animalkingdom_P3_bird-256x256-566feff5_20230519.pth\n",
      "11/08 19:39:28 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpose\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpose\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_m_8xb32-300e_coco/rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n",
      "11/08 19:39:28 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/Users/amee/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1724557175021/work/aten/src/ATen/native/TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: 267 with number of keypoints 23\n",
      "Processed image: 268 with number of keypoints 23\n",
      "Processed image: 269 with number of keypoints 23\n",
      "Processed image: 270 with number of keypoints 23\n",
      "Processed image: 271 with number of keypoints 23\n",
      "Processed image: 272 with number of keypoints 23\n",
      "Processed image: 273 with number of keypoints 23\n",
      "Processed image: 274 with number of keypoints 23\n",
      "Processed image: 275 with number of keypoints 23\n",
      "Processed image: 276 with number of keypoints 23\n",
      "Processed image: 277 with number of keypoints 23\n",
      "Processed image: 278 with number of keypoints 23\n",
      "Processed image: 279 with number of keypoints 23\n",
      "Processed image: 280 with number of keypoints 23\n",
      "Processed image: 281 with number of keypoints 23\n",
      "Processed image: 282 with number of keypoints 23\n",
      "Processed image: 283 with number of keypoints 23\n",
      "Processed image: 284 with number of keypoints 23\n",
      "Processed image: 285 with number of keypoints 23\n",
      "Processed image: 286 with number of keypoints 23\n",
      "Processed image: 287 with number of keypoints 23\n",
      "Processed image: 288 with number of keypoints 23\n",
      "Processed image: 289 with number of keypoints 23\n",
      "Processed image: 290 with number of keypoints 23\n",
      "Processed image: 291 with number of keypoints 23\n",
      "Processed image: 292 with number of keypoints 23\n",
      "Processed image: 293 with number of keypoints 23\n",
      "Processed image: 294 with number of keypoints 23\n",
      "Processed image: 295 with number of keypoints 23\n",
      "Processed image: 296 with number of keypoints 23\n",
      "Processed image: 297 with number of keypoints 23\n",
      "Processed image: 298 with number of keypoints 23\n",
      "Processed image: 299 with number of keypoints 23\n",
      "Processed image: 300 with number of keypoints 23\n",
      "Processed image: 301 with number of keypoints 23\n",
      "Processed image: 302 with number of keypoints 23\n",
      "Processed image: 303 with number of keypoints 23\n",
      "Processed image: 304 with number of keypoints 23\n",
      "Processed image: 305 with number of keypoints 23\n",
      "Processed image: 306 with number of keypoints 23\n",
      "Processed image: 307 with number of keypoints 23\n",
      "Processed image: 308 with number of keypoints 23\n",
      "Processed image: 309 with number of keypoints 23\n",
      "Processed image: 310 with number of keypoints 23\n",
      "Processed image: 311 with number of keypoints 23\n",
      "Processed image: 312 with number of keypoints 23\n",
      "Processed image: 313 with number of keypoints 23\n",
      "Processed image: 314 with number of keypoints 23\n",
      "Processed image: 315 with number of keypoints 23\n",
      "Processed image: 316 with number of keypoints 23\n",
      "Processed image: 317 with number of keypoints 23\n",
      "Processed image: 318 with number of keypoints 23\n",
      "Processed image: 319 with number of keypoints 23\n",
      "Processed image: 320 with number of keypoints 23\n",
      "Processed image: 321 with number of keypoints 23\n",
      "Processed image: 322 with number of keypoints 23\n",
      "Processed image: 323 with number of keypoints 23\n",
      "Processed image: 324 with number of keypoints 23\n",
      "Processed image: 325 with number of keypoints 23\n",
      "Processed image: 326 with number of keypoints 23\n",
      "Processed image: 327 with number of keypoints 23\n",
      "Processed image: 328 with number of keypoints 23\n",
      "Processed image: 329 with number of keypoints 23\n",
      "Processed image: 330 with number of keypoints 23\n",
      "Processed image: 331 with number of keypoints 23\n",
      "Processed image: 332 with number of keypoints 23\n",
      "Processed image: 333 with number of keypoints 23\n",
      "Processed image: 334 with number of keypoints 23\n",
      "Processed image: 335 with number of keypoints 23\n",
      "Processed image: 336 with number of keypoints 23\n",
      "Processed image: 337 with number of keypoints 23\n",
      "Processed image: 338 with number of keypoints 23\n",
      "Processed image: 339 with number of keypoints 23\n",
      "Processed image: 340 with number of keypoints 23\n",
      "Processed image: 341 with number of keypoints 23\n",
      "Processed image: 342 with number of keypoints 23\n",
      "Processed image: 343 with number of keypoints 23\n",
      "Processed image: 344 with number of keypoints 23\n",
      "Processed image: 345 with number of keypoints 23\n",
      "Processed image: 346 with number of keypoints 23\n",
      "Processed image: 347 with number of keypoints 23\n",
      "Processed image: 348 with number of keypoints 23\n",
      "Processed image: 349 with number of keypoints 23\n",
      "Processed image: 350 with number of keypoints 23\n",
      "Processed image: 351 with number of keypoints 23\n",
      "Processed image: 352 with number of keypoints 23\n",
      "Processed image: 353 with number of keypoints 23\n",
      "Processed image: 354 with number of keypoints 23\n",
      "Processed image: 355 with number of keypoints 23\n",
      "Processed image: 356 with number of keypoints 23\n",
      "Processed image: 357 with number of keypoints 23\n",
      "Processed image: 358 with number of keypoints 23\n",
      "Processed image: 359 with number of keypoints 23\n",
      "Processed image: 360 with number of keypoints 23\n",
      "Processed image: 361 with number of keypoints 23\n",
      "Processed image: 362 with number of keypoints 23\n",
      "Processed image: 363 with number of keypoints 23\n",
      "Processed image: 364 with number of keypoints 23\n",
      "Processed image: 365 with number of keypoints 23\n",
      "Processed image: 366 with number of keypoints 23\n",
      "Processed image: 367 with number of keypoints 23\n",
      "Processed image: 368 with number of keypoints 23\n",
      "Processed image: 369 with number of keypoints 23\n",
      "Processed image: 370 with number of keypoints 23\n",
      "Processed image: 371 with number of keypoints 23\n",
      "Processed image: 372 with number of keypoints 23\n",
      "Processed image: 373 with number of keypoints 23\n",
      "Processed image: 374 with number of keypoints 23\n",
      "Processed image: 375 with number of keypoints 23\n",
      "Processed image: 376 with number of keypoints 23\n",
      "Processed image: 377 with number of keypoints 23\n",
      "Processed image: 378 with number of keypoints 23\n",
      "Processed image: 379 with number of keypoints 23\n",
      "Processed image: 380 with number of keypoints 23\n",
      "Processed image: 381 with number of keypoints 23\n",
      "Processed image: 382 with number of keypoints 23\n",
      "Processed image: 383 with number of keypoints 23\n",
      "Processed image: 384 with number of keypoints 23\n",
      "Processed image: 385 with number of keypoints 23\n",
      "Processed image: 386 with number of keypoints 23\n",
      "Processed image: 387 with number of keypoints 23\n",
      "Processed image: 388 with number of keypoints 23\n",
      "Processed image: 389 with number of keypoints 23\n",
      "Processed image: 390 with number of keypoints 23\n",
      "Processed image: 391 with number of keypoints 23\n",
      "Processed image: 392 with number of keypoints 23\n",
      "Processed image: 393 with number of keypoints 23\n",
      "Processed image: 394 with number of keypoints 23\n",
      "Processed image: 395 with number of keypoints 23\n",
      "Processed image: 396 with number of keypoints 23\n",
      "Processed image: 397 with number of keypoints 23\n",
      "Processed image: 398 with number of keypoints 23\n",
      "Processed image: 399 with number of keypoints 23\n",
      "Processed image: 400 with number of keypoints 23\n",
      "Processed image: 401 with number of keypoints 23\n",
      "Processed image: 402 with number of keypoints 23\n",
      "Processed image: 403 with number of keypoints 23\n",
      "Processed image: 404 with number of keypoints 23\n",
      "Processed image: 405 with number of keypoints 23\n",
      "Processed image: 406 with number of keypoints 23\n",
      "Processed image: 407 with number of keypoints 23\n",
      "Processed image: 408 with number of keypoints 23\n",
      "Processed image: 409 with number of keypoints 23\n",
      "Processed image: 410 with number of keypoints 23\n",
      "Processed image: 411 with number of keypoints 23\n",
      "Processed image: 412 with number of keypoints 23\n",
      "Processed image: 413 with number of keypoints 23\n",
      "Processed image: 414 with number of keypoints 23\n",
      "Processed image: 415 with number of keypoints 23\n",
      "Processed image: 416 with number of keypoints 23\n",
      "Processed image: 417 with number of keypoints 23\n",
      "Processed image: 418 with number of keypoints 23\n",
      "Processed image: 419 with number of keypoints 23\n",
      "Processed image: 420 with number of keypoints 23\n",
      "Processed image: 421 with number of keypoints 23\n",
      "Processed image: 422 with number of keypoints 23\n",
      "Processed image: 423 with number of keypoints 23\n",
      "Processed image: 424 with number of keypoints 23\n",
      "Processed image: 425 with number of keypoints 23\n",
      "Processed image: 426 with number of keypoints 23\n",
      "Processed image: 427 with number of keypoints 23\n",
      "Processed image: 428 with number of keypoints 23\n",
      "Processed image: 429 with number of keypoints 23\n",
      "Processed image: 430 with number of keypoints 23\n",
      "Processed image: 431 with number of keypoints 23\n",
      "Processed image: 432 with number of keypoints 23\n",
      "Processed image: 433 with number of keypoints 23\n",
      "Processed image: 434 with number of keypoints 23\n",
      "Processed image: 435 with number of keypoints 23\n",
      "Processed image: 436 with number of keypoints 23\n",
      "Processed image: 437 with number of keypoints 23\n",
      "Processed image: 438 with number of keypoints 23\n",
      "Processed image: 439 with number of keypoints 23\n",
      "Processed image: 440 with number of keypoints 23\n",
      "Processed image: 441 with number of keypoints 23\n",
      "Processed image: 442 with number of keypoints 23\n",
      "Processed image: 443 with number of keypoints 23\n",
      "Processed image: 444 with number of keypoints 23\n",
      "Processed image: 445 with number of keypoints 23\n",
      "Processed image: 446 with number of keypoints 23\n",
      "Processed image: 447 with number of keypoints 23\n",
      "Processed image: 448 with number of keypoints 23\n",
      "Processed image: 449 with number of keypoints 23\n",
      "Processed image: 450 with number of keypoints 23\n",
      "Processed image: 451 with number of keypoints 23\n",
      "Processed image: 452 with number of keypoints 23\n",
      "Processed image: 453 with number of keypoints 23\n",
      "Processed image: 454 with number of keypoints 23\n",
      "Processed image: 455 with number of keypoints 23\n",
      "Processed image: 456 with number of keypoints 23\n",
      "Processed image: 457 with number of keypoints 23\n",
      "Processed image: 458 with number of keypoints 23\n",
      "Processed image: 459 with number of keypoints 23\n",
      "Processed image: 460 with number of keypoints 23\n",
      "Processed image: 461 with number of keypoints 23\n",
      "Processed image: 462 with number of keypoints 23\n",
      "Processed image: 463 with number of keypoints 23\n",
      "Processed image: 464 with number of keypoints 23\n",
      "Processed image: 465 with number of keypoints 23\n",
      "Processed image: 466 with number of keypoints 23\n",
      "Processed image: 467 with number of keypoints 23\n",
      "Processed image: 468 with number of keypoints 23\n",
      "Processed image: 469 with number of keypoints 23\n",
      "Processed image: 470 with number of keypoints 23\n",
      "Processed image: 471 with number of keypoints 23\n",
      "Processed image: 472 with number of keypoints 23\n",
      "Processed image: 473 with number of keypoints 23\n",
      "Processed image: 474 with number of keypoints 23\n",
      "Processed image: 475 with number of keypoints 23\n",
      "Processed image: 476 with number of keypoints 23\n",
      "Processed image: 477 with number of keypoints 23\n",
      "Processed image: 478 with number of keypoints 23\n",
      "Processed image: 479 with number of keypoints 23\n",
      "Processed image: 480 with number of keypoints 23\n",
      "Processed image: 481 with number of keypoints 23\n",
      "Processed image: 482 with number of keypoints 23\n",
      "Processed image: 483 with number of keypoints 23\n",
      "Processed image: 484 with number of keypoints 23\n",
      "Processed image: 485 with number of keypoints 23\n",
      "Processed image: 486 with number of keypoints 23\n",
      "Processed image: 487 with number of keypoints 23\n",
      "Processed image: 488 with number of keypoints 23\n",
      "Processed image: 489 with number of keypoints 23\n",
      "Processed image: 490 with number of keypoints 23\n",
      "Processed image: 491 with number of keypoints 23\n",
      "Processed image: 492 with number of keypoints 23\n",
      "Processed image: 493 with number of keypoints 23\n",
      "Processed image: 494 with number of keypoints 23\n",
      "Processed image: 495 with number of keypoints 23\n",
      "Processed image: 496 with number of keypoints 23\n",
      "Processed image: 497 with number of keypoints 23\n",
      "Processed image: 498 with number of keypoints 23\n",
      "Processed image: 499 with number of keypoints 23\n",
      "Processed image: 500 with number of keypoints 23\n",
      "Processed image: 501 with number of keypoints 23\n",
      "Processed image: 502 with number of keypoints 23\n",
      "Processed image: 503 with number of keypoints 23\n",
      "Processed image: 504 with number of keypoints 23\n",
      "Processed image: 505 with number of keypoints 23\n",
      "Processed image: 506 with number of keypoints 23\n",
      "Processed image: 507 with number of keypoints 23\n",
      "Processed image: 508 with number of keypoints 23\n",
      "Split: closed-set\n",
      "Samples: train/test/unassigned/total = 188/54/0/242\n",
      "Classes: train/test/unassigned/total = 38/38/0/38\n",
      "Classes: train only/test only/joint  = 0/0/38\n",
      "\n",
      "Fraction of train set     = 77.69%\n",
      "Fraction of test set only = 0.00%\n",
      "Training Set\n",
      "Length: 188\n",
      "Number of individuals: 38\n",
      "Mean images/individual: 4.947368421052632\n",
      "Min images/individual: 1\n",
      "Max images/individual: 16\n",
      "Test Set\n",
      "Length: 54\n",
      "Number of individuals: 38\n",
      "Mean images per individual: 1.4210526315789473\n",
      "Min images per individual: 1\n",
      "Max images per individual: 4\n"
     ]
    }
   ],
   "source": [
    "from data.wildlife_dataset import WildlifeDataModule\n",
    "data = WildlifeDataModule(metadata=dataset_goleag.df,\n",
    "                          data_dir='../../datasets/raptor_individuals_cropped', \n",
    "                          animal_cat=\"bird\", \n",
    "                          preprocess_lvl=3,\n",
    "                          cache_path='../dataset/dataframe/goleag_cache.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
