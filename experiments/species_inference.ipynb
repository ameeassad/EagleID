{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from wildlife_tools.data import WildlifeDataset\n",
    "from wildlife_tools.inference import KnnClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import itertools\n",
    "from torch.optim import SGD\n",
    "from utils.trainer_pl import basic_trainer_pl\n",
    "from models.template_model import TemplateModel\n",
    "from utils.triplet_loss_utils import TripletLoss_wildlife\n",
    "\n",
    "from utils.triplet_loss_utils import KnnClassifier\n",
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_lightning import Trainer\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import wandb\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from wildlife_datasets import analysis, datasets, loader\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from utils.visualization import query_prediction_results\n",
    "from data.wildlife_dataset import WildlifeDataModule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce what combined_datasets does but without config and with local paths.\n",
    "# create a config dict\n",
    "config = {}\n",
    "config['wildlife_name'] = \"raptors, BirdIndividualID, ATRW, whaleshark\"\n",
    "config['use_wandb'] == False\n",
    "config['animal_cat'] = ['bird', 'bird', 'mammal', 'fish']\n",
    "config['dataset']= '/proj/nobackup/aiforeagles/'\n",
    "config['cache_path']= '/proj/nobackup/aiforeagles/EagleID/dataset/dataframe/cache_multispecies.csv'\n",
    "config['cache_only']= True\n",
    "\n",
    "raptor_path = os.path.join(config['dataset'], 'raptor_individuals_cropped')\n",
    "birds_path = os.path.join(config['dataset'], 'BirdIndividualID')\n",
    "atrw_path = os.path.join(config['dataset'], 'ATRW')\n",
    "whaleshark_path = os.path.join(config['dataset'], 'EDA-whaleshark')\n",
    "\n",
    "dataset1 = Raptors(root=raptor_path, include_video=False)\n",
    "dataset1.df['wildlife_name'] = 'raptors'\n",
    "dataset1.df['path'] = dataset1.df['path'].apply(lambda x: os.path.join('raptor_individuals_cropped', x))\n",
    "dataset2 = datasets.BirdIndividualID(birds_path)\n",
    "dataset2.df['wildlife_name'] = 'BirdIndividualID'\n",
    "dataset2.df['path'] = dataset2.df['path'].apply(lambda x: os.path.join('BirdIndividualID', x))\n",
    "dataset3 = datasets.WhaleSharkID(whaleshark_path)\n",
    "dataset3.df['wildlife_name'] = 'whaleshark'\n",
    "dataset3.df['path'] = dataset3.df['path'].apply(lambda x: os.path.join('EDA-whaleshark', x))\n",
    "dataset4 = datasets.ATRW(atrw_path)\n",
    "dataset4.df['wildlife_name'] = 'ATRW'\n",
    "dataset4.df['path'] = dataset4.df['path'].apply(lambda x: os.path.join('ATRW', x))\n",
    "\n",
    "dataset_df = pd.concat([dataset1.df, dataset2.df, dataset3.df, dataset4.df], ignore_index=True)\n",
    "\n",
    "data = WildlifeDataModule(metadata=dataset_df, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>bbox</th>\n",
       "      <th>keypoints</th>\n",
       "      <th>original_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000408498f926bc6</td>\n",
       "      <td>16</td>\n",
       "      <td>atrw_detection_test/test/2639.jpg</td>\n",
       "      <td>[654, 285, 743, 406]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004d0b59e19461f</td>\n",
       "      <td>34</td>\n",
       "      <td>atrw_reid_train/train/001970.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[326, 77, 2, 283, 86, 2, 331, 141, 2, 210, 174...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000871c1fc726f0b</td>\n",
       "      <td>177</td>\n",
       "      <td>atrw_reid_train/train/004612.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[127, 57, 2, 144, 82, 2, 93, 149, 2, 264, 183,...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0031e80738c8832c</td>\n",
       "      <td>18</td>\n",
       "      <td>atrw_detection_test/test/1645.jpg</td>\n",
       "      <td>[497, 292, 788, 493]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00411460f7c92d21</td>\n",
       "      <td>112</td>\n",
       "      <td>atrw_reid_test/test/000363.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 537, 28, 2, 562, 77, 2, 437, 135, 2,...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id  identity                               path  \\\n",
       "0  000408498f926bc6        16  atrw_detection_test/test/2639.jpg   \n",
       "1  0004d0b59e19461f        34   atrw_reid_train/train/001970.jpg   \n",
       "2  000871c1fc726f0b       177   atrw_reid_train/train/004612.jpg   \n",
       "3  0031e80738c8832c        18  atrw_detection_test/test/1645.jpg   \n",
       "4  00411460f7c92d21       112     atrw_reid_test/test/000363.jpg   \n",
       "\n",
       "                   bbox                                          keypoints  \\\n",
       "0  [654, 285, 743, 406]                                                NaN   \n",
       "1                   NaN  [326, 77, 2, 283, 86, 2, 331, 141, 2, 210, 174...   \n",
       "2                   NaN  [127, 57, 2, 144, 82, 2, 93, 149, 2, 264, 183,...   \n",
       "3  [497, 292, 788, 493]                                                NaN   \n",
       "4                   NaN  [0, 0, 0, 537, 28, 2, 562, 77, 2, 437, 135, 2,...   \n",
       "\n",
       "  original_split  \n",
       "0           test  \n",
       "1          train  \n",
       "2          train  \n",
       "3           test  \n",
       "4           test  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "root = '/Users/amee/Documents/code/master-thesis/datasets/'\n",
    "\n",
    "# Load dataset metadata\n",
    "metadata = datasets.ATRW(root)\n",
    "transform = T.Compose([T.Resize([224, 224]), T.ToTensor(), T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "dataset = WildlifeDataset(metadata.df, metadata.root, transform=transform)\n",
    "\n",
    "metadata.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the trainer\n",
    "# Download MegaDescriptor-T backbone from HuggingFace Hub\n",
    "backbone = timm.create_model('hf-hub:BVRA/MegaDescriptor-T-224', num_classes=0, pretrained=True)\n",
    "\n",
    "# Arcface loss - needs backbone output size and number of classes.\n",
    "objective = TripletLoss_wildlife()\n",
    "\n",
    "# Optimize parameters in backbone and in objective using single optimizer.\n",
    "params = itertools.chain(backbone.parameters(), objective.parameters())\n",
    "optimizer = SGD(params=params, lr=0.001, momentum=0.9)\n",
    "\n",
    "def print_epoch_loss(trainer, epoch_data):\n",
    "    # This function will print the average loss at the end of each epoch\n",
    "    print(f\"Epoch {trainer.epoch}: Average Loss = {epoch_data['train_loss_epoch_avg']}\")\n",
    "\n",
    "\n",
    "trainer = basic_trainer_pl(\n",
    "    dataset=dataset,\n",
    "    model=backbone,\n",
    "    objective=objective,\n",
    "    optimizer=optimizer,\n",
    "    epochs=0,\n",
    "    device='cpu',\n",
    "    epoch_callback=print_epoch_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model in retrieval metrics\n",
    "dataset_database_P = WildlifeDataset(metadata.df.iloc[100:,:], metadata.root, transform=transform)\n",
    "dataset_query_P = WildlifeDataset(metadata.df.iloc[:100,:], metadata.root, transform=transform)\n",
    "\n",
    "# name = 'hf-hub:BVRA/MegaDescriptor-T-224'\n",
    "extractor_P = DeepFeatures(backbone , device = 'cpu')\n",
    "\n",
    "query_P, database_P = extractor_P(dataset_query_P), extractor_P(dataset_database_P)\n",
    "\n",
    "similarity_function = CosineSimilarity()\n",
    "similarity_P = similarity_function(query_P, database_P)\n",
    "print(similarity_P)\n",
    "classifier_P = KnnClassifier(k=1, database_labels=dataset_database_P.labels_string)\n",
    "predictions_P = classifier_P(similarity_P['cosine'])\n",
    "print(\"Predictions for 100 test Images:-\\n\",predictions_P)\n",
    "accuracy_P = np.mean(dataset_query_P.labels_string == predictions_P)\n",
    "print(\"Accuracy on ATRW data: {:.2f}%\".format(accuracy_P * 100))\n",
    "\n",
    "precision_P = precision_score(dataset_query_P.labels_string, predictions_P, average='weighted',zero_division=1)\n",
    "recall_P = recall_score(dataset_query_P.labels_string, predictions_P, average='weighted',zero_division=1)\n",
    "f1_P = f1_score(dataset_query_P.labels_string, predictions_P, average='weighted',zero_division=1)\n",
    "print(\"Precision:\", precision_P)\n",
    "print(\"Recall:\", recall_P)\n",
    "print(\"F1 Score:\", f1_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for just a specific species\n",
    "def validate_species(model, species_name, query_metadata, db_metadata, root, transform):\n",
    "    # Filter metadata for target species\n",
    "    query_filtered = query_metadata[query_metadata['species'] == species_name].copy()\n",
    "    db_filtered = db_metadata[db_metadata['species'] == species_name].copy()\n",
    "    \n",
    "    # Create datasets\n",
    "    query_dataset = WildlifeDataset(query_filtered, root, transform=transform)\n",
    "    db_dataset = WildlifeDataset(db_filtered, root, transform=transform)\n",
    "    \n",
    "    # Create extractor (assuming DeepFeatures works with your model)\n",
    "    extractor = DeepFeatures(model.backbone, device='cpu')  # Use model's backbone\n",
    "    \n",
    "    # Extract features\n",
    "    query_features = extractor(query_dataset)\n",
    "    db_features = extractor(db_dataset)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = CosineSimilarity()(query_features, db_features)\n",
    "    \n",
    "    # Get predictions\n",
    "    classifier = KnnClassifier(k=1, database_labels=db_dataset.labels_string)\n",
    "    predictions = classifier(similarity['cosine'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(query_dataset.labels_string == predictions)\n",
    "    precision = precision_score(query_dataset.labels_string, predictions, average='weighted', zero_division=1)\n",
    "    recall = recall_score(query_dataset.labels_string, predictions, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(query_dataset.labels_string, predictions, average='weighted', zero_division=1)\n",
    "\n",
    "    # Visualization\n",
    "    query_prediction_results(\n",
    "        root=root,\n",
    "        query_metadata=query_filtered.reset_index(drop=True),\n",
    "        db_metadata=db_filtered.reset_index(drop=True),\n",
    "        query_start=0,\n",
    "        predictions=predictions,\n",
    "        num_images=min(10, len(query_filtered))\n",
    "    )\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
